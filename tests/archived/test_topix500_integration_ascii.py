#!/usr/bin/env python3
"""
TOPIX500çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆï¼ˆASCIIå®‰å…¨ç‰ˆï¼‰
Issue #314: TOPIX500å…¨éŠ˜æŸ„å¯¾å¿œ

å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
"""

import gc
import logging
import sys
import time
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆè¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent))

# ãƒ†ã‚¹ãƒˆè¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler()],
)

logger = logging.getLogger(__name__)


def test_database_system():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("1. TOPIX500 Database System Test")
    print("=" * 50)

    try:
        from src.day_trade.data.topix500_master import TOPIX500MasterManager

        # ãƒã‚¹ã‚¿ãƒ¼ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
        master_manager = TOPIX500MasterManager()

        # ã‚»ã‚¯ã‚¿ãƒ¼ãƒã‚¹ã‚¿ãƒ¼åˆæœŸåŒ–
        master_manager.initialize_sector_master()
        print("[OK] Sector master initialization completed")

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        master_manager.load_topix500_sample_data()
        print("[OK] TOPIX500 sample data loading completed")

        # éŠ˜æŸ„å–å¾—ãƒ†ã‚¹ãƒˆ
        symbols = master_manager.get_all_active_symbols()
        print(f"[OK] Active symbols retrieved: {len(symbols)} symbols")

        # ã‚»ã‚¯ã‚¿ãƒ¼ã‚µãƒãƒªãƒ¼å–å¾—
        sector_summary = master_manager.get_sector_summary()
        print(f"[OK] Sector summary retrieved: {len(sector_summary)} sectors")

        # ãƒãƒ©ãƒ³ã‚¹è€ƒæ…®ãƒãƒƒãƒä½œæˆ
        batches = master_manager.create_balanced_batches(batch_size=25)
        print(f"[OK] Balanced batches created: {len(batches)} batches")

        return True, {
            "symbols_count": len(symbols),
            "sectors_count": len(sector_summary),
            "batches_count": len(batches),
        }

    except Exception as e:
        print(f"[NG] Database system test error: {e}")
        return False, {}


def test_integration_performance(target_symbols: int = 50):
    """çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    print("\n" + "=" * 50)
    print("2. Integration Performance Test")
    print("=" * 50)

    try:
        print(
            f"Target: Process {target_symbols} symbols within 20 seconds, under 1GB memory"
        )

        # ãƒ†ã‚¹ãƒˆéŠ˜æŸ„ç”Ÿæˆ
        test_symbols = [f"{1000+i:04d}" for i in range(target_symbols)]

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–é–‹å§‹
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        print(f"Initial memory usage: {initial_memory:.1f}MB")

        # çµ±åˆå‡¦ç†å®Ÿè¡Œ
        start_time = time.time()

        # ç°¡æ˜“åˆ†æå‡¦ç†
        processed_count = 0
        analysis_results = []

        # ãƒãƒƒãƒå‡¦ç†
        batch_size = 10
        batches = [
            test_symbols[i : i + batch_size]
            for i in range(0, len(test_symbols), batch_size)
        ]

        for batch_idx, batch in enumerate(batches):
            batch_start = time.time()

            for symbol in batch:
                # ãƒ¢ãƒƒã‚¯åˆ†æå‡¦ç†
                np.random.seed(int(symbol))
                mock_result = {
                    "symbol": symbol,
                    "current_price": np.random.uniform(1000, 5000),
                    "price_change": np.random.uniform(-0.05, 0.05),
                    "volatility": np.random.uniform(0.1, 0.5),
                }
                analysis_results.append(mock_result)
                processed_count += 1

            batch_time = time.time() - batch_start
            current_memory = psutil.Process().memory_info().rss / 1024 / 1024

            if batch_idx < 5 or batch_idx % 5 == 0:  # ãƒ­ã‚°å‡ºåŠ›åˆ¶é™
                print(
                    f"  Batch {batch_idx+1}/{len(batches)}: {len(batch)} symbols, "
                    f"{batch_time:.1f}sec, Memory {current_memory:.1f}MB"
                )

        total_time = time.time() - start_time
        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_increase = final_memory - initial_memory

        # çµæœè©•ä¾¡
        success = True
        issues = []

        if total_time > 20:
            success = False
            issues.append(f"Processing time exceeded: {total_time:.1f}sec > 20sec")

        if memory_increase > 1024:  # 1GB
            success = False
            issues.append(f"Memory usage exceeded: {memory_increase:.1f}MB > 1024MB")

        if processed_count < len(test_symbols) * 0.9:  # 90%ä»¥ä¸Šã®æˆåŠŸç‡
            success = False
            issues.append(
                f"Success rate too low: {processed_count}/{len(test_symbols)}"
            )

        print("\nIntegration Performance Test Results:")
        print(f"  Processed symbols: {processed_count}/{len(test_symbols)}")
        print(f"  Total processing time: {total_time:.1f}sec (target: 20sec)")
        print(f"  Memory increase: {memory_increase:.1f}MB (target: <1024MB)")
        print(f"  Throughput: {processed_count/total_time:.1f} symbols/sec")
        print(f"  Success rate: {processed_count/len(test_symbols)*100:.1f}%")

        if success:
            print("[OK] Integration Performance Test: PASSED")
        else:
            print("[NG] Integration Performance Test: FAILED")
            for issue in issues:
                print(f"  - {issue}")

        return success, {
            "processed_count": processed_count,
            "total_time": total_time,
            "memory_increase": memory_increase,
            "throughput": processed_count / total_time,
            "success_rate": processed_count / len(test_symbols) * 100,
            "target_achieved": success,
        }

    except Exception as e:
        print(f"[NG] Integration performance test error: {e}")
        return False, {}


def test_system_scalability():
    """ã‚·ã‚¹ãƒ†ãƒ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("3. System Scalability Test")
    print("=" * 50)

    try:
        # æ®µéšçš„è² è·ãƒ†ã‚¹ãƒˆ
        test_sizes = [10, 25, 50, 100]
        scalability_results = []

        for test_size in test_sizes:
            print(f"\nTesting with {test_size} symbols...")

            start_time = time.time()
            initial_memory = psutil.Process().memory_info().rss / 1024 / 1024

            # å‡¦ç†å®Ÿè¡Œ
            test_symbols = [f"{2000+i:04d}" for i in range(test_size)]
            processed_count = 0

            for symbol in test_symbols:
                # è»½é‡ãªå‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                np.random.seed(int(symbol))
                mock_analysis = np.random.uniform(0, 1, 10).mean()  # ç°¡æ˜“è¨ˆç®—
                processed_count += 1

            processing_time = time.time() - start_time
            final_memory = psutil.Process().memory_info().rss / 1024 / 1024
            memory_used = final_memory - initial_memory

            throughput = processed_count / processing_time
            memory_per_symbol = (
                memory_used / processed_count if processed_count > 0 else 0
            )

            scalability_results.append(
                {
                    "symbols": test_size,
                    "time": processing_time,
                    "memory": memory_used,
                    "throughput": throughput,
                    "memory_per_symbol": memory_per_symbol,
                }
            )

            print(
                f"  Results: {processing_time:.2f}sec, {memory_used:.1f}MB, "
                f"{throughput:.1f} symbols/sec"
            )

        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ
        print("\nScalability Analysis:")
        print("Symbols | Time(s) | Memory(MB) | Throughput(sym/s) | Mem/Symbol(MB)")
        print("-" * 70)

        for result in scalability_results:
            print(
                f"{result['symbols']:7d} | {result['time']:7.2f} | "
                f"{result['memory']:10.1f} | {result['throughput']:13.1f} | "
                f"{result['memory_per_symbol']:11.3f}"
            )

        # ç·šå½¢æ€§ãƒã‚§ãƒƒã‚¯
        if len(scalability_results) >= 2:
            time_ratio = (
                scalability_results[-1]["time"] / scalability_results[0]["time"]
            )
            symbols_ratio = (
                scalability_results[-1]["symbols"] / scalability_results[0]["symbols"]
            )
            linearity_score = min(
                time_ratio / symbols_ratio, symbols_ratio / time_ratio
            )

            print(
                f"\nLinearity Score: {linearity_score:.2f} (1.0 = perfect linear scaling)"
            )

            if linearity_score > 0.7:
                print("[OK] Good scalability characteristics")
                return True, {
                    "linearity_score": linearity_score,
                    "results": scalability_results,
                }
            else:
                print("[WARN] Scalability issues detected")
                return True, {
                    "linearity_score": linearity_score,
                    "results": scalability_results,
                }

        return True, {"results": scalability_results}

    except Exception as e:
        print(f"[NG] System scalability test error: {e}")
        return False, {}


def test_memory_efficiency():
    """ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 50)
    print("4. Memory Efficiency Test")
    print("=" * 50)

    try:
        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_snapshots = [initial_memory]

        print(f"Initial memory: {initial_memory:.1f}MB")

        # å¤§é‡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        large_datasets = []

        for i in range(10):  # 10å€‹ã®å¤§ããªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
            # å¤§ããªDataFrameä½œæˆ
            size = 1000
            data = pd.DataFrame(
                {
                    "values": np.random.randn(size),
                    "categories": np.random.choice(["A", "B", "C"], size),
                    "timestamps": pd.date_range("2023-01-01", periods=size, freq="H"),
                }
            )

            large_datasets.append(data)

            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡è¨˜éŒ²
            current_memory = psutil.Process().memory_info().rss / 1024 / 1024
            memory_snapshots.append(current_memory)

            if i % 3 == 0:
                print(f"  Dataset {i+1}: Memory {current_memory:.1f}MB")

        peak_memory = max(memory_snapshots)
        memory_growth = peak_memory - initial_memory

        print(f"Peak memory: {peak_memory:.1f}MB")
        print(f"Memory growth: {memory_growth:.1f}MB")

        # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆ
        print("Testing memory cleanup...")
        del large_datasets
        gc.collect()

        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®ãƒ¡ãƒ¢ãƒªç¢ºèª
        cleanup_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_recovered = peak_memory - cleanup_memory
        recovery_ratio = memory_recovered / memory_growth if memory_growth > 0 else 1.0

        print(f"Memory after cleanup: {cleanup_memory:.1f}MB")
        print(f"Memory recovered: {memory_recovered:.1f}MB")
        print(f"Recovery ratio: {recovery_ratio:.1%}")

        # åŠ¹ç‡æ€§è©•ä¾¡
        efficient = memory_growth < 500 and recovery_ratio > 0.7

        if efficient:
            print("[OK] Memory efficiency test: PASSED")
        else:
            print("[WARN] Memory efficiency test: Needs improvement")

        return True, {
            "initial_memory": initial_memory,
            "peak_memory": peak_memory,
            "memory_growth": memory_growth,
            "recovery_ratio": recovery_ratio,
            "efficient": efficient,
        }

    except Exception as e:
        print(f"[NG] Memory efficiency test error: {e}")
        return False, {}


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 80)
    print("TOPIX500 Comprehensive System Integration Test Suite")
    print("=" * 80)
    print(f"Test start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    test_results = {}
    overall_success = True

    # 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
    success, result = test_database_system()
    test_results["database"] = {"success": success, "result": result}
    if not success:
        overall_success = False

    # 2. çµ±åˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    success, result = test_integration_performance(target_symbols=50)
    test_results["performance"] = {"success": success, "result": result}
    if not success:
        overall_success = False

    # 3. ã‚·ã‚¹ãƒ†ãƒ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ
    success, result = test_system_scalability()
    test_results["scalability"] = {"success": success, "result": result}
    if not success:
        overall_success = False

    # 4. ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ãƒ†ã‚¹ãƒˆ
    success, result = test_memory_efficiency()
    test_results["memory"] = {"success": success, "result": result}
    if not success:
        overall_success = False

    # æœ€çµ‚çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 80)
    print("Integration Test Results Summary")
    print("=" * 80)

    test_names = {
        "database": "Database System",
        "performance": "Integration Performance",
        "scalability": "System Scalability",
        "memory": "Memory Efficiency",
    }

    success_count = 0
    for test_key, test_info in test_results.items():
        status = "[OK] PASSED" if test_info["success"] else "[NG] FAILED"
        print(f"{test_names[test_key]}: {status}")
        if test_info["success"]:
            success_count += 1

    print(f"\nOverall Result: {success_count}/{len(test_results)} tests passed")

    # çµ±è¨ˆã‚µãƒãƒªãƒ¼
    if "performance" in test_results and test_results["performance"]["success"]:
        perf_result = test_results["performance"]["result"]
        print("\nKey Performance Metrics:")
        print(f"  Processing Time: {perf_result.get('total_time', 0):.1f} seconds")
        print(f"  Throughput: {perf_result.get('throughput', 0):.1f} symbols/second")
        print(f"  Memory Usage: {perf_result.get('memory_increase', 0):.1f} MB")
        print(f"  Success Rate: {perf_result.get('success_rate', 0):.1f}%")

    if overall_success:
        print("\nğŸ‰ TOPIX500 System: Integration Test PASSED!")
        print("âœ… System is ready for TOPIX500 symbol processing")
    else:
        print("\nâš ï¸  TOPIX500 System: Some tests failed")
        print("âŒ Some components need improvement")

    print(f"Test end time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80)

    return overall_success


if __name__ == "__main__":
    try:
        success = main()
        exit(0 if success else 1)
    except KeyboardInterrupt:
        print("\n\nTest interrupted")
        exit(1)
    except Exception as e:
        print(f"\n\nUnexpected error: {e}")
        import traceback

        traceback.print_exc()
        exit(1)
