#!/usr/bin/env python3
"""
åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
Phase E: ã‚·ã‚¹ãƒ†ãƒ å“è³ªå¼·åŒ–ãƒ•ã‚§ãƒ¼ã‚º

çµ±åˆæœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½æ¤œè¨¼ãƒ»å›å¸°ãƒ†ã‚¹ãƒˆ
"""

import gc
import memory_profiler
import psutil
import pytest
import time
import threading
import numpy as np
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Tuple, Any

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "src"))

from src.day_trade.core.optimization_strategy import (
    OptimizationConfig,
    OptimizationLevel,
    get_optimized_implementation
)


class PerformanceTestSuite:
    """åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""
    
    @pytest.fixture(autouse=True)
    def setup_performance_test_data(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        np.random.seed(42)
        
        # å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆåŸºæœ¬ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        self.small_data = self._generate_market_data(100)
        
        # ä¸­è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆé€šå¸¸é‹ç”¨æƒ³å®šï¼‰
        self.medium_data = self._generate_market_data(1000)
        
        # å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè² è·ãƒ†ã‚¹ãƒˆç”¨ï¼‰
        self.large_data = self._generate_market_data(10000)
        
        # ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—
        self.system_info = self._get_system_info()
        
        print(f"ğŸ’» ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±: CPU {psutil.cpu_count()}ã‚³ã‚¢, ãƒ¡ãƒ¢ãƒª {self.system_info['memory_gb']:.1f}GB")
    
    def _generate_market_data(self, periods: int) -> pd.DataFrame:
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        dates = pd.date_range('2023-01-01', periods=periods, freq='D')
        
        price_base = 1000
        returns = np.random.normal(0.001, 0.02, periods)
        prices = [price_base]
        
        for ret in returns[:-1]:
            prices.append(prices[-1] * (1 + ret))
        
        return pd.DataFrame({
            'Date': dates,
            'Open': [p * (1 + np.random.normal(0, 0.005)) for p in prices],
            'High': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
            'Low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
            'Close': prices,
            'Volume': np.random.randint(1000000, 10000000, periods)
        }).set_index('Date')
    
    def _get_system_info(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ æƒ…å ±å–å¾—"""
        return {
            'cpu_count': psutil.cpu_count(),
            'memory_gb': psutil.virtual_memory().total / 1024**3,
            'cpu_freq_ghz': psutil.cpu_freq().max / 1000 if psutil.cpu_freq() else 0
        }
    
    @pytest.mark.benchmark(group="technical_indicators")
    def test_technical_indicators_performance_standard_vs_optimized(self):
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹: æ¨™æº– vs æœ€é©åŒ–"""
        try:
            from src.day_trade.analysis.technical_indicators_unified import TechnicalIndicatorsManager
            
            configs = {
                'standard': OptimizationConfig(level=OptimizationLevel.STANDARD),
                'optimized': OptimizationConfig(level=OptimizationLevel.OPTIMIZED)
            }
            
            indicators = ["sma", "ema", "rsi", "macd", "bollinger_bands", "stochastic", "cci", "williams_r"]
            results = {}
            
            for config_name, config in configs.items():
                manager = TechnicalIndicatorsManager(config)
                
                # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šé–‹å§‹
                process = psutil.Process()
                memory_before = process.memory_info().rss / 1024 / 1024  # MB
                
                start_time = time.time()
                
                # æŒ‡æ¨™è¨ˆç®—å®Ÿè¡Œ
                calculation_results = manager.calculate_indicators(self.medium_data, indicators, period=20)
                
                execution_time = time.time() - start_time
                memory_after = process.memory_info().rss / 1024 / 1024  # MB
                memory_used = memory_after - memory_before
                
                results[config_name] = {
                    'execution_time': execution_time,
                    'memory_used_mb': memory_used,
                    'indicators_calculated': len(calculation_results),
                    'strategy_name': manager.get_strategy().get_strategy_name()
                }
                
                # ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                del manager
                gc.collect()
            
            # æ€§èƒ½æ¯”è¼ƒåˆ†æ
            standard_time = results['standard']['execution_time']
            optimized_time = results['optimized']['execution_time']
            speedup_ratio = standard_time / optimized_time if optimized_time > 0 else float('inf')
            
            standard_memory = results['standard']['memory_used_mb']
            optimized_memory = results['optimized']['memory_used_mb']
            memory_efficiency = (standard_memory - optimized_memory) / standard_memory * 100 if standard_memory > 0 else 0
            
            # æ€§èƒ½æœŸå¾…å€¤ãƒã‚§ãƒƒã‚¯
            assert speedup_ratio > 0.8, f"æœ€é©åŒ–ç‰ˆã®æ€§èƒ½åŠ£åŒ–: {speedup_ratio:.2f}å€"  # æœ€ä½ã§ã‚‚åŒç­‰æ€§èƒ½
            assert results['optimized']['indicators_calculated'] == len(indicators), "æŒ‡æ¨™è¨ˆç®—æ•°ä¸ä¸€è‡´"
            
            print(f"âš¡ ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒ:")
            print(f"   æ¨™æº–ç‰ˆ: {standard_time:.3f}ç§’, {standard_memory:.1f}MB")
            print(f"   æœ€é©åŒ–ç‰ˆ: {optimized_time:.3f}ç§’, {optimized_memory:.1f}MB")
            print(f"   é€Ÿåº¦æ¯”: {speedup_ratio:.2f}å€, ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: {memory_efficiency:.1f}%æ”¹å–„")
            
            return results
            
        except ImportError as e:
            pytest.skip(f"ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™çµ±åˆã‚·ã‚¹ãƒ†ãƒ æœªåˆ©ç”¨: {e}")
    
    @pytest.mark.benchmark(group="parallel_processing")
    def test_parallel_processing_scalability(self):
        """ä¸¦åˆ—å‡¦ç†ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãƒ†ã‚¹ãƒˆ"""
        try:
            from src.day_trade.analysis.feature_engineering_unified import (
                FeatureEngineeringManager,
                FeatureConfig
            )
            
            # ä¸¦åˆ—åº¦ã‚’å¤‰åŒ–ã•ã›ã¦ãƒ†ã‚¹ãƒˆ
            worker_counts = [1, 2, 4, min(8, psutil.cpu_count())]
            results = {}
            
            for workers in worker_counts:
                config = OptimizationConfig(
                    level=OptimizationLevel.OPTIMIZED,
                    parallel_processing=True
                )
                
                feature_config = FeatureConfig(
                    lookback_periods=[5, 10, 20, 50],
                    volatility_windows=[10, 20, 50],
                    momentum_periods=[5, 10, 20],
                    enable_parallel=True,
                    max_workers=workers
                )
                
                manager = FeatureEngineeringManager(config)
                
                start_time = time.time()
                result = manager.generate_features(self.medium_data, feature_config)
                execution_time = time.time() - start_time
                
                results[workers] = {
                    'execution_time': execution_time,
                    'features_generated': len(result.feature_names) if result else 0,
                    'worker_count': workers
                }
                
                del manager
                gc.collect()
            
            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£åˆ†æ
            single_thread_time = results[1]['execution_time']
            best_parallel_time = min(results[w]['execution_time'] for w in worker_counts if w > 1)
            parallel_efficiency = single_thread_time / best_parallel_time
            
            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£æœŸå¾…å€¤
            assert parallel_efficiency > 1.0, f"ä¸¦åˆ—å‡¦ç†åŠ¹æœãªã—: {parallel_efficiency:.2f}å€"
            
            print(f"âš¡ ä¸¦åˆ—å‡¦ç†ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£:")
            for workers, result in results.items():
                speedup = single_thread_time / result['execution_time']
                efficiency = speedup / workers * 100
                print(f"   {workers}ãƒ¯ãƒ¼ã‚«ãƒ¼: {result['execution_time']:.3f}ç§’, é«˜é€ŸåŒ–{speedup:.2f}å€, åŠ¹ç‡{efficiency:.1f}%")
            
            return results
            
        except ImportError as e:
            pytest.skip(f"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°çµ±åˆã‚·ã‚¹ãƒ†ãƒ æœªåˆ©ç”¨: {e}")
    
    @pytest.mark.memory
    def test_memory_usage_optimization(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""
        try:
            from src.day_trade.analysis.technical_indicators_unified import TechnicalIndicatorsManager
            
            configs = {
                'cache_disabled': OptimizationConfig(
                    level=OptimizationLevel.OPTIMIZED,
                    cache_enabled=False
                ),
                'cache_enabled': OptimizationConfig(
                    level=OptimizationLevel.OPTIMIZED,
                    cache_enabled=True
                )
            }
            
            results = {}
            
            for config_name, config in configs.items():
                # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
                memory_samples = []
                
                def memory_monitor():
                    process = psutil.Process()
                    for _ in range(10):  # 1ç§’é–“ã€0.1ç§’é–“éš”ã§ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                        memory_samples.append(process.memory_info().rss / 1024 / 1024)
                        time.sleep(0.1)
                
                manager = TechnicalIndicatorsManager(config)
                
                # ãƒ¡ãƒ¢ãƒªç›£è¦–é–‹å§‹
                monitor_thread = threading.Thread(target=memory_monitor)
                monitor_thread.start()
                
                # è¤‡æ•°å›å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœç¢ºèªï¼‰
                indicators = ["sma", "ema", "rsi", "bollinger_bands"]
                for i in range(3):
                    manager.calculate_indicators(self.small_data, indicators)
                
                monitor_thread.join()
                
                results[config_name] = {
                    'max_memory_mb': max(memory_samples),
                    'avg_memory_mb': np.mean(memory_samples),
                    'memory_variance': np.var(memory_samples)
                }
                
                del manager
                gc.collect()
            
            # ãƒ¡ãƒ¢ãƒªåŠ¹ç‡åˆ†æ
            cache_disabled_memory = results['cache_disabled']['avg_memory_mb']
            cache_enabled_memory = results['cache_enabled']['avg_memory_mb']
            
            print(f"ğŸ’¾ ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¯”è¼ƒ:")
            print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹: æœ€å¤§{results['cache_disabled']['max_memory_mb']:.1f}MB, å¹³å‡{cache_disabled_memory:.1f}MB")
            print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥æœ‰åŠ¹: æœ€å¤§{results['cache_enabled']['max_memory_mb']:.1f}MB, å¹³å‡{cache_enabled_memory:.1f}MB")
            
            # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
            assert results['cache_enabled']['max_memory_mb'] < 500, "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡éå¤§"  # 500MBæœªæº€
            
            return results
            
        except ImportError as e:
            pytest.skip(f"ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆæœªå®Ÿè¡Œ: {e}")
    
    @pytest.mark.stress
    def test_high_load_stress_test(self):
        """é«˜è² è·ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        try:
            from src.day_trade.analysis.multi_timeframe_analysis_unified import MultiTimeframeAnalysisManager
            
            config = OptimizationConfig(
                level=OptimizationLevel.OPTIMIZED,
                parallel_processing=True
            )
            
            manager = MultiTimeframeAnalysisManager(config)
            
            # åŒæ™‚å®Ÿè¡Œæ•°ã‚’æ®µéšçš„ã«å¢—åŠ 
            concurrent_levels = [1, 2, 4, 8]
            results = {}
            
            for concurrent_count in concurrent_levels:
                start_time = time.time()
                successful_executions = 0
                
                with ThreadPoolExecutor(max_workers=concurrent_count) as executor:
                    # è¤‡æ•°ã®åˆ†æã‚’åŒæ™‚å®Ÿè¡Œ
                    futures = []
                    for i in range(concurrent_count * 2):  # ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°ã®2å€ã®ã‚¿ã‚¹ã‚¯
                        future = executor.submit(manager.analyze_multi_timeframe, self.medium_data)
                        futures.append(future)
                    
                    # çµæœåé›†
                    for future in as_completed(futures, timeout=60):
                        try:
                            result = future.result()
                            if result and hasattr(result, 'integrated_trend'):
                                successful_executions += 1
                        except Exception as e:
                            print(f"âš ï¸  ä¸¦è¡Œå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
                
                execution_time = time.time() - start_time
                success_rate = successful_executions / (concurrent_count * 2)
                
                results[concurrent_count] = {
                    'execution_time': execution_time,
                    'successful_executions': successful_executions,
                    'success_rate': success_rate,
                    'throughput': successful_executions / execution_time
                }
                
                # æˆåŠŸç‡æœŸå¾…å€¤
                assert success_rate > 0.8, f"é«˜è² è·æ™‚ã®æˆåŠŸç‡ä¸è¶³: {success_rate:.2%}"
            
            print(f"ğŸ”¥ é«˜è² è·ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœ:")
            for concurrent, result in results.items():
                print(f"   åŒæ™‚å®Ÿè¡Œæ•°{concurrent}: æˆåŠŸç‡{result['success_rate']:.2%}, "
                      f"ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ{result['throughput']:.2f}ã‚¿ã‚¹ã‚¯/ç§’")
            
            return results
            
        except ImportError as e:
            pytest.skip(f"é«˜è² è·ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆæœªå®Ÿè¡Œ: {e}")
    
    @pytest.mark.regression
    def test_performance_regression(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å›å¸°ãƒ†ã‚¹ãƒˆ"""
        # åŸºæº–æ€§èƒ½å€¤ï¼ˆå®Ÿæ¸¬å€¤ãƒ™ãƒ¼ã‚¹ï¼‰
        baseline_performance = {
            'technical_indicators_time': 2.0,  # ç§’
            'feature_engineering_time': 3.0,   # ç§’
            'multi_timeframe_time': 5.0,       # ç§’
            'max_memory_usage': 200,            # MB
        }
        
        current_performance = {}
        
        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«æŒ‡æ¨™æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        try:
            from src.day_trade.analysis.technical_indicators_unified import TechnicalIndicatorsManager
            
            config = OptimizationConfig(level=OptimizationLevel.OPTIMIZED)
            manager = TechnicalIndicatorsManager(config)
            
            start_time = time.time()
            manager.calculate_indicators(self.medium_data, ["sma", "ema", "rsi", "macd"])
            current_performance['technical_indicators_time'] = time.time() - start_time
            
        except ImportError:
            current_performance['technical_indicators_time'] = float('inf')
        
        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        try:
            from src.day_trade.analysis.feature_engineering_unified import (
                FeatureEngineeringManager,
                FeatureConfig
            )
            
            config = OptimizationConfig(level=OptimizationLevel.OPTIMIZED)
            manager = FeatureEngineeringManager(config)
            feature_config = FeatureConfig(
                lookback_periods=[5, 10, 20],
                volatility_windows=[10, 20],
                momentum_periods=[5, 10]
            )
            
            start_time = time.time()
            manager.generate_features(self.medium_data, feature_config)
            current_performance['feature_engineering_time'] = time.time() - start_time
            
        except ImportError:
            current_performance['feature_engineering_time'] = float('inf')
        
        # ãƒãƒ«ãƒã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ æ€§èƒ½ãƒ†ã‚¹ãƒˆ
        try:
            from src.day_trade.analysis.multi_timeframe_analysis_unified import MultiTimeframeAnalysisManager
            
            config = OptimizationConfig(level=OptimizationLevel.OPTIMIZED)
            manager = MultiTimeframeAnalysisManager(config)
            
            start_time = time.time()
            manager.analyze_multi_timeframe(self.medium_data)
            current_performance['multi_timeframe_time'] = time.time() - start_time
            
        except ImportError:
            current_performance['multi_timeframe_time'] = float('inf')
        
        # å›å¸°ãƒã‚§ãƒƒã‚¯
        regression_detected = False
        regression_details = []
        
        for metric, baseline_value in baseline_performance.items():
            if metric in current_performance:
                current_value = current_performance[metric]
                if current_value > baseline_value * 1.2:  # 20%ä»¥ä¸Šã®åŠ£åŒ–ã§å›å¸°
                    regression_detected = True
                    regression_ratio = current_value / baseline_value
                    regression_details.append(f"{metric}: {regression_ratio:.2f}å€åŠ£åŒ–")
        
        print(f"ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å›å¸°ãƒ†ã‚¹ãƒˆ:")
        for metric, baseline in baseline_performance.items():
            current = current_performance.get(metric, float('inf'))
            status = "âœ…" if current <= baseline * 1.2 else "âŒ"
            print(f"   {status} {metric}: åŸºæº–{baseline:.2f}, ç¾åœ¨{current:.2f}")
        
        if regression_detected:
            print(f"âš ï¸  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å›å¸°æ¤œå‡º: {', '.join(regression_details)}")
            # å›å¸°ã¯è­¦å‘Šã®ã¿ï¼ˆCIã§ã¯ç¶™ç¶šï¼‰
        
        return {
            'regression_detected': regression_detected,
            'current_performance': current_performance,
            'baseline_performance': baseline_performance
        }
    
    @pytest.mark.benchmark(group="cache_efficiency")
    def test_cache_efficiency(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãƒ†ã‚¹ãƒˆ"""
        try:
            from src.day_trade.analysis.technical_indicators_unified import TechnicalIndicatorsManager
            
            config = OptimizationConfig(
                level=OptimizationLevel.OPTIMIZED,
                cache_enabled=True
            )
            
            manager = TechnicalIndicatorsManager(config)
            indicators = ["sma", "ema", "rsi"]
            
            # 1å›ç›®å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥æ§‹ç¯‰ï¼‰
            start_time = time.time()
            manager.calculate_indicators(self.small_data, indicators)
            first_execution_time = time.time() - start_time
            
            # 2å›ç›®å®Ÿè¡Œï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæœŸå¾…ï¼‰
            start_time = time.time()
            manager.calculate_indicators(self.small_data, indicators)  # åŒã˜ãƒ‡ãƒ¼ã‚¿ãƒ»æŒ‡æ¨™
            second_execution_time = time.time() - start_time
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœåˆ†æ
            cache_speedup = first_execution_time / max(second_execution_time, 0.001)
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—
            strategy = manager.get_strategy()
            cache_stats = {}
            if hasattr(strategy, 'get_cache_stats'):
                cache_stats = strategy.get_cache_stats()
            
            print(f"ğŸ—„ï¸  ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãƒ†ã‚¹ãƒˆ:")
            print(f"   1å›ç›®: {first_execution_time:.3f}ç§’")
            print(f"   2å›ç›®: {second_execution_time:.3f}ç§’")
            print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ: {cache_speedup:.1f}å€é«˜é€ŸåŒ–")
            
            if cache_stats:
                print(f"   ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ: {cache_stats}")
            
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæœŸå¾…å€¤
            assert cache_speedup > 1.0, f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœãªã—: {cache_speedup:.2f}å€"
            
            return {
                'first_execution_time': first_execution_time,
                'second_execution_time': second_execution_time,
                'cache_speedup': cache_speedup,
                'cache_stats': cache_stats
            }
            
        except ImportError as e:
            pytest.skip(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ç‡ãƒ†ã‚¹ãƒˆæœªå®Ÿè¡Œ: {e}")


if __name__ == "__main__":
    # ç›´æ¥å®Ÿè¡Œæ™‚ã®ãƒ†ã‚¹ãƒˆ
    test_suite = PerformanceTestSuite()
    test_suite.setup_performance_test_data()
    
    print("ğŸš€ åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹")
    
    try:
        # åŸºæœ¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
        test_suite.test_technical_indicators_performance_standard_vs_optimized()
        test_suite.test_memory_usage_optimization()
        test_suite.test_cache_efficiency()
        
        print("âœ… åŒ…æ‹¬çš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº†")
        
    except Exception as e:
        print(f"âŒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
        raise