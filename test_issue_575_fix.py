#!/usr/bin/env python3
"""
Issue #575ä¿®æ­£ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ
æ‹¡å¼µå¯èƒ½ãªã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ
"""

import sys
import numpy as np
import pandas as pd
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / "src"))

try:
    from day_trade.data.feature_engines import (
        FeatureEngine,
        FeatureEngineRegistry,
        calculate_custom_feature,
        list_available_features,
        register_custom_engine,
        FeatureEngineError
    )
    from day_trade.data.batch_data_fetcher import AdvancedBatchDataFetcher, DataRequest

except ImportError as e:
    print(f"ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    sys.exit(1)


class CustomVolatilityEngine(FeatureEngine):
    """ã‚«ã‚¹ã‚¿ãƒ ãƒ»ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""

    name = "custom_volatility"
    required_columns = ["çµ‚å€¤"]
    description = "ã‚«ã‚¹ã‚¿ãƒ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æŒ‡æ¨™è¨ˆç®—"

    def calculate(self, data: pd.DataFrame, window: int = 20, **kwargs) -> pd.DataFrame:
        """ã‚«ã‚¹ã‚¿ãƒ ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—"""
        result = data.copy()

        returns = data["çµ‚å€¤"].pct_change()
        result[f"volatility_{window}"] = returns.rolling(window).std()
        result[f"volatility_{window}_annualized"] = result[f"volatility_{window}"] * np.sqrt(252)

        return result


def create_test_data(n_days: int = 100) -> pd.DataFrame:
    """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
    dates = pd.date_range('2023-01-01', periods=n_days, freq='D')
    np.random.seed(42)

    # ç¾å®Ÿçš„ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    base_price = 100
    price_changes = np.random.randn(n_days).cumsum() * 0.02  # 2%ã®æ—¥æ¬¡å¤‰å‹•

    prices = base_price * (1 + price_changes)
    highs = prices * (1 + np.random.rand(n_days) * 0.03)  # é«˜å€¤ã¯çµ‚å€¤ã‚ˆã‚Šæœ€å¤§3%é«˜ã„
    lows = prices * (1 - np.random.rand(n_days) * 0.03)   # å®‰å€¤ã¯çµ‚å€¤ã‚ˆã‚Šæœ€å¤§3%ä½ã„
    opens = np.roll(prices, 1)  # å‰æ—¥çµ‚å€¤åŸºæº–ã®å§‹å€¤
    opens[0] = base_price

    volumes = 1000000 + np.random.randint(-200000, 200000, n_days)
    volumes = np.maximum(volumes, 100000)  # æœ€ä½10ä¸‡æ ª

    return pd.DataFrame({
        'å§‹å€¤': opens,
        'é«˜å€¤': highs,
        'å®‰å€¤': lows,
        'çµ‚å€¤': prices,
        'å‡ºæ¥é«˜': volumes,
    }, index=dates)


def test_feature_engine_system():
    """æ‹¡å¼µå¯èƒ½ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    print("=== Issue #575 æ‹¡å¼µå¯èƒ½ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆ ===\n")

    # 1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("1. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ...")
    test_data = create_test_data(60)
    print(f"   ä½œæˆå®Œäº†: {test_data.shape}")
    print(f"   åˆ—: {list(test_data.columns)}")

    # 2. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰¹å¾´é‡ä¸€è¦§ç¢ºèª
    print("\n2. ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç‰¹å¾´é‡ç¢ºèª...")
    features = list_available_features()
    print(f"   åˆ©ç”¨å¯èƒ½ç‰¹å¾´é‡: {len(features)}ç¨®é¡")
    for name, info in features.items():
        print(f"   - {name}: {info.get('description', 'N/A')}")

    # 3. ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ç™»éŒ²ãƒ†ã‚¹ãƒˆ
    print("\n3. ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ç™»éŒ²...")
    try:
        register_custom_engine(CustomVolatilityEngine)
        print("   OK CustomVolatilityEngineç™»éŒ²æˆåŠŸ")

        # ç™»éŒ²ç¢ºèª
        updated_features = list_available_features()
        if "custom_volatility" in updated_features:
            print("   OK ç™»éŒ²ã•ã‚ŒãŸç‰¹å¾´é‡ãŒåˆ©ç”¨å¯èƒ½ãƒªã‚¹ãƒˆã«è¿½åŠ ")

    except Exception as e:
        print(f"   NG ã‚«ã‚¹ã‚¿ãƒ ã‚¨ãƒ³ã‚¸ãƒ³ç™»éŒ²ã‚¨ãƒ©ãƒ¼: {e}")

    # 4. å„ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    print("\n4. ç‰¹å¾´é‡è¨ˆç®—ãƒ†ã‚¹ãƒˆ...")

    test_features = [
        ("trend_strength", {}),
        ("momentum", {"periods": [5, 10]}),
        ("price_channel", {"period": 15}),
        ("gap_analysis", {"gap_threshold": 0.03}),
        ("volume_analysis", {"short_period": 3, "long_period": 10}),
        ("custom_volatility", {"window": 15}),
    ]

    accumulated_data = test_data.copy()
    original_cols = len(test_data.columns)

    for feature_name, params in test_features:
        try:
            print(f"   {feature_name}è¨ˆç®—ä¸­...")
            result = calculate_custom_feature(accumulated_data, feature_name, **params)

            new_cols = set(result.columns) - set(accumulated_data.columns)
            if new_cols:
                print(f"   âœ“ {feature_name}: {len(new_cols)}å€‹ã®ç‰¹å¾´é‡è¿½åŠ ")
                print(f"     æ–°è¦åˆ—: {list(new_cols)[:3]}{'...' if len(new_cols) > 3 else ''}")
                accumulated_data = result
            else:
                print(f"   âš  {feature_name}: æ–°ç‰¹å¾´é‡ãªã—")

        except FeatureEngineError as e:
            print(f"   âœ— {feature_name}: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼ - {e}")
        except Exception as e:
            print(f"   âœ— {feature_name}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ - {e}")

    print(f"\n   æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {original_cols}åˆ— â†’ {accumulated_data.shape[1]}åˆ—")

    # 5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    print("\n5. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ...")

    # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆ
    invalid_data = pd.DataFrame({'invalid_col': [1, 2, 3]})

    try:
        result = calculate_custom_feature(invalid_data, "trend_strength")
        if result.equals(invalid_data):
            print("   âœ“ ä¸æ­£ãƒ‡ãƒ¼ã‚¿æ™‚ã®é©åˆ‡ãªå‡¦ç†ï¼ˆå…ƒãƒ‡ãƒ¼ã‚¿è¿”å´ï¼‰")
        else:
            print("   âš  ä¸æ­£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«å•é¡Œã‚ã‚Š")
    except Exception as e:
        print(f"   âœ— ä¸æ­£ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã§ã‚¨ãƒ©ãƒ¼: {e}")

    # æœªçŸ¥ç‰¹å¾´é‡ã§ã®ãƒ†ã‚¹ãƒˆ
    try:
        result = calculate_custom_feature(test_data, "unknown_feature")
        print("   âœ“ æœªçŸ¥ç‰¹å¾´é‡ã®é©åˆ‡ãªå‡¦ç†")
    except Exception as e:
        print(f"   âš  æœªçŸ¥ç‰¹å¾´é‡å‡¦ç†: {e}")

    return accumulated_data


def test_batch_data_fetcher_integration():
    """BatchDataFetcherçµ±åˆãƒ†ã‚¹ãƒˆ"""

    print("\n=== BatchDataFetcherçµ±åˆãƒ†ã‚¹ãƒˆ ===")

    # 1. ç‰¹å¾´é‡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ããƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
    print("1. ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ããƒ‡ãƒ¼ã‚¿ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ...")

    request = DataRequest(
        symbol="TEST_SYMBOL",
        period="60d",
        features=["trend_strength", "momentum", "price_channel"],
        preprocessing=True,
        metadata={
            "trend_strength_params": {"short_period": 5, "long_period": 25},
            "momentum_params": {"periods": [3, 7, 14]},
            "price_channel_params": {"period": 25}
        }
    )

    print(f"   ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆå®Œäº†: {len(request.features)}ç‰¹å¾´é‡ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ä»˜ã")

    # 2. BatchDataFetcheråˆæœŸåŒ–ï¼ˆãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰ï¼‰
    print("\n2. AdvancedBatchDataFetcheråˆæœŸåŒ–...")
    fetcher = AdvancedBatchDataFetcher(
        max_workers=2,
        enable_kafka=False,
        enable_redis=False
    )
    print("   âœ“ ãƒ•ã‚§ãƒƒãƒãƒ£ãƒ¼åˆæœŸåŒ–å®Œäº†")

    # 3. _add_custom_feature ãƒ¡ã‚½ãƒƒãƒ‰ã®ç›´æ¥ãƒ†ã‚¹ãƒˆ
    print("\n3. ã‚«ã‚¹ã‚¿ãƒ ç‰¹å¾´é‡è¿½åŠ ãƒ¡ã‚½ãƒƒãƒ‰ãƒ†ã‚¹ãƒˆ...")

    test_data = create_test_data(30)

    test_cases = [
        ("trend_strength", {"short_period": 8, "long_period": 21}),
        ("momentum", {"periods": [5, 15]}),
        ("price_channel", {"period": 18}),
        ("unknown_feature", {}),  # ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
    ]

    for feature_name, params in test_cases:
        try:
            print(f"   {feature_name}ãƒ†ã‚¹ãƒˆ...")
            original_cols = set(test_data.columns)

            result = fetcher._add_custom_feature(test_data, feature_name, **params)

            new_cols = set(result.columns) - original_cols
            if new_cols:
                print(f"   âœ“ {feature_name}: {len(new_cols)}å€‹è¿½åŠ ")
            elif feature_name == "unknown_feature":
                print(f"   âœ“ {feature_name}: é©åˆ‡ã«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°")
            else:
                print(f"   âš  {feature_name}: æ–°ç‰¹å¾´é‡ãªã—")

        except Exception as e:
            print(f"   âœ— {feature_name}: ã‚¨ãƒ©ãƒ¼ - {e}")

    # 4. ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    fetcher.close()
    print("   âœ“ ãƒªã‚½ãƒ¼ã‚¹è§£æ”¾å®Œäº†")

    return True


def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    print("Issue #575 ä¿®æ­£ãƒ†ã‚¹ãƒˆé–‹å§‹\n")
    print("="*60)

    try:
        # 1. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
        final_data = test_feature_engine_system()

        # 2. BatchDataFetcherçµ±åˆãƒ†ã‚¹ãƒˆ
        integration_success = test_batch_data_fetcher_integration()

        # 3. çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "="*60)
        print("=== ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ ===")
        print(f"âœ“ ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ³ã‚·ã‚¹ãƒ†ãƒ : å‹•ä½œç¢ºèªå®Œäº†")
        print(f"âœ“ æ‹¡å¼µæ€§: ãƒ—ãƒ©ã‚°ã‚¤ãƒ³å¼ç‰¹å¾´é‡è¿½åŠ å¯¾å¿œ")
        print(f"âœ“ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°: å …ç‰¢æ€§å‘ä¸Š")
        print(f"âœ“ BatchDataFetcherçµ±åˆ: æ­£å¸¸å‹•ä½œ")

        if final_data is not None and integration_success:
            print(f"âœ“ æœ€çµ‚ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ: {final_data.shape[1]}ç‰¹å¾´é‡")
            print("\nğŸ‰ Issue #575 ä¿®æ­£ãƒ†ã‚¹ãƒˆ: å…¨ã¦æˆåŠŸ")
            return True
        else:
            print("\nâš ï¸ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆã«å•é¡Œã‚ã‚Š")
            return False

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)