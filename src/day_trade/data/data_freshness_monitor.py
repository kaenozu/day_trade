#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 
Issue #420: ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã¨ãƒ‡ãƒ¼ã‚¿å“è³ªä¿è¨¼ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã®å¼·åŒ–

ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ‡ãƒ¼ã‚¿å“è³ªç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½:
- ãƒ‡ãƒ¼ã‚¿é®®åº¦ç›£è¦–
- æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ
- SLAè¿½è·¡
- ãƒ˜ãƒ«ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- è‡ªå‹•å›å¾©æ©Ÿèƒ½
- ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
"""

import asyncio
import json
import logging
import threading
import time
import warnings
from abc import ABC, abstractmethod
from collections import defaultdict, deque
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd

try:
    from ..utils.data_quality_manager import DataQualityLevel, DataQualityMetrics
    from ..utils.logging_config import get_context_logger
    from ..utils.unified_cache_manager import (
        UnifiedCacheManager,
        generate_unified_cache_key,
    )
except ImportError:
    logging.basicConfig(level=logging.INFO)

    def get_context_logger(name):
        return logging.getLogger(name)

    class UnifiedCacheManager:
        def get(self, key, default=None):
            return default

        def put(self, key, value, **kwargs):
            return True

    def generate_unified_cache_key(*args, **kwargs):
        return f"monitor_key_{hash(str(args))}"

    class DataQualityLevel(Enum):
        EXCELLENT = "excellent"
        GOOD = "good"
        FAIR = "fair"
        POOR = "poor"
        CRITICAL = "critical"


logger = get_context_logger(__name__)

# è­¦å‘ŠæŠ‘åˆ¶
warnings.filterwarnings("ignore", category=FutureWarning)
warnings.filterwarnings("ignore", category=UserWarning)


class MonitorStatus(Enum):
    """ç›£è¦–çŠ¶æ…‹"""

    ACTIVE = "active"
    INACTIVE = "inactive"
    PAUSED = "paused"
    ERROR = "error"
    MAINTENANCE = "maintenance"


class AlertSeverity(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆé‡è¦åº¦"""

    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFO = "info"


class AlertType(Enum):
    """ã‚¢ãƒ©ãƒ¼ãƒˆç¨®åˆ¥"""

    DATA_STALE = "data_stale"
    DATA_MISSING = "data_missing"
    INTEGRITY_VIOLATION = "integrity_violation"
    THRESHOLD_BREACH = "threshold_breach"
    SYSTEM_ERROR = "system_error"
    PERFORMANCE_DEGRADATION = "performance_degradation"
    SLA_VIOLATION = "sla_violation"


class RecoveryAction(Enum):
    """å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""

    RETRY_FETCH = "retry_fetch"
    USE_FALLBACK = "use_fallback"
    NOTIFY_ADMIN = "notify_admin"
    DISABLE_SOURCE = "disable_source"
    ESCALATE = "escalate"
    AUTO_FIX = "auto_fix"


@dataclass
class MonitorRule:
    """ç›£è¦–ãƒ«ãƒ¼ãƒ«å®šç¾©"""

    rule_id: str
    name: str
    description: str
    data_source: str
    rule_type: str  # "freshness", "consistency", "completeness", "accuracy"
    threshold_value: float
    threshold_unit: str  # "minutes", "hours", "percentage", "count"
    severity: AlertSeverity
    enabled: bool = True
    check_interval_seconds: int = 300  # 5åˆ†
    recovery_actions: List[RecoveryAction] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class MonitorAlert:
    """ç›£è¦–ã‚¢ãƒ©ãƒ¼ãƒˆ"""

    alert_id: str
    rule_id: str
    alert_type: AlertType
    severity: AlertSeverity
    title: str
    message: str
    data_source: str
    triggered_at: datetime
    resolved_at: Optional[datetime] = None
    acknowledged_at: Optional[datetime] = None
    acknowledged_by: Optional[str] = None
    recovery_actions_taken: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class DataSourceHealth:
    """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹"""

    source_id: str
    source_type: str  # "api", "database", "file", "stream"
    last_update: datetime
    data_age_minutes: float
    quality_score: float
    availability: float  # 0-1
    error_rate: float  # 0-1
    response_time_ms: float
    health_status: str  # "healthy", "warning", "critical", "unknown"
    consecutive_failures: int = 0
    last_error: Optional[str] = None


@dataclass
class SLAMetrics:
    """SLA ãƒ¡ãƒˆãƒªã‚¯ã‚¹"""

    sla_id: str
    name: str
    target_availability: float  # ç›®æ¨™å¯ç”¨æ€§ (99.9%)
    target_freshness_minutes: int  # ç›®æ¨™ãƒ‡ãƒ¼ã‚¿é®®åº¦ï¼ˆåˆ†ï¼‰
    target_quality_score: float  # ç›®æ¨™å“è³ªã‚¹ã‚³ã‚¢
    current_availability: float
    current_freshness_minutes: float
    current_quality_score: float
    violations_count: int
    measurement_period: str  # "daily", "weekly", "monthly"
    last_violation: Optional[datetime] = None


class MonitorCheck(ABC):
    """æŠ½è±¡ç›£è¦–ãƒã‚§ãƒƒã‚¯ã‚¯ãƒ©ã‚¹"""

    @abstractmethod
    async def execute_check(
        self, data_source: str, data: Any, context: Dict[str, Any]
    ) -> Tuple[bool, Optional[MonitorAlert]]:
        """ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        pass

    @abstractmethod
    def get_check_info(self) -> Dict[str, Any]:
        """ãƒã‚§ãƒƒã‚¯æƒ…å ±å–å¾—"""
        pass


class FreshnessCheck(MonitorCheck):
    """ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒã‚§ãƒƒã‚¯"""

    def __init__(self, threshold_minutes: int = 60):
        self.threshold_minutes = threshold_minutes

    async def execute_check(
        self, data_source: str, data: Any, context: Dict[str, Any]
    ) -> Tuple[bool, Optional[MonitorAlert]]:
        """é®®åº¦ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            current_time = datetime.utcnow()
            data_timestamp = context.get("data_timestamp")

            if not data_timestamp:
                # ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¨å®š
                data_timestamp = self._extract_timestamp(data)

            if not data_timestamp:
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒå–å¾—ã§ããªã„å ´åˆã¯è­¦å‘Š
                return False, MonitorAlert(
                    alert_id=f"freshness_unknown_{int(time.time())}",
                    rule_id="freshness_check",
                    alert_type=AlertType.DATA_STALE,
                    severity=AlertSeverity.MEDIUM,
                    title="ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä¸æ˜",
                    message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¾—ã§ãã¾ã›ã‚“",
                    data_source=data_source,
                    triggered_at=current_time,
                )

            # é®®åº¦è¨ˆç®—
            age_minutes = (current_time - data_timestamp).total_seconds() / 60

            if age_minutes > self.threshold_minutes:
                return False, MonitorAlert(
                    alert_id=f"freshness_violation_{int(time.time())}",
                    rule_id="freshness_check",
                    alert_type=AlertType.DATA_STALE,
                    severity=(
                        AlertSeverity.HIGH
                        if age_minutes > self.threshold_minutes * 2
                        else AlertSeverity.MEDIUM
                    ),
                    title="ãƒ‡ãƒ¼ã‚¿é®®åº¦é•å",
                    message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã®ãƒ‡ãƒ¼ã‚¿ãŒå¤ã™ãã¾ã™ ({age_minutes:.1f}åˆ†å‰)",
                    data_source=data_source,
                    triggered_at=current_time,
                    metadata={
                        "data_age_minutes": age_minutes,
                        "threshold_minutes": self.threshold_minutes,
                        "data_timestamp": data_timestamp.isoformat(),
                    },
                )

            return True, None

        except Exception as e:
            logger.error(f"é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ {data_source}: {e}")
            return False, MonitorAlert(
                alert_id=f"freshness_error_{int(time.time())}",
                rule_id="freshness_check",
                alert_type=AlertType.SYSTEM_ERROR,
                severity=AlertSeverity.HIGH,
                title="é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼",
                message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã®é®®åº¦ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {str(e)}",
                data_source=data_source,
                triggered_at=datetime.utcnow(),
            )

    def _extract_timestamp(self, data: Any) -> Optional[datetime]:
        """ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡º"""
        try:
            if isinstance(data, pd.DataFrame):
                if hasattr(data.index, "max") and hasattr(data.index, "to_pydatetime"):
                    return pd.to_datetime(data.index.max()).to_pydatetime()
                elif "timestamp" in data.columns:
                    return pd.to_datetime(data["timestamp"].max()).to_pydatetime()
                elif "date" in data.columns:
                    return pd.to_datetime(data["date"].max()).to_pydatetime()

            elif isinstance(data, dict):
                if "timestamp" in data:
                    return pd.to_datetime(data["timestamp"]).to_pydatetime()
                elif "date" in data:
                    return pd.to_datetime(data["date"]).to_pydatetime()

            elif isinstance(data, list) and len(data) > 0:
                item = data[0]
                if isinstance(item, dict):
                    if "timestamp" in item:
                        return pd.to_datetime(item["timestamp"]).to_pydatetime()

            return None

        except Exception as e:
            logger.error(f"ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æŠ½å‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return None

    def get_check_info(self) -> Dict[str, Any]:
        return {
            "check_type": "freshness",
            "threshold_minutes": self.threshold_minutes,
            "version": "1.0",
        }


class ConsistencyCheck(MonitorCheck):
    """ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""

    def __init__(self, consistency_rules: Dict[str, Any] = None):
        self.consistency_rules = consistency_rules or {}

    async def execute_check(
        self, data_source: str, data: Any, context: Dict[str, Any]
    ) -> Tuple[bool, Optional[MonitorAlert]]:
        """æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            violations = []

            if isinstance(data, pd.DataFrame):
                violations.extend(self._check_dataframe_consistency(data))
            elif isinstance(data, dict):
                violations.extend(self._check_dict_consistency(data))
            elif isinstance(data, list):
                violations.extend(self._check_list_consistency(data))

            if violations:
                return False, MonitorAlert(
                    alert_id=f"consistency_violation_{int(time.time())}",
                    rule_id="consistency_check",
                    alert_type=AlertType.INTEGRITY_VIOLATION,
                    severity=AlertSeverity.HIGH,
                    title="ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§é•å",
                    message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã§æ•´åˆæ€§é•å: {', '.join(violations)}",
                    data_source=data_source,
                    triggered_at=datetime.utcnow(),
                    metadata={
                        "violations": violations,
                        "violation_count": len(violations),
                    },
                )

            return True, None

        except Exception as e:
            logger.error(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ {data_source}: {e}")
            return False, MonitorAlert(
                alert_id=f"consistency_error_{int(time.time())}",
                rule_id="consistency_check",
                alert_type=AlertType.SYSTEM_ERROR,
                severity=AlertSeverity.HIGH,
                title="æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼",
                message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã§ã‚¨ãƒ©ãƒ¼: {str(e)}",
                data_source=data_source,
                triggered_at=datetime.utcnow(),
            )

    def _check_dataframe_consistency(self, df: pd.DataFrame) -> List[str]:
        """DataFrameã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        violations = []

        try:
            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            if all(col in df.columns for col in ["Open", "High", "Low", "Close"]):
                # ä¾¡æ ¼é †åºãƒã‚§ãƒƒã‚¯
                invalid_prices = df[
                    (df["Low"] > df["High"])
                    | (df["Low"] > df["Open"])
                    | (df["Low"] > df["Close"])
                    | (df["High"] < df["Open"])
                    | (df["High"] < df["Close"])
                ]

                if len(invalid_prices) > 0:
                    violations.append(f"ä¾¡æ ¼é †åºç•°å¸¸: {len(invalid_prices)}ä»¶")

            # è² ã®å€¤ãƒã‚§ãƒƒã‚¯ï¼ˆVolumeç­‰ï¼‰
            if "Volume" in df.columns:
                negative_volume = df[df["Volume"] < 0]
                if len(negative_volume) > 0:
                    violations.append(f"è² ã®å‡ºæ¥é«˜: {len(negative_volume)}ä»¶")

            # é‡è¤‡ãƒ‡ãƒ¼ã‚¿ãƒã‚§ãƒƒã‚¯
            duplicates = df.duplicated().sum()
            if duplicates > 0:
                violations.append(f"é‡è¤‡ãƒ‡ãƒ¼ã‚¿: {duplicates}ä»¶")

            # ç•°å¸¸ãªæ¬ æç‡ãƒã‚§ãƒƒã‚¯
            missing_ratio = df.isnull().sum().sum() / (len(df) * len(df.columns))
            if missing_ratio > 0.5:
                violations.append(f"é«˜ã„æ¬ æç‡: {missing_ratio:.2%}")

        except Exception as e:
            violations.append(f"æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return violations

    def _check_dict_consistency(self, data: Dict[str, Any]) -> List[str]:
        """è¾æ›¸ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        violations = []

        try:
            # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§
            if "positive_ratio" in data and "negative_ratio" in data and "neutral_ratio" in data:
                total_ratio = (
                    data["positive_ratio"] + data["negative_ratio"] + data["neutral_ratio"]
                )
                if abs(total_ratio - 1.0) > 0.01:  # è¨±å®¹èª¤å·®1%
                    violations.append(f"ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆæ¯”ç‡åˆè¨ˆç•°å¸¸: {total_ratio:.3f}")

            # ç¯„å›²ãƒã‚§ãƒƒã‚¯
            range_checks = {
                "overall_sentiment": (-1.0, 1.0),
                "positive_ratio": (0.0, 1.0),
                "negative_ratio": (0.0, 1.0),
                "interest_rate": (-10.0, 50.0),  # é‡‘åˆ©ç¯„å›²
                "inflation_rate": (-5.0, 30.0),  # ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ç¯„å›²
            }

            for field, (min_val, max_val) in range_checks.items():
                if field in data and isinstance(data[field], (int, float)):
                    value = data[field]
                    if not (min_val <= value <= max_val):
                        violations.append(f"{field}ç¯„å›²å¤–: {value} (ç¯„å›²: {min_val}-{max_val})")

        except Exception as e:
            violations.append(f"è¾æ›¸æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return violations

    def _check_list_consistency(self, data: List[Any]) -> List[str]:
        """ãƒªã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯"""
        violations = []

        try:
            if not data:
                violations.append("ç©ºã®ãƒªã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿")
                return violations

            # é‡è¤‡ãƒã‚§ãƒƒã‚¯ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿æƒ³å®šï¼‰
            if isinstance(data[0], dict) and "title" in data[0]:
                titles = [item.get("title", "") for item in data]
                unique_titles = set(titles)
                if len(titles) != len(unique_titles):
                    duplicate_count = len(titles) - len(unique_titles)
                    violations.append(f"é‡è¤‡ã‚¿ã‚¤ãƒˆãƒ«: {duplicate_count}ä»¶")

        except Exception as e:
            violations.append(f"ãƒªã‚¹ãƒˆæ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")

        return violations

    def get_check_info(self) -> Dict[str, Any]:
        return {
            "check_type": "consistency",
            "rules": self.consistency_rules,
            "version": "1.0",
        }


class DataFreshnessMonitor:
    """ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(
        self,
        storage_path: str = "data/monitoring",
        enable_cache: bool = True,
        alert_retention_days: int = 30,
        check_interval_seconds: int = 300,
    ):
        self.storage_path = Path(storage_path)
        self.enable_cache = enable_cache
        self.alert_retention_days = alert_retention_days
        self.check_interval_seconds = check_interval_seconds

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªåˆæœŸåŒ–
        self.storage_path.mkdir(parents=True, exist_ok=True)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
        if enable_cache:
            try:
                self.cache_manager = UnifiedCacheManager(
                    l1_memory_mb=32, l2_memory_mb=128, l3_disk_mb=256
                )
                logger.info("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–å®Œäº†")
            except Exception as e:
                logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆæœŸåŒ–å¤±æ•—: {e}")
                self.cache_manager = None
        else:
            self.cache_manager = None

        # ç›£è¦–çŠ¶æ…‹ç®¡ç†
        self.monitor_status = MonitorStatus.INACTIVE
        self.monitor_thread: Optional[threading.Thread] = None
        self.stop_event = threading.Event()

        # ç›£è¦–ãƒ«ãƒ¼ãƒ«ç®¡ç†
        self.monitor_rules: Dict[str, MonitorRule] = {}

        # ãƒã‚§ãƒƒã‚¯å®Ÿè£…
        self.checks: Dict[str, MonitorCheck] = {
            "freshness": FreshnessCheck(threshold_minutes=60),
            "consistency": ConsistencyCheck(),
        }

        # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ç®¡ç†
        self.data_source_health: Dict[str, DataSourceHealth] = {}

        # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
        self.active_alerts: Dict[str, MonitorAlert] = {}
        self.alert_history: deque = deque(maxlen=1000)

        # SLAç®¡ç†
        self.sla_metrics: Dict[str, SLAMetrics] = {}

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç®¡ç†
        self.metrics_history = defaultdict(lambda: deque(maxlen=1000))

        # ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.alert_callbacks: List[Callable[[MonitorAlert], None]] = []

        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self._setup_default_rules()
        self._setup_default_sla()

        logger.info("ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
        logger.info(f"  - ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‘ã‚¹: {self.storage_path}")
        logger.info(f"  - ãƒã‚§ãƒƒã‚¯é–“éš”: {check_interval_seconds}ç§’")
        logger.info(f"  - ã‚¢ãƒ©ãƒ¼ãƒˆä¿æŒæœŸé–“: {alert_retention_days}æ—¥")

    def _setup_default_rules(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç›£è¦–ãƒ«ãƒ¼ãƒ«è¨­å®š"""
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ«ãƒ¼ãƒ«
        price_freshness_rule = MonitorRule(
            rule_id="price_freshness",
            name="ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿é®®åº¦ç›£è¦–",
            description="ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ãŒ1æ™‚é–“ä»¥å†…ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯",
            data_source="price_data",
            rule_type="freshness",
            threshold_value=60,
            threshold_unit="minutes",
            severity=AlertSeverity.HIGH,
            check_interval_seconds=300,
            recovery_actions=[RecoveryAction.RETRY_FETCH, RecoveryAction.USE_FALLBACK],
        )
        self.monitor_rules[price_freshness_rule.rule_id] = price_freshness_rule

        # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ«ãƒ¼ãƒ«
        news_freshness_rule = MonitorRule(
            rule_id="news_freshness",
            name="ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿é®®åº¦ç›£è¦–",
            description="ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒ4æ™‚é–“ä»¥å†…ã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯",
            data_source="news_data",
            rule_type="freshness",
            threshold_value=240,
            threshold_unit="minutes",
            severity=AlertSeverity.MEDIUM,
            check_interval_seconds=600,
        )
        self.monitor_rules[news_freshness_rule.rule_id] = news_freshness_rule

        # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ«ãƒ¼ãƒ«
        consistency_rule = MonitorRule(
            rule_id="data_consistency",
            name="ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç›£è¦–",
            description="ãƒ‡ãƒ¼ã‚¿ã®è«–ç†çš„æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯",
            data_source="all",
            rule_type="consistency",
            threshold_value=0,
            threshold_unit="violations",
            severity=AlertSeverity.HIGH,
            check_interval_seconds=300,
            recovery_actions=[RecoveryAction.AUTO_FIX, RecoveryAction.NOTIFY_ADMIN],
        )
        self.monitor_rules[consistency_rule.rule_id] = consistency_rule

    def _setup_default_sla(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆSLAè¨­å®š"""
        # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿SLA
        price_sla = SLAMetrics(
            sla_id="price_data_sla",
            name="ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿SLA",
            target_availability=0.999,  # 99.9%
            target_freshness_minutes=60,
            target_quality_score=0.95,
            current_availability=1.0,
            current_freshness_minutes=0.0,
            current_quality_score=1.0,
            violations_count=0,
            measurement_period="daily",
        )
        self.sla_metrics[price_sla.sla_id] = price_sla

    async def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""
        if self.monitor_status == MonitorStatus.ACTIVE:
            logger.warning("ç›£è¦–ã¯æ—¢ã«ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã§ã™")
            return

        logger.info("ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–é–‹å§‹")

        self.monitor_status = MonitorStatus.ACTIVE
        self.stop_event.clear()

        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        self.monitor_thread = threading.Thread(
            target=self._monitor_loop, name="DataFreshnessMonitor", daemon=True
        )
        self.monitor_thread.start()

        logger.info("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹å®Œäº†")

    async def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""
        if self.monitor_status != MonitorStatus.ACTIVE:
            logger.warning("ç›£è¦–ã¯æ—¢ã«åœæ­¢ã—ã¦ã„ã¾ã™")
            return

        logger.info("ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–åœæ­¢ä¸­...")

        self.monitor_status = MonitorStatus.INACTIVE
        self.stop_event.set()

        # ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†å¾…æ©Ÿ
        if self.monitor_thread and self.monitor_thread.is_alive():
            self.monitor_thread.join(timeout=10)

        logger.info("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åœæ­¢å®Œäº†")

    def _monitor_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å®Ÿè¡Œï¼‰"""
        logger.info("ç›£è¦–ãƒ«ãƒ¼ãƒ—é–‹å§‹")

        while not self.stop_event.is_set():
            try:
                # å„ç›£è¦–ãƒ«ãƒ¼ãƒ«ã®å®Ÿè¡Œæ™‚é–“ã‚’ãƒã‚§ãƒƒã‚¯
                current_time = time.time()

                for rule_id, rule in self.monitor_rules.items():
                    if not rule.enabled:
                        continue

                    # å‰å›ãƒã‚§ãƒƒã‚¯ã‹ã‚‰ã®çµŒéæ™‚é–“ç¢ºèª
                    last_check_key = f"last_check_{rule_id}"
                    last_check_time = getattr(self, last_check_key, 0)

                    if current_time - last_check_time >= rule.check_interval_seconds:
                        # éåŒæœŸã§ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
                        asyncio.run_coroutine_threadsafe(
                            self._execute_rule_check(rule), asyncio.new_event_loop()
                        )
                        setattr(self, last_check_key, current_time)

                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°
                self._update_system_metrics()

                # ã‚¢ãƒ©ãƒ¼ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                self._cleanup_expired_alerts()

                # çŸ­ã„é–“éš”ã§å†ãƒã‚§ãƒƒã‚¯
                self.stop_event.wait(30)  # 30ç§’é–“éš”

            except Exception as e:
                logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                self.stop_event.wait(60)  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯1åˆ†å¾…æ©Ÿ

        logger.info("ç›£è¦–ãƒ«ãƒ¼ãƒ—çµ‚äº†")

    async def _execute_rule_check(self, rule: MonitorRule):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ"""
        try:
            logger.debug(f"ç›£è¦–ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ: {rule.rule_id}")

            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å›ºæœ‰ã®ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            if rule.data_source != "all":
                await self._check_data_source(rule, rule.data_source)
            else:
                # å…¨ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
                for source_id in self.data_source_health.keys():
                    await self._check_data_source(rule, source_id)

        except Exception as e:
            logger.error(f"ãƒ«ãƒ¼ãƒ«ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ {rule.rule_id}: {e}")

    async def _check_data_source(self, rule: MonitorRule, data_source: str):
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹å€‹åˆ¥ãƒã‚§ãƒƒã‚¯"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ¨¡æ“¬ï¼‰
            data, context = await self._fetch_data_for_monitoring(data_source)

            if data is None:
                # ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—
                alert = MonitorAlert(
                    alert_id=f"data_missing_{data_source}_{int(time.time())}",
                    rule_id=rule.rule_id,
                    alert_type=AlertType.DATA_MISSING,
                    severity=AlertSeverity.HIGH,
                    title="ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—",
                    message=f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ {data_source} ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“",
                    data_source=data_source,
                    triggered_at=datetime.utcnow(),
                )
                await self._handle_alert(alert)
                return

            # é©åˆ‡ãªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            check_passed = True
            generated_alert = None

            if rule.rule_type == "freshness" and "freshness" in self.checks:
                check_passed, generated_alert = await self.checks["freshness"].execute_check(
                    data_source, data, context
                )
            elif rule.rule_type == "consistency" and "consistency" in self.checks:
                check_passed, generated_alert = await self.checks["consistency"].execute_check(
                    data_source, data, context
                )

            # ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†
            if not check_passed and generated_alert:
                await self._handle_alert(generated_alert)

            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹æ›´æ–°
            await self._update_data_source_health(data_source, check_passed, context)

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼ {data_source}: {e}")

    async def _fetch_data_for_monitoring(self, data_source: str) -> Tuple[Any, Dict[str, Any]]:
        """ç›£è¦–ç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ¨¡æ“¬å®Ÿè£…ï¼‰"""
        try:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            # ã“ã“ã§ã¯æ¨¡æ“¬ãƒ‡ãƒ¼ã‚¿ã‚’è¿”ã™

            context = {
                "data_timestamp": datetime.utcnow() - timedelta(minutes=30),
                "source_type": "api",
                "response_time_ms": 150,
            }

            if data_source == "price_data":
                data = pd.DataFrame(
                    {
                        "Open": [2500, 2520],
                        "High": [2550, 2540],
                        "Low": [2480, 2500],
                        "Close": [2530, 2485],
                        "Volume": [1500000, 1200000],
                    },
                    index=pd.date_range(
                        datetime.utcnow() - timedelta(hours=2), periods=2, freq="H"
                    ),
                )

            elif data_source == "news_data":
                data = [
                    {
                        "title": "Test News 1",
                        "timestamp": datetime.utcnow() - timedelta(hours=1),
                        "summary": "Test summary 1",
                    },
                    {
                        "title": "Test News 2",
                        "timestamp": datetime.utcnow() - timedelta(minutes=30),
                        "summary": "Test summary 2",
                    },
                ]

            else:
                data = {"test_value": 123, "timestamp": datetime.utcnow()}

            return data, context

        except Exception as e:
            logger.error(f"ç›£è¦–ç”¨ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ {data_source}: {e}")
            return None, {}

    async def _handle_alert(self, alert: MonitorAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆå‡¦ç†"""
        logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿ: {alert.title} - {alert.message}")

        # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†
        self.active_alerts[alert.alert_id] = alert

        # ã‚¢ãƒ©ãƒ¼ãƒˆå±¥æ­´ä¿å­˜
        self.alert_history.append(alert)

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè¡Œ
        for callback in self.alert_callbacks:
            try:
                callback(alert)
            except Exception as e:
                logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")

        # SLAæ›´æ–°
        await self._update_sla_violations(alert)

        # ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ï¼ˆå®Ÿè£…ã¯ç’°å¢ƒã«ä¾å­˜ï¼‰
        await self._send_alert_notification(alert)

        # è‡ªå‹•å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        await self._execute_recovery_actions(alert)

        # ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ä¿å­˜
        await self._save_alert_to_file(alert)

    async def _update_data_source_health(
        self, data_source: str, check_passed: bool, context: Dict[str, Any]
    ):
        """ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹æ›´æ–°"""
        try:
            current_time = datetime.utcnow()

            if data_source not in self.data_source_health:
                # æ–°è¦ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹
                self.data_source_health[data_source] = DataSourceHealth(
                    source_id=data_source,
                    source_type=context.get("source_type", "unknown"),
                    last_update=current_time,
                    data_age_minutes=0.0,
                    quality_score=1.0 if check_passed else 0.0,
                    availability=1.0,
                    error_rate=0.0,
                    response_time_ms=context.get("response_time_ms", 0),
                    health_status="healthy" if check_passed else "warning",
                    consecutive_failures=0 if check_passed else 1,
                )
            else:
                # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ›´æ–°
                health = self.data_source_health[data_source]
                health.last_update = current_time

                # ãƒ‡ãƒ¼ã‚¿å¹´é½¢è¨ˆç®—
                data_timestamp = context.get("data_timestamp")
                if data_timestamp:
                    health.data_age_minutes = (current_time - data_timestamp).total_seconds() / 60

                # å“è³ªã‚¹ã‚³ã‚¢æ›´æ–°ï¼ˆç§»å‹•å¹³å‡ï¼‰
                if check_passed:
                    health.quality_score = health.quality_score * 0.9 + 0.1
                    health.consecutive_failures = 0
                else:
                    health.quality_score = health.quality_score * 0.9
                    health.consecutive_failures += 1

                # å¯ç”¨æ€§æ›´æ–°
                if check_passed:
                    health.availability = min(1.0, health.availability + 0.01)
                else:
                    health.availability = max(0.0, health.availability - 0.05)

                # ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“æ›´æ–°
                response_time = context.get("response_time_ms", 0)
                if response_time > 0:
                    health.response_time_ms = health.response_time_ms * 0.8 + response_time * 0.2

                # ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹åˆ¤å®š
                if health.consecutive_failures >= 5:
                    health.health_status = "critical"
                elif health.consecutive_failures >= 2:
                    health.health_status = "warning"
                elif health.quality_score >= 0.9:
                    health.health_status = "healthy"
                else:
                    health.health_status = "warning"

        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼ {data_source}: {e}")

    async def _update_sla_violations(self, alert: MonitorAlert):
        """SLAé•åæ›´æ–°"""
        try:
            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã«å¯¾å¿œã™ã‚‹SLAã‚’æ¢ã™
            for sla_id, sla in self.sla_metrics.items():
                if alert.data_source in sla_id or "all" in sla_id:
                    sla.violations_count += 1
                    sla.last_violation = alert.triggered_at

                    # å¯ç”¨æ€§ã®æ›´æ–°
                    if alert.alert_type in [
                        AlertType.DATA_MISSING,
                        AlertType.SYSTEM_ERROR,
                    ]:
                        sla.current_availability = max(0.0, sla.current_availability - 0.001)

                    # é®®åº¦ã®æ›´æ–°
                    if (
                        alert.alert_type == AlertType.DATA_STALE
                        and "data_age_minutes" in alert.metadata
                    ):
                        sla.current_freshness_minutes = alert.metadata["data_age_minutes"]

                    break

        except Exception as e:
            logger.error(f"SLAé•åæ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    async def _send_alert_notification(self, alert: MonitorAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥é€ä¿¡ï¼ˆå®Ÿè£…ã¯ç’°å¢ƒä¾å­˜ï¼‰"""
        try:
            # ã“ã“ã§ã¯é€šçŸ¥ã®æ¨¡æ“¬å®Ÿè£…
            notification_message = {
                "alert_id": alert.alert_id,
                "severity": alert.severity.value,
                "title": alert.title,
                "message": alert.message,
                "data_source": alert.data_source,
                "timestamp": alert.triggered_at.isoformat(),
            }

            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ¡ãƒ¼ãƒ«ã€Slackã€Teamsç­‰ã¸ã®é€šçŸ¥
            logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥: {json.dumps(notification_message, ensure_ascii=False)}")

        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

    async def _execute_recovery_actions(self, alert: MonitorAlert):
        """å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        try:
            rule = self.monitor_rules.get(alert.rule_id)
            if not rule or not rule.recovery_actions:
                return

            executed_actions = []

            for action in rule.recovery_actions:
                try:
                    if action == RecoveryAction.RETRY_FETCH:
                        # ãƒ‡ãƒ¼ã‚¿å†å–å¾—è©¦è¡Œ
                        logger.info(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: ãƒ‡ãƒ¼ã‚¿å†å–å¾— ({alert.data_source})")
                        executed_actions.append("retry_fetch")

                    elif action == RecoveryAction.USE_FALLBACK:
                        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
                        logger.info(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä½¿ç”¨ ({alert.data_source})")
                        executed_actions.append("use_fallback")

                    elif action == RecoveryAction.AUTO_FIX:
                        # è‡ªå‹•ä¿®æ­£å®Ÿè¡Œ
                        logger.info(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: è‡ªå‹•ä¿®æ­£ ({alert.data_source})")
                        executed_actions.append("auto_fix")

                    elif action == RecoveryAction.NOTIFY_ADMIN:
                        # ç®¡ç†è€…é€šçŸ¥
                        logger.info(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ: ç®¡ç†è€…é€šçŸ¥ ({alert.data_source})")
                        executed_actions.append("notify_admin")

                except Exception as e:
                    logger.error(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ {action}: {e}")

            alert.recovery_actions_taken = executed_actions

        except Exception as e:
            logger.error(f"å›å¾©ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")

    async def _save_alert_to_file(self, alert: MonitorAlert):
        """ã‚¢ãƒ©ãƒ¼ãƒˆæƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜"""
        try:
            alert_file = self.storage_path / f"alert_{alert.alert_id}.json"

            alert_data = {
                "alert_id": alert.alert_id,
                "rule_id": alert.rule_id,
                "alert_type": alert.alert_type.value,
                "severity": alert.severity.value,
                "title": alert.title,
                "message": alert.message,
                "data_source": alert.data_source,
                "triggered_at": alert.triggered_at.isoformat(),
                "resolved_at": alert.resolved_at.isoformat() if alert.resolved_at else None,
                "acknowledged_at": (
                    alert.acknowledged_at.isoformat() if alert.acknowledged_at else None
                ),
                "acknowledged_by": alert.acknowledged_by,
                "recovery_actions_taken": alert.recovery_actions_taken,
                "metadata": alert.metadata,
            }

            with open(alert_file, "w", encoding="utf-8") as f:
                json.dump(alert_data, f, indent=2, ensure_ascii=False)

        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def _update_system_metrics(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°"""
        try:
            current_time = datetime.utcnow()

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆæ•°
            self.metrics_history["active_alerts_count"].append(
                {"timestamp": current_time, "value": len(self.active_alerts)}
            )

            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹çµ±è¨ˆ
            healthy_sources = sum(
                1
                for health in self.data_source_health.values()
                if health.health_status == "healthy"
            )
            total_sources = len(self.data_source_health)

            if total_sources > 0:
                health_percentage = healthy_sources / total_sources * 100
                self.metrics_history["system_health_percentage"].append(
                    {"timestamp": current_time, "value": health_percentage}
                )

            # å¹³å‡å“è³ªã‚¹ã‚³ã‚¢
            if self.data_source_health:
                avg_quality = np.mean(
                    [health.quality_score for health in self.data_source_health.values()]
                )
                self.metrics_history["avg_quality_score"].append(
                    {"timestamp": current_time, "value": avg_quality}
                )

        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def _cleanup_expired_alerts(self):
        """æœŸé™åˆ‡ã‚Œã‚¢ãƒ©ãƒ¼ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            current_time = datetime.utcnow()
            retention_threshold = current_time - timedelta(days=self.alert_retention_days)

            # æœŸé™åˆ‡ã‚Œã‚¢ãƒ©ãƒ¼ãƒˆç‰¹å®š
            expired_alert_ids = []
            for alert_id, alert in self.active_alerts.items():
                if alert.triggered_at < retention_threshold:
                    expired_alert_ids.append(alert_id)

            # æœŸé™åˆ‡ã‚Œã‚¢ãƒ©ãƒ¼ãƒˆå‰Šé™¤
            for alert_id in expired_alert_ids:
                del self.active_alerts[alert_id]

            if expired_alert_ids:
                logger.info(f"æœŸé™åˆ‡ã‚Œã‚¢ãƒ©ãƒ¼ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {len(expired_alert_ids)}ä»¶")

        except Exception as e:
            logger.error(f"ã‚¢ãƒ©ãƒ¼ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")

    def add_alert_callback(self, callback: Callable[[MonitorAlert], None]):
        """ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ """
        self.alert_callbacks.append(callback)

    def add_monitor_rule(self, rule: MonitorRule):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ«è¿½åŠ """
        self.monitor_rules[rule.rule_id] = rule
        logger.info(f"ç›£è¦–ãƒ«ãƒ¼ãƒ«è¿½åŠ : {rule.rule_id}")

    def remove_monitor_rule(self, rule_id: str):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ«å‰Šé™¤"""
        if rule_id in self.monitor_rules:
            del self.monitor_rules[rule_id]
            logger.info(f"ç›£è¦–ãƒ«ãƒ¼ãƒ«å‰Šé™¤: {rule_id}")

    def get_system_dashboard(self) -> Dict[str, Any]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±å–å¾—"""
        try:
            current_time = datetime.utcnow()

            # ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆ
            alert_stats = {
                "total_active": len(self.active_alerts),
                "by_severity": defaultdict(int),
                "by_type": defaultdict(int),
            }

            for alert in self.active_alerts.values():
                alert_stats["by_severity"][alert.severity.value] += 1
                alert_stats["by_type"][alert.alert_type.value] += 1

            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹çµ±è¨ˆ
            health_stats = {
                "total_sources": len(self.data_source_health),
                "by_status": defaultdict(int),
                "avg_quality_score": 0.0,
                "avg_availability": 0.0,
            }

            if self.data_source_health:
                for health in self.data_source_health.values():
                    health_stats["by_status"][health.health_status] += 1

                health_stats["avg_quality_score"] = np.mean(
                    [health.quality_score for health in self.data_source_health.values()]
                )
                health_stats["avg_availability"] = np.mean(
                    [health.availability for health in self.data_source_health.values()]
                )

            # SLAçµ±è¨ˆ
            sla_stats = {}
            for sla_id, sla in self.sla_metrics.items():
                sla_stats[sla_id] = {
                    "name": sla.name,
                    "availability": sla.current_availability,
                    "freshness_minutes": sla.current_freshness_minutes,
                    "quality_score": sla.current_quality_score,
                    "violations_count": sla.violations_count,
                    "target_availability": sla.target_availability,
                    "target_freshness": sla.target_freshness_minutes,
                    "target_quality": sla.target_quality_score,
                }

            # æœ€è¿‘ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            recent_metrics = {}
            for metric_name, metric_history in self.metrics_history.items():
                if metric_history:
                    latest_metric = metric_history[-1]
                    recent_metrics[metric_name] = latest_metric["value"]

            return {
                "generated_at": current_time.isoformat(),
                "monitor_status": self.monitor_status.value,
                "uptime_minutes": (
                    current_time - getattr(self, "_start_time", current_time)
                ).total_seconds()
                / 60,
                "alert_statistics": dict(alert_stats),
                "health_statistics": dict(health_stats),
                "sla_metrics": sla_stats,
                "recent_metrics": recent_metrics,
                "system_configuration": {
                    "check_interval_seconds": self.check_interval_seconds,
                    "alert_retention_days": self.alert_retention_days,
                    "total_rules": len(self.monitor_rules),
                    "active_rules": sum(1 for rule in self.monitor_rules.values() if rule.enabled),
                },
            }

        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}

    async def acknowledge_alert(self, alert_id: str, acknowledged_by: str):
        """ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.acknowledged_at = datetime.utcnow()
            alert.acknowledged_by = acknowledged_by

            logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª: {alert_id} by {acknowledged_by}")
        else:
            logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {alert_id}")

    async def resolve_alert(self, alert_id: str, resolved_by: str = "system"):
        """ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±º"""
        if alert_id in self.active_alerts:
            alert = self.active_alerts[alert_id]
            alert.resolved_at = datetime.utcnow()

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆã‹ã‚‰å‰Šé™¤
            del self.active_alerts[alert_id]

            logger.info(f"ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±º: {alert_id} by {resolved_by}")
        else:
            logger.warning(f"ã‚¢ãƒ©ãƒ¼ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {alert_id}")

    async def cleanup(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        logger.info("ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—é–‹å§‹")

        # ç›£è¦–åœæ­¢
        await self.stop_monitoring()

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´ã‚¯ãƒªã‚¢
        self.metrics_history.clear()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
        if self.cache_manager:
            # å…·ä½“çš„ãªã‚¯ãƒªã‚¢å‡¦ç†ã¯å®Ÿè£…ã«ä¾å­˜
            pass

        logger.info("ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†")


# Factory function
def create_data_freshness_monitor(
    storage_path: str = "data/monitoring",
    enable_cache: bool = True,
    alert_retention_days: int = 30,
    check_interval_seconds: int = 300,
) -> DataFreshnessMonitor:
    """ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ä½œæˆ"""
    return DataFreshnessMonitor(
        storage_path=storage_path,
        enable_cache=enable_cache,
        alert_retention_days=alert_retention_days,
        check_interval_seconds=check_interval_seconds,
    )


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    async def test_data_freshness_monitor():
        print("=== Issue #420 ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")

        try:
            # ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            monitor = create_data_freshness_monitor(
                storage_path="test_monitoring",
                enable_cache=True,
                alert_retention_days=7,
                check_interval_seconds=60,
            )

            print("\n1. ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")
            print(f"   ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ‘ã‚¹: {monitor.storage_path}")
            print(f"   ãƒã‚§ãƒƒã‚¯é–“éš”: {monitor.check_interval_seconds}ç§’")
            print(f"   ç›£è¦–ãƒ«ãƒ¼ãƒ«æ•°: {len(monitor.monitor_rules)}")

            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ç™»éŒ²
            def alert_handler(alert: MonitorAlert):
                print(f"   ğŸ“¢ ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯: {alert.title}")

            monitor.add_alert_callback(alert_handler)

            # ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹åˆæœŸåŒ–ï¼ˆæ¨¡æ“¬ï¼‰
            print("\n2. ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹åˆæœŸåŒ–...")
            monitor.data_source_health["price_data"] = DataSourceHealth(
                source_id="price_data",
                source_type="api",
                last_update=datetime.utcnow() - timedelta(minutes=45),
                data_age_minutes=45.0,
                quality_score=0.95,
                availability=0.99,
                error_rate=0.01,
                response_time_ms=120,
                health_status="healthy",
            )
            print("   ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ç™»éŒ²å®Œäº†")

            # ç›£è¦–é–‹å§‹
            print("\n3. ç›£è¦–é–‹å§‹...")
            await monitor.start_monitoring()
            print(f"   ç›£è¦–çŠ¶æ…‹: {monitor.monitor_status.value}")

            # æ‰‹å‹•ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            print("\n4. æ‰‹å‹•ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ...")

            # é®®åº¦ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            freshness_check = monitor.checks["freshness"]
            test_data = pd.DataFrame(
                {
                    "Open": [2500],
                    "High": [2550],
                    "Low": [2480],
                    "Close": [2530],
                    "Volume": [1000000],
                },
                index=[datetime.utcnow() - timedelta(hours=2)],
            )  # 2æ™‚é–“å‰ã®ãƒ‡ãƒ¼ã‚¿

            test_context = {"data_timestamp": datetime.utcnow() - timedelta(hours=2)}

            check_passed, alert = await freshness_check.execute_check(
                "test_source", test_data, test_context
            )
            print(f"   é®®åº¦ãƒã‚§ãƒƒã‚¯çµæœ: {'åˆæ ¼' if check_passed else 'å¤±æ•—'}")
            if alert:
                print(f"   ç”Ÿæˆã‚¢ãƒ©ãƒ¼ãƒˆ: {alert.title}")

            # æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ
            consistency_check = monitor.checks["consistency"]

            # ä¸æ­£ãªä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            invalid_data = pd.DataFrame(
                {
                    "Open": [2500],
                    "High": [2400],
                    "Low": [2600],
                    "Close": [2530],
                    "Volume": [-1000],  # High < Low, è² ã®Volume
                }
            )

            check_passed, alert = await consistency_check.execute_check(
                "test_source", invalid_data, {}
            )
            print(f"   æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯çµæœ: {'åˆæ ¼' if check_passed else 'å¤±æ•—'}")
            if alert:
                print(f"   ç”Ÿæˆã‚¢ãƒ©ãƒ¼ãƒˆ: {alert.title}")

            # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰æƒ…å ±å–å¾—
            print("\n5. ã‚·ã‚¹ãƒ†ãƒ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰...")
            dashboard = monitor.get_system_dashboard()

            print(f"   ç›£è¦–çŠ¶æ…‹: {dashboard['monitor_status']}")
            print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {dashboard['alert_statistics']['total_active']}ä»¶")
            print(f"   ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æ•°: {dashboard['health_statistics']['total_sources']}")
            print(f"   å¹³å‡å“è³ªã‚¹ã‚³ã‚¢: {dashboard['health_statistics']['avg_quality_score']:.3f}")
            print(f"   å¹³å‡å¯ç”¨æ€§: {dashboard['health_statistics']['avg_availability']:.3f}")

            # SLAçŠ¶æ³
            print("\n   SLAçŠ¶æ³:")
            for sla_id, sla_info in dashboard["sla_metrics"].items():
                print(
                    f"     {sla_info['name']}: å¯ç”¨æ€§ {sla_info['availability']:.3f} "
                    f"(ç›®æ¨™: {sla_info['target_availability']:.3f})"
                )

            # ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆ
            print("\n6. ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†ãƒ†ã‚¹ãƒˆ...")
            if monitor.active_alerts:
                first_alert_id = list(monitor.active_alerts.keys())[0]
                print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª: {first_alert_id}")
                await monitor.acknowledge_alert(first_alert_id, "test_user")
                await monitor.resolve_alert(first_alert_id, "test_user")
                print("   ã‚¢ãƒ©ãƒ¼ãƒˆè§£æ±ºå®Œäº†")

            # ã—ã°ã‚‰ãç›£è¦–ç¶™ç¶š
            print("\n7. ç›£è¦–ç¶™ç¶šãƒ†ã‚¹ãƒˆï¼ˆ10ç§’é–“ï¼‰...")
            await asyncio.sleep(10)

            # æœ€çµ‚ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ç¢ºèª
            final_dashboard = monitor.get_system_dashboard()
            print(
                f"   æœ€çµ‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {final_dashboard['alert_statistics']['total_active']}"
            )

            # ç›£è¦–åœæ­¢
            print("\n8. ç›£è¦–åœæ­¢...")
            await monitor.stop_monitoring()
            print(f"   ç›£è¦–çŠ¶æ…‹: {monitor.monitor_status.value}")

            # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            await monitor.cleanup()

            print("\nâœ… Issue #420 ãƒ‡ãƒ¼ã‚¿é®®åº¦ãƒ»æ•´åˆæ€§ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Œäº†")

        except Exception as e:
            print(f"âŒ ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            import traceback

            traceback.print_exc()

    asyncio.run(test_data_freshness_monitor())
