#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Data Quality Manager - ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

Issue #810å¯¾å¿œï¼šãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã®å®Ÿè£…
ãƒ‡ãƒ¼ã‚¿ã®å®Œæ•´æ€§ã€ä¸€è²«æ€§ã€é®®åº¦ã‚’åŒ…æ‹¬çš„ã«ç®¡ç†
"""

import asyncio
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union
from dataclasses import dataclass, field
from enum import Enum
import json
import sqlite3
from pathlib import Path
import time

# Windowsç’°å¢ƒã§ã®æ–‡å­—åŒ–ã‘å¯¾ç­–
import sys
import os
os.environ['PYTHONIOENCODING'] = 'utf-8'

if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)

class DataQualityLevel(Enum):
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒ™ãƒ«"""
    EXCELLENT = "excellent"  # 95-100%
    GOOD = "good"           # 85-94%
    ACCEPTABLE = "acceptable"  # 70-84%
    POOR = "poor"           # 50-69%
    CRITICAL = "critical"   # 0-49%

class QualityCheckType(Enum):
    """å“è³ªãƒã‚§ãƒƒã‚¯ã‚¿ã‚¤ãƒ—"""
    COMPLETENESS = "completeness"     # å®Œæ•´æ€§
    CONSISTENCY = "consistency"       # ä¸€è²«æ€§
    FRESHNESS = "freshness"          # é®®åº¦
    ACCURACY = "accuracy"            # æ­£ç¢ºæ€§
    VALIDITY = "validity"            # æœ‰åŠ¹æ€§
    UNIQUENESS = "uniqueness"        # ä¸€æ„æ€§

@dataclass
class QualityCheckResult:
    """å“è³ªãƒã‚§ãƒƒã‚¯çµæœ"""
    check_type: QualityCheckType
    score: float  # 0-100
    issues: List[str]
    details: Dict[str, Any]
    timestamp: datetime

@dataclass
class DataQualityReport:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ¬ãƒãƒ¼ãƒˆ"""
    symbol: str
    timestamp: datetime
    overall_score: float
    quality_level: DataQualityLevel
    check_results: List[QualityCheckResult]
    recommendations: List[str]
    data_points: int
    missing_data_ratio: float

class DataQualityChecker:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒã‚§ãƒƒã‚«ãƒ¼"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)

    def check_completeness(self, data: pd.DataFrame) -> QualityCheckResult:
        """å®Œæ•´æ€§ãƒã‚§ãƒƒã‚¯"""

        issues = []
        details = {}

        if data is None or len(data) == 0:
            return QualityCheckResult(
                check_type=QualityCheckType.COMPLETENESS,
                score=0.0,
                issues=["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"],
                details={"total_records": 0},
                timestamp=datetime.now()
            )

        # å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
        required_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        missing_columns = [col for col in required_columns if col not in data.columns]

        if missing_columns:
            issues.append(f"å¿…é ˆã‚«ãƒ©ãƒ æ¬ æ: {missing_columns}")

        # æ¬ æå€¤ãƒã‚§ãƒƒã‚¯
        total_cells = data.size
        missing_cells = data.isnull().sum().sum()
        missing_ratio = missing_cells / total_cells if total_cells > 0 else 1.0

        details = {
            "total_records": len(data),
            "total_cells": total_cells,
            "missing_cells": missing_cells,
            "missing_ratio": missing_ratio,
            "missing_columns": missing_columns
        }

        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        column_score = (1 - len(missing_columns) / len(required_columns)) * 100
        data_score = (1 - missing_ratio) * 100
        overall_score = (column_score + data_score) / 2

        if missing_ratio > 0.1:
            issues.append(f"æ¬ æå€¤ãŒå¤šã„: {missing_ratio:.1%}")

        return QualityCheckResult(
            check_type=QualityCheckType.COMPLETENESS,
            score=overall_score,
            issues=issues,
            details=details,
            timestamp=datetime.now()
        )

    def check_consistency(self, data: pd.DataFrame) -> QualityCheckResult:
        """ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""

        issues = []
        details = {}

        if data is None or len(data) == 0:
            return QualityCheckResult(
                check_type=QualityCheckType.CONSISTENCY,
                score=0.0,
                issues=["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"],
                details={},
                timestamp=datetime.now()
            )

        consistency_violations = 0
        total_checks = 0

        # OHLCä¾¡æ ¼ã®è«–ç†çš„ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        if all(col in data.columns for col in ['Open', 'High', 'Low', 'Close']):
            # High >= max(Open, Close)
            high_violations = (data['High'] < data[['Open', 'Close']].max(axis=1)).sum()

            # Low <= min(Open, Close)
            low_violations = (data['Low'] > data[['Open', 'Close']].min(axis=1)).sum()

            # High >= Low
            hl_violations = (data['High'] < data['Low']).sum()

            consistency_violations += high_violations + low_violations + hl_violations
            total_checks += len(data) * 3

            if high_violations > 0:
                issues.append(f"Highä¾¡æ ¼ã®ä¸æ•´åˆ: {high_violations}ä»¶")
            if low_violations > 0:
                issues.append(f"Lowä¾¡æ ¼ã®ä¸æ•´åˆ: {low_violations}ä»¶")
            if hl_violations > 0:
                issues.append(f"High-Lowä¾¡æ ¼ã®ä¸æ•´åˆ: {hl_violations}ä»¶")

        # ä¾¡æ ¼ã®å¦¥å½“æ€§ï¼ˆè² ã®å€¤ãƒã‚§ãƒƒã‚¯ï¼‰
        price_columns = ['Open', 'High', 'Low', 'Close']
        for col in price_columns:
            if col in data.columns:
                negative_prices = (data[col] <= 0).sum()
                if negative_prices > 0:
                    consistency_violations += negative_prices
                    total_checks += len(data)
                    issues.append(f"{col}ã«è² ã®ä¾¡æ ¼: {negative_prices}ä»¶")

        # å‡ºæ¥é«˜ã®å¦¥å½“æ€§
        if 'Volume' in data.columns:
            negative_volume = (data['Volume'] < 0).sum()
            if negative_volume > 0:
                consistency_violations += negative_volume
                total_checks += len(data)
                issues.append(f"è² ã®å‡ºæ¥é«˜: {negative_volume}ä»¶")

        # ã‚¹ã‚³ã‚¢è¨ˆç®—
        consistency_ratio = 1 - (consistency_violations / max(total_checks, 1))
        score = consistency_ratio * 100

        details = {
            "total_checks": total_checks,
            "violations": consistency_violations,
            "consistency_ratio": consistency_ratio
        }

        return QualityCheckResult(
            check_type=QualityCheckType.CONSISTENCY,
            score=score,
            issues=issues,
            details=details,
            timestamp=datetime.now()
        )

    def check_freshness(self, data: pd.DataFrame) -> QualityCheckResult:
        """é®®åº¦ãƒã‚§ãƒƒã‚¯"""

        issues = []
        details = {}

        if data is None or len(data) == 0:
            return QualityCheckResult(
                check_type=QualityCheckType.FRESHNESS,
                score=0.0,
                issues=["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"],
                details={},
                timestamp=datetime.now()
            )

        try:
            # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ç¢ºèª
            if hasattr(data.index, 'to_pydatetime'):
                latest_date = pd.to_datetime(data.index[-1])
            else:
                latest_date = pd.to_datetime(data.index[-1])

            now = datetime.now()

            # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã‚’çµ±ä¸€
            if latest_date.tzinfo is not None:
                latest_date = latest_date.replace(tzinfo=None)

            time_diff = now - latest_date
            days_old = time_diff.days + time_diff.seconds / 86400

            # é®®åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå¹³æ—¥è€ƒæ…®ï¼‰
            # 1æ—¥ä»¥å†…: 100%, 2æ—¥ä»¥å†…: 80%, 3æ—¥ä»¥å†…: 60%, ãã‚Œä»¥ä¸Š: æ¸›ç®—
            if days_old <= 1:
                score = 100
            elif days_old <= 2:
                score = 80
            elif days_old <= 3:
                score = 60
            elif days_old <= 7:
                score = max(0, 60 - (days_old - 3) * 10)
            else:
                score = max(0, 20 - (days_old - 7) * 2)

            details = {
                "latest_date": latest_date.isoformat(),
                "current_time": now.isoformat(),
                "days_old": days_old,
                "hours_old": time_diff.total_seconds() / 3600
            }

            if days_old > 1:
                issues.append(f"ãƒ‡ãƒ¼ã‚¿ãŒå¤ã„: {days_old:.1f}æ—¥å‰")
            if days_old > 7:
                issues.append("ãƒ‡ãƒ¼ã‚¿ãŒ1é€±é–“ä»¥ä¸Šå¤ã„")

        except Exception as e:
            score = 50  # ã‚¨ãƒ©ãƒ¼æ™‚ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¹ã‚³ã‚¢
            issues.append(f"é®®åº¦ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
            details = {"error": str(e)}

        return QualityCheckResult(
            check_type=QualityCheckType.FRESHNESS,
            score=score,
            issues=issues,
            details=details,
            timestamp=datetime.now()
        )

    def check_accuracy(self, data: pd.DataFrame) -> QualityCheckResult:
        """æ­£ç¢ºæ€§ãƒã‚§ãƒƒã‚¯"""

        issues = []
        details = {}

        if data is None or len(data) == 0:
            return QualityCheckResult(
                check_type=QualityCheckType.ACCURACY,
                score=0.0,
                issues=["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"],
                details={},
                timestamp=datetime.now()
            )

        accuracy_issues = 0
        total_checks = 0

        # ä¾¡æ ¼å¤‰å‹•ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆæ¥µç«¯ãªå€¤ã®æ¤œå‡ºï¼‰
        if 'Close' in data.columns and len(data) > 1:
            price_changes = data['Close'].pct_change().dropna()

            # 1æ—¥ã§50%ä»¥ä¸Šã®å¤‰å‹•ã¯ç•°å¸¸ã¨ã¿ãªã™
            extreme_changes = (abs(price_changes) > 0.5).sum()
            accuracy_issues += extreme_changes
            total_checks += len(price_changes)

            if extreme_changes > 0:
                issues.append(f"æ¥µç«¯ãªä¾¡æ ¼å¤‰å‹•: {extreme_changes}ä»¶")

            details.update({
                "max_price_change": price_changes.abs().max(),
                "extreme_changes": extreme_changes,
                "avg_volatility": price_changes.std()
            })

        # å‡ºæ¥é«˜ã®ç•°å¸¸å€¤ãƒã‚§ãƒƒã‚¯
        if 'Volume' in data.columns and len(data) > 1:
            volume_median = data['Volume'].median()
            volume_q75 = data['Volume'].quantile(0.75)
            volume_q25 = data['Volume'].quantile(0.25)
            iqr = volume_q75 - volume_q25

            # IQRã®3å€ã‚’è¶…ãˆã‚‹å€¤ã¯ç•°å¸¸ã¨ã¿ãªã™
            upper_bound = volume_q75 + 3 * iqr
            lower_bound = max(0, volume_q25 - 3 * iqr)

            volume_outliers = ((data['Volume'] > upper_bound) |
                             (data['Volume'] < lower_bound)).sum()

            if volume_outliers > 0:
                accuracy_issues += volume_outliers
                issues.append(f"å‡ºæ¥é«˜ç•°å¸¸å€¤: {volume_outliers}ä»¶")

            total_checks += len(data)

            details.update({
                "volume_outliers": volume_outliers,
                "volume_median": volume_median,
                "volume_iqr": iqr
            })

        # æ­£ç¢ºæ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        if total_checks > 0:
            accuracy_ratio = 1 - (accuracy_issues / total_checks)
            score = accuracy_ratio * 100
        else:
            score = 100  # ãƒã‚§ãƒƒã‚¯é …ç›®ãŒãªã„å ´åˆã¯æº€ç‚¹

        details["total_accuracy_checks"] = total_checks
        details["accuracy_issues"] = accuracy_issues

        return QualityCheckResult(
            check_type=QualityCheckType.ACCURACY,
            score=score,
            issues=issues,
            details=details,
            timestamp=datetime.now()
        )

    def check_validity(self, data: pd.DataFrame) -> QualityCheckResult:
        """æœ‰åŠ¹æ€§ãƒã‚§ãƒƒã‚¯"""

        issues = []
        details = {}

        if data is None or len(data) == 0:
            return QualityCheckResult(
                check_type=QualityCheckType.VALIDITY,
                score=0.0,
                issues=["ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ã¾ã›ã‚“"],
                details={},
                timestamp=datetime.now()
            )

        validity_issues = 0
        total_checks = 0

        # ãƒ‡ãƒ¼ã‚¿å‹ã®å¦¥å½“æ€§
        numeric_columns = ['Open', 'High', 'Low', 'Close', 'Volume']
        for col in numeric_columns:
            if col in data.columns:
                non_numeric = pd.to_numeric(data[col], errors='coerce').isnull().sum()
                if non_numeric > 0:
                    validity_issues += non_numeric
                    issues.append(f"{col}ã«éæ•°å€¤ãƒ‡ãƒ¼ã‚¿: {non_numeric}ä»¶")
                total_checks += len(data)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®æœ‰åŠ¹æ€§ï¼ˆæ—¥ä»˜ï¼‰
        try:
            if hasattr(data.index, 'to_pydatetime'):
                invalid_dates = 0  # pandas DatetimeIndexã¯åŸºæœ¬çš„ã«æœ‰åŠ¹
            else:
                invalid_dates = pd.to_datetime(data.index, errors='coerce').isnull().sum()

            if invalid_dates > 0:
                validity_issues += invalid_dates
                issues.append(f"ç„¡åŠ¹ãªæ—¥ä»˜: {invalid_dates}ä»¶")

            total_checks += len(data)

        except Exception as e:
            validity_issues += len(data)
            issues.append(f"æ—¥ä»˜ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼: {str(e)}")
            total_checks += len(data)

        # æœ‰åŠ¹æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        if total_checks > 0:
            validity_ratio = 1 - (validity_issues / total_checks)
            score = validity_ratio * 100
        else:
            score = 100

        details = {
            "total_validity_checks": total_checks,
            "validity_issues": validity_issues,
            "validity_ratio": validity_ratio if total_checks > 0 else 1.0
        }

        return QualityCheckResult(
            check_type=QualityCheckType.VALIDITY,
            score=score,
            issues=issues,
            details=details,
            timestamp=datetime.now()
        )

class DataQualityManager:
    """ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.checker = DataQualityChecker()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
        self.db_path = Path("data_quality/quality_reports.db")
        self.db_path.parent.mkdir(exist_ok=True)
        self._init_database()

        # å“è³ªåŸºæº–
        self.quality_thresholds = {
            DataQualityLevel.EXCELLENT: 95,
            DataQualityLevel.GOOD: 85,
            DataQualityLevel.ACCEPTABLE: 70,
            DataQualityLevel.POOR: 50,
            DataQualityLevel.CRITICAL: 0
        }

        self.logger.info("Data quality manager initialized")

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS quality_reports (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        symbol TEXT NOT NULL,
                        timestamp TEXT NOT NULL,
                        overall_score REAL NOT NULL,
                        quality_level TEXT NOT NULL,
                        data_points INTEGER NOT NULL,
                        missing_data_ratio REAL NOT NULL,
                        completeness_score REAL,
                        consistency_score REAL,
                        freshness_score REAL,
                        accuracy_score REAL,
                        validity_score REAL,
                        issues_summary TEXT,
                        recommendations TEXT
                    )
                ''')

                conn.commit()

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    async def evaluate_data_quality(self, symbol: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡"""

        try:
            # ãƒ‡ãƒ¼ã‚¿å–å¾—
            from real_data_provider_v2 import real_data_provider
            data = await real_data_provider.get_stock_data(symbol, "3mo")  # 3ãƒ¶æœˆåˆ†

            if data is None or len(data) == 0:
                return {
                    "symbol": symbol,
                    "overall_score": 0,
                    "quality_level": DataQualityLevel.CRITICAL.value,
                    "error": "ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ"
                }

            # å„å“è³ªãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
            check_results = []

            check_results.append(self.checker.check_completeness(data))
            check_results.append(self.checker.check_consistency(data))
            check_results.append(self.checker.check_freshness(data))
            check_results.append(self.checker.check_accuracy(data))
            check_results.append(self.checker.check_validity(data))

            # ç·åˆã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆé‡ã¿ä»˜ãå¹³å‡ï¼‰
            weights = {
                QualityCheckType.COMPLETENESS: 0.25,
                QualityCheckType.CONSISTENCY: 0.25,
                QualityCheckType.FRESHNESS: 0.20,
                QualityCheckType.ACCURACY: 0.20,
                QualityCheckType.VALIDITY: 0.10
            }

            overall_score = sum(
                result.score * weights[result.check_type]
                for result in check_results
            )

            # å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š
            quality_level = self._determine_quality_level(overall_score)

            # æ¨å¥¨äº‹é …ç”Ÿæˆ
            recommendations = self._generate_recommendations(check_results, quality_level)

            # æ¬ æãƒ‡ãƒ¼ã‚¿æ¯”ç‡è¨ˆç®—
            missing_ratio = data.isnull().sum().sum() / data.size if data.size > 0 else 1.0

            # ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
            report = DataQualityReport(
                symbol=symbol,
                timestamp=datetime.now(),
                overall_score=overall_score,
                quality_level=quality_level,
                check_results=check_results,
                recommendations=recommendations,
                data_points=len(data),
                missing_data_ratio=missing_ratio
            )

            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜
            await self._save_report(report)

            # çµæœè¾æ›¸ä½œæˆ
            result_dict = {
                "symbol": symbol,
                "timestamp": report.timestamp.isoformat(),
                "overall_score": overall_score,
                "quality_level": quality_level.value,
                "data_points": len(data),
                "missing_data_ratio": missing_ratio,
                "check_scores": {
                    result.check_type.value: result.score
                    for result in check_results
                },
                "issues": [
                    issue for result in check_results for issue in result.issues
                ],
                "recommendations": recommendations
            }

            return result_dict

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
            return {
                "symbol": symbol,
                "overall_score": 0,
                "quality_level": DataQualityLevel.CRITICAL.value,
                "error": str(e)
            }

    def _determine_quality_level(self, score: float) -> DataQualityLevel:
        """å“è³ªãƒ¬ãƒ™ãƒ«åˆ¤å®š"""

        if score >= 95:
            return DataQualityLevel.EXCELLENT
        elif score >= 85:
            return DataQualityLevel.GOOD
        elif score >= 70:
            return DataQualityLevel.ACCEPTABLE
        elif score >= 50:
            return DataQualityLevel.POOR
        else:
            return DataQualityLevel.CRITICAL

    def _generate_recommendations(self, check_results: List[QualityCheckResult],
                                quality_level: DataQualityLevel) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""

        recommendations = []

        # å“è³ªãƒ¬ãƒ™ãƒ«åˆ¥ã®ä¸€èˆ¬çš„ãªæ¨å¥¨äº‹é …
        if quality_level == DataQualityLevel.CRITICAL:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªãŒæ¥µã‚ã¦ä½ã„ãŸã‚ã€ä½¿ç”¨ã‚’é¿ã‘ã‚‹ã“ã¨ã‚’æ¨å¥¨")
            recommendations.append("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã®è¦‹ç›´ã—ãŒå¿…è¦")
        elif quality_level == DataQualityLevel.POOR:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã«é‡å¤§ãªå•é¡ŒãŒã‚ã‚Šã¾ã™")
            recommendations.append("å–å¼•åˆ¤æ–­ã«ã¯æ³¨æ„ãŒå¿…è¦")
        elif quality_level == DataQualityLevel.ACCEPTABLE:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã¯åŸºæº–ã‚’æº€ãŸã—ã¦ã„ã¾ã™ãŒæ”¹å–„ä½™åœ°ãŒã‚ã‚Šã¾ã™")
        elif quality_level == DataQualityLevel.GOOD:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã¯è‰¯å¥½ã§ã™")
        else:
            recommendations.append("ãƒ‡ãƒ¼ã‚¿å“è³ªã¯éå¸¸ã«å„ªç§€ã§ã™")

        # å€‹åˆ¥ãƒã‚§ãƒƒã‚¯çµæœã«åŸºã¥ãæ¨å¥¨äº‹é …
        for result in check_results:
            if result.score < 70:
                if result.check_type == QualityCheckType.COMPLETENESS:
                    recommendations.append("ãƒ‡ãƒ¼ã‚¿æ¬ æã®å¯¾å‡¦ãŒå¿…è¦ï¼ˆè£œé–“ãƒ»é™¤å¤–æ¤œè¨ï¼‰")
                elif result.check_type == QualityCheckType.CONSISTENCY:
                    recommendations.append("ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ã®ç¢ºèªã¨ä¿®æ­£ãŒå¿…è¦")
                elif result.check_type == QualityCheckType.FRESHNESS:
                    recommendations.append("ã‚ˆã‚Šæ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã®å–å¾—ã‚’æ¨å¥¨")
                elif result.check_type == QualityCheckType.ACCURACY:
                    recommendations.append("ç•°å¸¸å€¤ã®é™¤å»ãƒ»èª¿æ•´ã‚’æ¤œè¨")
                elif result.check_type == QualityCheckType.VALIDITY:
                    recommendations.append("ãƒ‡ãƒ¼ã‚¿å½¢å¼ã®ç¢ºèªã¨ä¿®æ­£ãŒå¿…è¦")

        return recommendations

    async def _save_report(self, report: DataQualityReport):
        """ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ã‚¹ã‚³ã‚¢è¾æ›¸ä½œæˆ
                score_dict = {result.check_type.value: result.score for result in report.check_results}

                cursor.execute('''
                    INSERT INTO quality_reports
                    (symbol, timestamp, overall_score, quality_level, data_points,
                     missing_data_ratio, completeness_score, consistency_score,
                     freshness_score, accuracy_score, validity_score,
                     issues_summary, recommendations)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    report.symbol,
                    report.timestamp.isoformat(),
                    report.overall_score,
                    report.quality_level.value,
                    report.data_points,
                    report.missing_data_ratio,
                    score_dict.get('completeness', 0),
                    score_dict.get('consistency', 0),
                    score_dict.get('freshness', 0),
                    score_dict.get('accuracy', 0),
                    score_dict.get('validity', 0),
                    json.dumps([issue for result in report.check_results for issue in result.issues]),
                    json.dumps(report.recommendations)
                ))

                conn.commit()

        except Exception as e:
            self.logger.error(f"ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
data_quality_manager = DataQualityManager()

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
async def run_data_quality_test():
    """ãƒ‡ãƒ¼ã‚¿å“è³ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    print("=== ğŸ“Š ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")

    test_symbols = ["7203", "8306", "4751"]

    for symbol in test_symbols:
        print(f"\n--- {symbol} ãƒ‡ãƒ¼ã‚¿å“è³ªè©•ä¾¡ ---")

        result = await data_quality_manager.evaluate_data_quality(symbol)

        print(f"ç·åˆã‚¹ã‚³ã‚¢: {result.get('overall_score', 0):.1f}/100")
        print(f"å“è³ªãƒ¬ãƒ™ãƒ«: {result.get('quality_level', 'unknown')}")
        print(f"ãƒ‡ãƒ¼ã‚¿ç‚¹æ•°: {result.get('data_points', 0)}")
        print(f"æ¬ ææ¯”ç‡: {result.get('missing_data_ratio', 0):.1%}")

        if 'check_scores' in result:
            print("å€‹åˆ¥ã‚¹ã‚³ã‚¢:")
            for check_type, score in result['check_scores'].items():
                print(f"  {check_type}: {score:.1f}/100")

        if result.get('issues'):
            print("æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
            for issue in result['issues'][:3]:  # ä¸Šä½3ä»¶
                print(f"  â€¢ {issue}")

        if result.get('recommendations'):
            print("æ¨å¥¨äº‹é …:")
            for rec in result['recommendations'][:2]:  # ä¸Šä½2ä»¶
                print(f"  â€¢ {rec}")

    print(f"\nâœ… ãƒ‡ãƒ¼ã‚¿å“è³ªç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒç¢ºèªå®Œäº†")

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(run_data_quality_test())