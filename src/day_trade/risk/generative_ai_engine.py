#!/usr/bin/env python3
"""
Generative AI Risk Analysis Engine
ç”ŸæˆAIçµ±åˆãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ³ã‚¸ãƒ³

GPT-4/Claudeçµ±åˆã«ã‚ˆã‚‹æ¬¡ä¸–ä»£é‡‘èãƒªã‚¹ã‚¯åˆ†æã‚·ã‚¹ãƒ†ãƒ 
"""

import asyncio
import json
import time
from dataclasses import dataclass
from datetime import datetime, timedelta
from typing import Any, Dict, List, Optional

import numpy as np

# ç”ŸæˆAIçµ±åˆ
try:
    import openai
    from openai import AsyncOpenAI

    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False

try:
    import anthropic
    from anthropic import AsyncAnthropic

    ANTHROPIC_AVAILABLE = True
except ImportError:
    ANTHROPIC_AVAILABLE = False

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..utils.logging_config import get_context_logger

logger = get_context_logger(__name__)


@dataclass
class RiskAnalysisRequest:
    """ãƒªã‚¹ã‚¯åˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆ"""

    transaction_id: str
    symbol: str
    transaction_type: str
    amount: float
    timestamp: datetime
    market_data: Dict[str, Any]
    user_profile: Dict[str, Any]
    additional_context: Dict[str, Any] = None


@dataclass
class RiskAnalysisResult:
    """ãƒªã‚¹ã‚¯åˆ†æçµæœ"""

    request_id: str
    risk_score: float  # 0-1 (1ãŒæœ€é«˜ãƒªã‚¹ã‚¯)
    risk_level: str  # "low", "medium", "high", "critical"
    confidence: float  # 0-1 (1ãŒæœ€é«˜ä¿¡é ¼åº¦)
    explanation: str  # ç”ŸæˆAI ã«ã‚ˆã‚‹è‡ªç„¶è¨€èªèª¬æ˜
    recommendations: List[str]
    risk_factors: Dict[str, float]
    processing_time: float
    ai_models_used: List[str]
    timestamp: datetime


@dataclass
class GenerativeAIConfig:
    """ç”ŸæˆAIè¨­å®š"""

    openai_api_key: Optional[str] = None
    anthropic_api_key: Optional[str] = None
    default_model_gpt: str = "gpt-4"
    default_model_claude: str = "claude-3-opus-20240229"
    temperature: float = 0.3
    max_tokens: int = 1000
    timeout_seconds: int = 10
    enable_caching: bool = True
    cache_ttl_seconds: int = 300


class GenerativeAIRiskEngine:
    """ç”ŸæˆAIçµ±åˆãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, config: Optional[GenerativeAIConfig] = None):
        self.config = config or GenerativeAIConfig()

        # OpenAI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        if OPENAI_AVAILABLE and self.config.openai_api_key:
            self.openai_client = AsyncOpenAI(api_key=self.config.openai_api_key)
            logger.info("OpenAI GPT-4 ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        else:
            self.openai_client = None
            logger.warning("OpenAI APIåˆ©ç”¨ä¸å¯")

        # Anthropic ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
        if ANTHROPIC_AVAILABLE and self.config.anthropic_api_key:
            self.anthropic_client = AsyncAnthropic(api_key=self.config.anthropic_api_key)
            logger.info("Anthropic Claude ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")
        else:
            self.anthropic_client = None
            logger.warning("Anthropic APIåˆ©ç”¨ä¸å¯")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ 
        self.analysis_cache: Dict[str, RiskAnalysisResult] = {}
        self.cache_timestamps: Dict[str, datetime] = {}

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.performance_stats = {
            "total_analyses": 0,
            "avg_processing_time": 0.0,
            "successful_analyses": 0,
            "failed_analyses": 0,
            "cache_hits": 0,
            "gpt4_calls": 0,
            "claude_calls": 0,
        }

        logger.info("ç”ŸæˆAIçµ±åˆãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–å®Œäº†")

    async def analyze_risk_comprehensive(
        self,
        request: RiskAnalysisRequest,
        use_gpt4: bool = True,
        use_claude: bool = True,
        use_ensemble: bool = True,
    ) -> RiskAnalysisResult:
        """åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯åˆ†æï¼ˆç”ŸæˆAIçµ±åˆï¼‰"""

        start_time = time.time()
        request_hash = self._generate_request_hash(request)

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒã‚§ãƒƒã‚¯
        if self.config.enable_caching:
            cached_result = self._get_cached_result(request_hash)
            if cached_result:
                self.performance_stats["cache_hits"] += 1
                return cached_result

        try:
            # ä¸¦åˆ—AIåˆ†æå®Ÿè¡Œ
            analysis_tasks = []
            ai_models_used = []

            if use_gpt4 and self.openai_client:
                analysis_tasks.append(self._analyze_with_gpt4(request))
                ai_models_used.append("gpt-4")

            if use_claude and self.anthropic_client:
                analysis_tasks.append(self._analyze_with_claude(request))
                ai_models_used.append("claude-3-opus")

            # åŸºæœ¬ãƒªã‚¹ã‚¯åˆ†æã‚‚ä¸¦åˆ—å®Ÿè¡Œ
            analysis_tasks.append(self._basic_risk_analysis(request))
            ai_models_used.append("heuristic-analyzer")

            # ä¸¦åˆ—å®Ÿè¡Œ
            analysis_results = await asyncio.gather(*analysis_tasks, return_exceptions=True)

            # çµæœçµ±åˆ
            if use_ensemble and len(analysis_results) > 1:
                final_result = self._ensemble_analysis(
                    request, analysis_results, ai_models_used, start_time
                )
            else:
                # å˜ä¸€ãƒ¢ãƒ‡ãƒ«çµæœä½¿ç”¨
                valid_results = [r for r in analysis_results if not isinstance(r, Exception)]
                if valid_results:
                    final_result = valid_results[0]
                else:
                    raise ValueError("ã™ã¹ã¦ã®AIãƒ¢ãƒ‡ãƒ«åˆ†æãŒå¤±æ•—ã—ã¾ã—ãŸ")

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
            if self.config.enable_caching:
                self._cache_result(request_hash, final_result)

            # çµ±è¨ˆæ›´æ–°
            self.performance_stats["total_analyses"] += 1
            self.performance_stats["successful_analyses"] += 1
            self.performance_stats["avg_processing_time"] = (
                self.performance_stats["avg_processing_time"]
                * (self.performance_stats["total_analyses"] - 1)
                + (time.time() - start_time)
            ) / self.performance_stats["total_analyses"]

            return final_result

        except Exception as e:
            self.performance_stats["total_analyses"] += 1
            self.performance_stats["failed_analyses"] += 1
            logger.error(f"ãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {e}")

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ
            return await self._fallback_analysis(request, start_time)

    async def _analyze_with_gpt4(self, request: RiskAnalysisRequest) -> Dict[str, Any]:
        """GPT-4ã«ã‚ˆã‚‹é«˜åº¦ãƒªã‚¹ã‚¯åˆ†æ"""

        self.performance_stats["gpt4_calls"] += 1

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰
        system_prompt = """ã‚ãªãŸã¯ä¸–ç•Œæœ€é«˜ãƒ¬ãƒ™ãƒ«ã®é‡‘èãƒªã‚¹ã‚¯åˆ†æå°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã€ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã¨è©³ç´°ãªèª¬æ˜ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:
{
  "risk_score": 0.0-1.0ã®æ•°å€¤,
  "risk_level": "low/medium/high/critical",
  "explanation": "è©³ç´°ãªæ—¥æœ¬èªèª¬æ˜",
  "key_risk_factors": ["è¦å› 1", "è¦å› 2", "è¦å› 3"],
  "recommendations": ["æ¨å¥¨äº‹é …1", "æ¨å¥¨äº‹é …2"]
}"""

        user_prompt = f"""
å–å¼•æƒ…å ±:
- éŠ˜æŸ„: {request.symbol}
- å–å¼•ã‚¿ã‚¤ãƒ—: {request.transaction_type}
- é‡‘é¡: {request.amount:,.0f}å††
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—: {request.timestamp}

å¸‚å ´ãƒ‡ãƒ¼ã‚¿:
{json.dumps(request.market_data, ensure_ascii=False, indent=2)}

ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«:
{json.dumps(request.user_profile, ensure_ascii=False, indent=2)}

ã“ã®å–å¼•ã®ãƒªã‚¹ã‚¯ã‚’åŒ…æ‹¬çš„ã«åˆ†æã—ã¦ãã ã•ã„ã€‚"""

        try:
            response = await asyncio.wait_for(
                self.openai_client.chat.completions.create(
                    model=self.config.default_model_gpt,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt},
                    ],
                    temperature=self.config.temperature,
                    max_tokens=self.config.max_tokens,
                ),
                timeout=self.config.timeout_seconds,
            )

            # JSONè§£æ
            content = response.choices[0].message.content
            analysis = json.loads(content)

            return {
                "source": "gpt-4",
                "risk_score": float(analysis.get("risk_score", 0.5)),
                "risk_level": analysis.get("risk_level", "medium"),
                "explanation": analysis.get("explanation", ""),
                "recommendations": analysis.get("recommendations", []),
                "risk_factors": analysis.get("key_risk_factors", []),
                "raw_response": content,
            }

        except asyncio.TimeoutError:
            logger.error("GPT-4 API ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
            return self._create_fallback_response("gpt-4", "API timeout")
        except json.JSONDecodeError as e:
            logger.error(f"GPT-4 ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_response("gpt-4", f"JSON parse error: {e}")
        except Exception as e:
            logger.error(f"GPT-4 åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_response("gpt-4", str(e))

    async def _analyze_with_claude(self, request: RiskAnalysisRequest) -> Dict[str, Any]:
        """Claudeã«ã‚ˆã‚‹é«˜åº¦ãƒªã‚¹ã‚¯åˆ†æ"""

        self.performance_stats["claude_calls"] += 1

        prompt = f"""ã‚ãªãŸã¯é‡‘èãƒªã‚¹ã‚¯ç®¡ç†ã®å°‚é–€å®¶ã§ã™ã€‚ä»¥ä¸‹ã®å–å¼•ã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚

å–å¼•ãƒ‡ãƒ¼ã‚¿:
- ID: {request.transaction_id}
- éŠ˜æŸ„: {request.symbol}
- ç¨®é¡: {request.transaction_type}
- é‡‘é¡: {request.amount:,.0f}å††
- æ™‚åˆ»: {request.timestamp}

å¸‚å ´çŠ¶æ³: {json.dumps(request.market_data, ensure_ascii=False)}
ãƒ¦ãƒ¼ã‚¶ãƒ¼æƒ…å ±: {json.dumps(request.user_profile, ensure_ascii=False)}

ä»¥ä¸‹ã®JSONå½¢å¼ã§å›ç­”ã—ã¦ãã ã•ã„:
{{
  "risk_score": 0.0-1.0ã®æ•°å€¤,
  "risk_level": "low/medium/high/critical",
  "explanation": "è©³ç´°ãªèª¬æ˜",
  "recommendations": ["æ¨å¥¨äº‹é …ã®ãƒªã‚¹ãƒˆ"],
  "confidence": 0.0-1.0ã®ä¿¡é ¼åº¦
}}"""

        try:
            response = await asyncio.wait_for(
                self.anthropic_client.messages.create(
                    model=self.config.default_model_claude,
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=self.config.max_tokens,
                ),
                timeout=self.config.timeout_seconds,
            )

            content = response.content[0].text
            analysis = json.loads(content)

            return {
                "source": "claude-3-opus",
                "risk_score": float(analysis.get("risk_score", 0.5)),
                "risk_level": analysis.get("risk_level", "medium"),
                "explanation": analysis.get("explanation", ""),
                "recommendations": analysis.get("recommendations", []),
                "confidence": float(analysis.get("confidence", 0.7)),
                "raw_response": content,
            }

        except Exception as e:
            logger.error(f"Claudeåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return self._create_fallback_response("claude-3-opus", str(e))

    async def _basic_risk_analysis(self, request: RiskAnalysisRequest) -> Dict[str, Any]:
        """åŸºæœ¬çš„ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒªã‚¹ã‚¯åˆ†æ"""

        risk_score = 0.0
        risk_factors = []

        # é‡‘é¡ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ã‚¯
        if request.amount > 10000000:  # 1000ä¸‡å††ä»¥ä¸Š
            risk_score += 0.3
            risk_factors.append("é«˜é¡å–å¼•")
        elif request.amount > 1000000:  # 100ä¸‡å††ä»¥ä¸Š
            risk_score += 0.1
            risk_factors.append("ä¸­é¡å–å¼•")

        # æ™‚é–“å¸¯ãƒªã‚¹ã‚¯
        hour = request.timestamp.hour
        if hour < 9 or hour > 15:  # å–å¼•æ™‚é–“å¤–
            risk_score += 0.2
            risk_factors.append("æ™‚é–“å¤–å–å¼•")

        # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒªã‚¹ã‚¯
        if "volatility" in request.market_data:
            volatility = request.market_data["volatility"]
            if volatility > 0.3:
                risk_score += 0.2
                risk_factors.append("é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£")

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ãƒªã‚¹ã‚¯
        if "risk_tolerance" in request.user_profile:
            risk_tolerance = request.user_profile["risk_tolerance"]
            if risk_tolerance == "conservative" and request.amount > 500000:
                risk_score += 0.15
                risk_factors.append("ãƒªã‚¹ã‚¯è¨±å®¹åº¦ä¸æ•´åˆ")

        # æ­£è¦åŒ–
        risk_score = min(1.0, max(0.0, risk_score))

        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if risk_score >= 0.8:
            risk_level = "critical"
        elif risk_score >= 0.6:
            risk_level = "high"
        elif risk_score >= 0.3:
            risk_level = "medium"
        else:
            risk_level = "low"

        return {
            "source": "heuristic-analyzer",
            "risk_score": risk_score,
            "risk_level": risk_level,
            "explanation": f"åŸºæœ¬åˆ†æã«ã‚ˆã‚‹ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {risk_score:.2f}",
            "recommendations": self._generate_basic_recommendations(risk_score),
            "risk_factors": risk_factors,
            "confidence": 0.8,
        }

    def _ensemble_analysis(
        self,
        request: RiskAnalysisRequest,
        results: List[Dict[str, Any]],
        models_used: List[str],
        start_time: float,
    ) -> RiskAnalysisResult:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆ†æçµæœçµ±åˆ"""

        valid_results = [r for r in results if isinstance(r, dict) and "risk_score" in r]

        if not valid_results:
            raise ValueError("æœ‰åŠ¹ãªåˆ†æçµæœãŒã‚ã‚Šã¾ã›ã‚“")

        # é‡ã¿ä»˜ãå¹³å‡ï¼ˆGPT-4ã¨Claudeã‚’é«˜é‡è¦–ï¼‰
        weights = {"gpt-4": 0.4, "claude-3-opus": 0.4, "heuristic-analyzer": 0.2}

        weighted_risk_score = 0.0
        total_weight = 0.0
        all_recommendations = []
        all_risk_factors = []
        explanations = []
        confidences = []

        for result in valid_results:
            source = result.get("source", "unknown")
            weight = weights.get(source, 0.1)

            weighted_risk_score += result.get("risk_score", 0.5) * weight
            total_weight += weight

            all_recommendations.extend(result.get("recommendations", []))
            all_risk_factors.extend(result.get("risk_factors", []))
            explanations.append(f"[{source}] {result.get('explanation', '')}")
            confidences.append(result.get("confidence", 0.5))

        # æ­£è¦åŒ–
        if total_weight > 0:
            final_risk_score = weighted_risk_score / total_weight
        else:
            final_risk_score = 0.5

        # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«æ±ºå®š
        if final_risk_score >= 0.8:
            risk_level = "critical"
        elif final_risk_score >= 0.6:
            risk_level = "high"
        elif final_risk_score >= 0.3:
            risk_level = "medium"
        else:
            risk_level = "low"

        # çµ±åˆèª¬æ˜æ–‡ç”Ÿæˆ
        combined_explanation = "\n\n".join(explanations)

        return RiskAnalysisResult(
            request_id=request.transaction_id,
            risk_score=final_risk_score,
            risk_level=risk_level,
            confidence=np.mean(confidences),
            explanation=combined_explanation,
            recommendations=list(set(all_recommendations)),  # é‡è¤‡é™¤å»
            risk_factors={f"factor_{i}": 1.0 for i, f in enumerate(set(all_risk_factors))},
            processing_time=time.time() - start_time,
            ai_models_used=models_used,
            timestamp=datetime.now(),
        )

    async def _fallback_analysis(
        self, request: RiskAnalysisRequest, start_time: float
    ) -> RiskAnalysisResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ"""

        logger.warning("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æã‚’å®Ÿè¡Œ")

        # åŸºæœ¬åˆ†æã®ã¿å®Ÿè¡Œ
        basic_result = await self._basic_risk_analysis(request)

        return RiskAnalysisResult(
            request_id=request.transaction_id,
            risk_score=basic_result["risk_score"],
            risk_level=basic_result["risk_level"],
            confidence=0.6,  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ™‚ã¯ä¿¡é ¼åº¦ä½ä¸‹
            explanation=f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯åˆ†æ: {basic_result['explanation']}",
            recommendations=basic_result.get("recommendations", ["è©³ç´°åˆ†æã‚’å†å®Ÿè¡Œã—ã¦ãã ã•ã„"]),
            risk_factors={"fallback_analysis": 1.0},
            processing_time=time.time() - start_time,
            ai_models_used=["fallback-analyzer"],
            timestamp=datetime.now(),
        )

    def _create_fallback_response(self, source: str, error: str) -> Dict[str, Any]:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ"""
        return {
            "source": source,
            "risk_score": 0.5,
            "risk_level": "medium",
            "explanation": f"åˆ†æã‚¨ãƒ©ãƒ¼ ({source}): {error}",
            "recommendations": ["ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„"],
            "confidence": 0.3,
            "error": error,
        }

    def _generate_basic_recommendations(self, risk_score: float) -> List[str]:
        """åŸºæœ¬æ¨å¥¨äº‹é …ç”Ÿæˆ"""
        if risk_score >= 0.8:
            return [
                "å–å¼•ã‚’åœæ­¢ã—ã¦ãã ã•ã„",
                "ãƒªã‚¹ã‚¯ç®¡ç†è²¬ä»»è€…ã«ç›¸è«‡ã—ã¦ãã ã•ã„",
                "è©³ç´°ãªãƒ‡ãƒ¥ãƒ¼ãƒ‡ãƒªã‚¸ã‚§ãƒ³ã‚¹ã‚’å®Ÿæ–½ã—ã¦ãã ã•ã„",
            ]
        elif risk_score >= 0.6:
            return [
                "å–å¼•å‰ã«è¿½åŠ ç¢ºèªã‚’è¡Œã£ã¦ãã ã•ã„",
                "å–å¼•é‡‘é¡ã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„",
                "å¸‚å ´çŠ¶æ³ã‚’å†ç¢ºèªã—ã¦ãã ã•ã„",
            ]
        elif risk_score >= 0.3:
            return [
                "å®šæœŸçš„ãªç›£è¦–ã‚’ç¶™ç¶šã—ã¦ãã ã•ã„",
                "ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºã«æ³¨æ„ã—ã¦ãã ã•ã„",
            ]
        else:
            return [
                "é€šå¸¸ã©ãŠã‚Šå–å¼•ã‚’ç¶™ç¶šã§ãã¾ã™",
                "å¼•ãç¶šãå¸‚å ´å‹•å‘ã‚’ç›£è¦–ã—ã¦ãã ã•ã„",
            ]

    def _generate_request_hash(self, request: RiskAnalysisRequest) -> str:
        """ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒãƒƒã‚·ãƒ¥ç”Ÿæˆï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ç”¨ï¼‰"""
        import hashlib

        hash_data = (
            f"{request.transaction_id}-{request.symbol}-{request.amount}-{request.timestamp}"
        )
        return hashlib.md5(hash_data.encode()).hexdigest()

    def _get_cached_result(self, request_hash: str) -> Optional[RiskAnalysisResult]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµæœå–å¾—"""
        if request_hash not in self.analysis_cache:
            return None

        # TTL ãƒã‚§ãƒƒã‚¯
        cache_time = self.cache_timestamps.get(request_hash)
        if not cache_time:
            return None

        if datetime.now() - cache_time > timedelta(seconds=self.config.cache_ttl_seconds):
            # æœŸé™åˆ‡ã‚Œã‚­ãƒ£ãƒƒã‚·ãƒ¥å‰Šé™¤
            del self.analysis_cache[request_hash]
            del self.cache_timestamps[request_hash]
            return None

        return self.analysis_cache[request_hash]

    def _cache_result(self, request_hash: str, result: RiskAnalysisResult):
        """çµæœã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜"""
        self.analysis_cache[request_hash] = result
        self.cache_timestamps[request_hash] = datetime.now()

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ï¼ˆ1000ä»¶ï¼‰
        if len(self.analysis_cache) > 1000:
            # æœ€ã‚‚å¤ã„ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’å‰Šé™¤
            oldest_key = min(self.cache_timestamps.keys(), key=lambda k: self.cache_timestamps[k])
            del self.analysis_cache[oldest_key]
            del self.cache_timestamps[oldest_key]

    def get_performance_stats(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆå–å¾—"""
        return {
            **self.performance_stats,
            "cache_size": len(self.analysis_cache),
            "success_rate": (
                self.performance_stats["successful_analyses"]
                / max(1, self.performance_stats["total_analyses"])
            ),
            "models_available": {
                "gpt4": self.openai_client is not None,
                "claude": self.anthropic_client is not None,
            },
        }

    def clear_cache(self):
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢"""
        self.analysis_cache.clear()
        self.cache_timestamps.clear()
        logger.info("åˆ†æã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")


# ä½¿ç”¨ä¾‹ã¨ãƒ†ã‚¹ãƒˆ
async def test_generative_ai_risk_engine():
    """ç”ŸæˆAI ãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ"""

    # è¨­å®šï¼ˆå®Ÿéš›ã®APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
    config = GenerativeAIConfig(
        openai_api_key="dummy_key",  # å®Ÿéš›ã¯ os.getenv("OPENAI_API_KEY")
        anthropic_api_key="dummy_key",  # å®Ÿéš›ã¯ os.getenv("ANTHROPIC_API_KEY")
        temperature=0.3,
        max_tokens=800,
    )

    engine = GenerativeAIRiskEngine(config)

    # ãƒ†ã‚¹ãƒˆç”¨ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    test_request = RiskAnalysisRequest(
        transaction_id="TEST_001",
        symbol="7203",  # ãƒˆãƒ¨ã‚¿
        transaction_type="buy",
        amount=5000000,  # 500ä¸‡å††
        timestamp=datetime.now(),
        market_data={
            "current_price": 2500,
            "volatility": 0.25,
            "volume": 1000000,
            "trend": "upward",
        },
        user_profile={
            "risk_tolerance": "moderate",
            "experience_level": "intermediate",
            "portfolio_value": 10000000,
        },
    )

    # åˆ†æå®Ÿè¡Œ
    print("ğŸ¤– ç”ŸæˆAIçµ±åˆãƒªã‚¹ã‚¯åˆ†æé–‹å§‹...")

    result = await engine.analyze_risk_comprehensive(
        test_request,
        use_gpt4=False,  # ãƒ†ã‚¹ãƒˆæ™‚ã¯ãƒ€ãƒŸãƒ¼ã‚­ãƒ¼ãªã®ã§False
        use_claude=False,  # ãƒ†ã‚¹ãƒˆæ™‚ã¯ãƒ€ãƒŸãƒ¼ã‚­ãƒ¼ãªã®ã§False
        use_ensemble=True,
    )

    print("âœ… åˆ†æå®Œäº†!")
    print(f"ğŸ¯ ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {result.risk_score:.2f}")
    print(f"âš ï¸ ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {result.risk_level}")
    print(f"ğŸ• å‡¦ç†æ™‚é–“: {result.processing_time:.2f}ç§’")
    print(f"ğŸ§  ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {result.ai_models_used}")
    print(f"ğŸ“Š èª¬æ˜: {result.explanation[:100]}...")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    stats = engine.get_performance_stats()
    print(f"ğŸ“ˆ çµ±è¨ˆ: {stats}")


if __name__ == "__main__":
    asyncio.run(test_generative_ai_risk_engine())
