#!/usr/bin/env python3
"""
ãƒªã‚¹ã‚¯åˆ†æçµ±åˆã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼
Risk Analysis Coordinator

ç”ŸæˆAIãƒ»æ·±å±¤å­¦ç¿’ãƒ»ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æã®çµ±åˆç®¡ç†
"""

import asyncio
import time
import json
from datetime import datetime, timedelta
from dataclasses import dataclass, asdict
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import numpy as np
import pandas as pd

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from ..utils.logging_config import get_context_logger
from .generative_ai_engine import GenerativeAIRiskEngine, RiskAnalysisRequest, RiskAnalysisResult
from .fraud_detection_engine import FraudDetectionEngine, FraudDetectionRequest
from ..realtime.alert_system import AlertManager, AlertLevel

logger = get_context_logger(__name__)

@dataclass
class RiskAssessmentSummary:
    """ãƒªã‚¹ã‚¯è©•ä¾¡ã‚µãƒãƒªãƒ¼"""
    request_id: str
    overall_risk_score: float  # 0-1
    risk_category: str  # "low", "medium", "high", "critical"
    confidence_score: float   # 0-1
    analysis_methods: List[str]
    key_risk_factors: List[str]
    recommendations: List[str]
    estimated_loss_potential: float
    processing_time_total: float
    component_results: Dict[str, Any]
    timestamp: datetime

class RiskAnalysisCoordinator:
    """ãƒªã‚¹ã‚¯åˆ†æçµ±åˆã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼"""

    def __init__(self):
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.generative_ai_engine = GenerativeAIRiskEngine()
        self.fraud_detection_engine = FraudDetectionEngine()
        self.alert_manager = AlertManager()

        # åˆ†æå±¥æ­´
        self.analysis_history: List[RiskAssessmentSummary] = []
        self.daily_statistics = {}

        # è¨­å®š
        self.risk_thresholds = {
            'low': 0.3,
            'medium': 0.6,
            'high': 0.8,
            'critical': 0.9
        }

        self.alert_thresholds = {
            'medium_risk': 0.5,
            'high_risk': 0.7,
            'critical_risk': 0.85
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.performance_stats = {
            'total_assessments': 0,
            'successful_assessments': 0,
            'avg_processing_time': 0.0,
            'component_usage': {
                'generative_ai': 0,
                'fraud_detection': 0,
                'rule_based': 0
            },
            'risk_distribution': {
                'low': 0, 'medium': 0, 'high': 0, 'critical': 0
            }
        }

        logger.info("ãƒªã‚¹ã‚¯åˆ†æã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼åˆæœŸåŒ–å®Œäº†")

    async def comprehensive_risk_assessment(
        self,
        transaction_data: Dict[str, Any],
        market_context: Optional[Dict[str, Any]] = None,
        user_profile: Optional[Dict[str, Any]] = None,
        enable_ai_analysis: bool = True,
        enable_fraud_detection: bool = True
    ) -> RiskAssessmentSummary:
        """åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯è©•ä¾¡"""

        start_time = time.time()
        request_id = f"RISK_{int(time.time() * 1000)}_{np.random.randint(1000, 9999)}"

        logger.info(f"åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯è©•ä¾¡é–‹å§‹: {request_id}")

        try:
            # ä¸¦åˆ—åˆ†æå®Ÿè¡Œ
            analysis_tasks = []
            analysis_methods = []

            # ç”ŸæˆAIåˆ†æ
            if enable_ai_analysis:
                ai_request = self._create_ai_analysis_request(
                    request_id, transaction_data, market_context, user_profile
                )
                analysis_tasks.append(self._run_ai_analysis(ai_request))
                analysis_methods.append("GenerativeAI")

            # ä¸æ­£æ¤œçŸ¥åˆ†æ
            if enable_fraud_detection:
                fraud_request = self._create_fraud_detection_request(
                    request_id, transaction_data
                )
                analysis_tasks.append(self._run_fraud_analysis(fraud_request))
                analysis_methods.append("FraudDetection")

            # åŸºæœ¬ãƒ«ãƒ¼ãƒ«ãƒ™ãƒ¼ã‚¹åˆ†æ
            analysis_tasks.append(self._run_basic_risk_analysis(transaction_data))
            analysis_methods.append("RuleBasedAnalysis")

            # ä¸¦åˆ—å®Ÿè¡Œ
            analysis_results = await asyncio.gather(
                *analysis_tasks, return_exceptions=True
            )

            # çµæœçµ±åˆ
            summary = await self._integrate_analysis_results(
                request_id, analysis_results, analysis_methods,
                transaction_data, start_time
            )

            # ã‚¢ãƒ©ãƒ¼ãƒˆåˆ¤å®š
            await self._evaluate_and_send_alerts(summary)

            # å±¥æ­´ä¿å­˜
            self.analysis_history.append(summary)
            if len(self.analysis_history) > 10000:
                self.analysis_history = self.analysis_history[-5000:]

            # çµ±è¨ˆæ›´æ–°
            self._update_performance_stats(summary, True)

            logger.info(f"ãƒªã‚¹ã‚¯è©•ä¾¡å®Œäº†: {request_id} - {summary.risk_category}")
            return summary

        except Exception as e:
            logger.error(f"ãƒªã‚¹ã‚¯è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")

            # ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è©•ä¾¡
            error_summary = self._create_error_summary(
                request_id, str(e), transaction_data, start_time
            )
            self._update_performance_stats(error_summary, False)
            return error_summary

    def _create_ai_analysis_request(
        self,
        request_id: str,
        transaction_data: Dict[str, Any],
        market_context: Optional[Dict[str, Any]],
        user_profile: Optional[Dict[str, Any]]
    ) -> RiskAnalysisRequest:
        """AIåˆ†æãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ"""

        return RiskAnalysisRequest(
            transaction_id=request_id,
            symbol=transaction_data.get('symbol', 'UNKNOWN'),
            transaction_type=transaction_data.get('type', 'unknown'),
            amount=float(transaction_data.get('amount', 0)),
            timestamp=datetime.fromisoformat(transaction_data.get('timestamp', datetime.now().isoformat())),
            market_data=market_context or {},
            user_profile=user_profile or {},
            additional_context=transaction_data
        )

    def _create_fraud_detection_request(
        self,
        request_id: str,
        transaction_data: Dict[str, Any]
    ) -> FraudDetectionRequest:
        """ä¸æ­£æ¤œçŸ¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ"""

        return FraudDetectionRequest(
            transaction_id=request_id,
            user_id=transaction_data.get('user_id', 'unknown'),
            amount=float(transaction_data.get('amount', 0)),
            timestamp=datetime.fromisoformat(transaction_data.get('timestamp', datetime.now().isoformat())),
            transaction_type=transaction_data.get('type', 'unknown'),
            account_balance=float(transaction_data.get('account_balance', 0)),
            location=transaction_data.get('location', 'unknown'),
            device_info=transaction_data.get('device_info', {}),
            transaction_history=transaction_data.get('history', []),
            market_conditions=transaction_data.get('market_conditions', {})
        )

    async def _run_ai_analysis(self, request: RiskAnalysisRequest) -> RiskAnalysisResult:
        """AIåˆ†æå®Ÿè¡Œ"""

        try:
            result = await self.generative_ai_engine.analyze_risk_comprehensive(
                request,
                use_gpt4=True,
                use_claude=True,
                use_ensemble=True
            )
            self.performance_stats['component_usage']['generative_ai'] += 1
            return result
        except Exception as e:
            logger.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def _run_fraud_analysis(self, request: FraudDetectionRequest):
        """ä¸æ­£æ¤œçŸ¥åˆ†æå®Ÿè¡Œ"""

        try:
            result = await self.fraud_detection_engine.detect_fraud(request)
            self.performance_stats['component_usage']['fraud_detection'] += 1
            return result
        except Exception as e:
            logger.error(f"ä¸æ­£æ¤œçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    async def _run_basic_risk_analysis(self, transaction_data: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºæœ¬ãƒªã‚¹ã‚¯åˆ†æ"""

        start_time = time.time()

        try:
            risk_score = 0.0
            risk_factors = []

            # é‡‘é¡ãƒ™ãƒ¼ã‚¹ãƒªã‚¹ã‚¯
            amount = float(transaction_data.get('amount', 0))
            if amount > 50000000:  # 5000ä¸‡å††ä»¥ä¸Š
                risk_score += 0.4
                risk_factors.append("è¶…é«˜é¡å–å¼•")
            elif amount > 10000000:  # 1000ä¸‡å††ä»¥ä¸Š
                risk_score += 0.2
                risk_factors.append("é«˜é¡å–å¼•")

            # æ™‚é–“å¸¯ãƒªã‚¹ã‚¯
            timestamp_str = transaction_data.get('timestamp', datetime.now().isoformat())
            timestamp = datetime.fromisoformat(timestamp_str)
            hour = timestamp.hour

            if hour < 6 or hour > 22:
                risk_score += 0.15
                risk_factors.append("æ™‚é–“å¤–å–å¼•")

            # å–å¼•ã‚¿ã‚¤ãƒ—ãƒªã‚¹ã‚¯
            transaction_type = transaction_data.get('type', 'unknown')
            high_risk_types = ['margin', 'options', 'futures', 'fx']
            if transaction_type.lower() in high_risk_types:
                risk_score += 0.1
                risk_factors.append("é«˜ãƒªã‚¹ã‚¯å•†å“")

            # åœ°ç†çš„ãƒªã‚¹ã‚¯
            location = transaction_data.get('location', 'domestic')
            if location in ['foreign', 'high_risk_country']:
                risk_score += 0.2
                risk_factors.append("åœ°ç†çš„ãƒªã‚¹ã‚¯")

            # å¸‚å ´çŠ¶æ³ãƒªã‚¹ã‚¯
            market_conditions = transaction_data.get('market_conditions', {})
            volatility = market_conditions.get('volatility', 0.2)
            if volatility > 0.4:
                risk_score += 0.15
                risk_factors.append("é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£")

            # æ­£è¦åŒ–
            risk_score = min(1.0, max(0.0, risk_score))

            self.performance_stats['component_usage']['rule_based'] += 1

            return {
                'source': 'rule_based_analysis',
                'risk_score': risk_score,
                'risk_factors': risk_factors,
                'processing_time': time.time() - start_time,
                'confidence': 0.7
            }

        except Exception as e:
            logger.error(f"åŸºæœ¬ãƒªã‚¹ã‚¯åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'source': 'rule_based_analysis',
                'risk_score': 0.5,
                'risk_factors': ['åˆ†æã‚¨ãƒ©ãƒ¼'],
                'processing_time': time.time() - start_time,
                'confidence': 0.3,
                'error': str(e)
            }

    async def _integrate_analysis_results(
        self,
        request_id: str,
        analysis_results: List[Any],
        analysis_methods: List[str],
        transaction_data: Dict[str, Any],
        start_time: float
    ) -> RiskAssessmentSummary:
        """åˆ†æçµæœçµ±åˆ"""

        valid_results = []
        component_results = {}

        for i, result in enumerate(analysis_results):
            method = analysis_methods[i] if i < len(analysis_methods) else f"Method_{i}"

            if isinstance(result, Exception):
                logger.warning(f"åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ {method} ã§ã‚¨ãƒ©ãƒ¼: {result}")
                component_results[method] = {'error': str(result)}
                continue

            valid_results.append((method, result))
            component_results[method] = self._serialize_result(result)

        if not valid_results:
            raise ValueError("ã™ã¹ã¦ã®åˆ†æãƒ¡ã‚½ãƒƒãƒ‰ãŒå¤±æ•—ã—ã¾ã—ãŸ")

        # é‡ã¿ä»˜ãçµ±åˆ
        risk_scores = []
        confidences = []
        all_recommendations = []
        all_risk_factors = []
        method_weights = {
            'GenerativeAI': 0.5,
            'FraudDetection': 0.3,
            'RuleBasedAnalysis': 0.2
        }

        for method, result in valid_results:
            weight = method_weights.get(method, 0.1)

            if hasattr(result, 'risk_score'):
                # RiskAnalysisResult
                risk_scores.append((result.risk_score, weight))
                confidences.append(result.confidence)
                all_recommendations.extend(result.recommendations)
                all_risk_factors.extend(result.risk_factors.keys() if hasattr(result, 'risk_factors') else [])

            elif hasattr(result, 'fraud_probability'):
                # FraudDetectionResult
                risk_scores.append((result.fraud_probability, weight))
                confidences.append(result.confidence)
                all_recommendations.append(result.recommended_action)
                all_risk_factors.extend(result.risk_factors.keys())

            elif isinstance(result, dict):
                # åŸºæœ¬åˆ†æçµæœ
                risk_scores.append((result.get('risk_score', 0.5), weight))
                confidences.append(result.get('confidence', 0.5))
                all_risk_factors.extend(result.get('risk_factors', []))

        # åŠ é‡å¹³å‡ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—
        if risk_scores:
            weighted_sum = sum(score * weight for score, weight in risk_scores)
            total_weight = sum(weight for _, weight in risk_scores)
            overall_risk_score = weighted_sum / total_weight if total_weight > 0 else 0.5
        else:
            overall_risk_score = 0.5

        # ãƒªã‚¹ã‚¯ã‚«ãƒ†ã‚´ãƒªæ±ºå®š
        if overall_risk_score >= self.risk_thresholds['critical']:
            risk_category = 'critical'
        elif overall_risk_score >= self.risk_thresholds['high']:
            risk_category = 'high'
        elif overall_risk_score >= self.risk_thresholds['medium']:
            risk_category = 'medium'
        else:
            risk_category = 'low'

        # æå¤±ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«æ¨å®š
        amount = float(transaction_data.get('amount', 0))
        estimated_loss_potential = amount * overall_risk_score * 0.1  # ç°¡ç•¥åŒ–

        return RiskAssessmentSummary(
            request_id=request_id,
            overall_risk_score=overall_risk_score,
            risk_category=risk_category,
            confidence_score=np.mean(confidences) if confidences else 0.5,
            analysis_methods=[method for method, _ in valid_results],
            key_risk_factors=list(set(all_risk_factors))[:10],  # é‡è¤‡å‰Šé™¤ã€ä¸Šä½10å€‹
            recommendations=list(set(all_recommendations))[:5],   # é‡è¤‡å‰Šé™¤ã€ä¸Šä½5å€‹
            estimated_loss_potential=estimated_loss_potential,
            processing_time_total=time.time() - start_time,
            component_results=component_results,
            timestamp=datetime.now()
        )

    def _serialize_result(self, result: Any) -> Dict[str, Any]:
        """çµæœã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚º"""

        if hasattr(result, '__dict__'):
            return asdict(result) if hasattr(result, '_fields') else result.__dict__
        elif isinstance(result, dict):
            return result
        else:
            return {'value': str(result), 'type': type(result).__name__}

    async def _evaluate_and_send_alerts(self, summary: RiskAssessmentSummary):
        """ã‚¢ãƒ©ãƒ¼ãƒˆè©•ä¾¡ãƒ»é€ä¿¡"""

        risk_score = summary.overall_risk_score

        # ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«æ±ºå®š
        alert_level = None
        if risk_score >= self.alert_thresholds['critical_risk']:
            alert_level = AlertLevel.CRITICAL
        elif risk_score >= self.alert_thresholds['high_risk']:
            alert_level = AlertLevel.HIGH
        elif risk_score >= self.alert_thresholds['medium_risk']:
            alert_level = AlertLevel.MEDIUM

        if alert_level:
            await self.alert_manager.create_alert(
                title=f"ãƒªã‚¹ã‚¯è©•ä¾¡ã‚¢ãƒ©ãƒ¼ãƒˆ: {summary.risk_category.upper()}",
                message=f"å–å¼•ID: {summary.request_id}\n"
                       f"ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {risk_score:.3f}\n"
                       f"æ¨å®šæå¤±: Â¥{summary.estimated_loss_potential:,.0f}\n"
                       f"ä¸»è¦è¦å› : {', '.join(summary.key_risk_factors[:3])}",
                level=alert_level,
                source="RiskCoordinator",
                metadata={
                    'request_id': summary.request_id,
                    'risk_score': risk_score,
                    'risk_category': summary.risk_category,
                    'analysis_methods': summary.analysis_methods
                }
            )

            logger.info(f"ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆé€ä¿¡: {alert_level} - {summary.request_id}")

    def _create_error_summary(
        self,
        request_id: str,
        error_message: str,
        transaction_data: Dict[str, Any],
        start_time: float
    ) -> RiskAssessmentSummary:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã‚µãƒãƒªãƒ¼ä½œæˆ"""

        return RiskAssessmentSummary(
            request_id=request_id,
            overall_risk_score=0.5,  # ä¸­ç¨‹åº¦ãƒªã‚¹ã‚¯ã¨ã—ã¦æ‰±ã†
            risk_category='medium',
            confidence_score=0.3,
            analysis_methods=['error_fallback'],
            key_risk_factors=['åˆ†æã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼'],
            recommendations=['ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«é€£çµ¡', 'æ‰‹å‹•ç¢ºèªå®Ÿæ–½'],
            estimated_loss_potential=float(transaction_data.get('amount', 0)) * 0.05,
            processing_time_total=time.time() - start_time,
            component_results={'error': error_message},
            timestamp=datetime.now()
        )

    def _update_performance_stats(self, summary: RiskAssessmentSummary, success: bool):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆæ›´æ–°"""

        self.performance_stats['total_assessments'] += 1

        if success:
            self.performance_stats['successful_assessments'] += 1
            self.performance_stats['risk_distribution'][summary.risk_category] += 1

        # å¹³å‡å‡¦ç†æ™‚é–“æ›´æ–°
        total = self.performance_stats['total_assessments']
        old_avg = self.performance_stats['avg_processing_time']
        new_time = summary.processing_time_total

        self.performance_stats['avg_processing_time'] = (
            (old_avg * (total - 1) + new_time) / total
        )

    def get_performance_summary(self) -> Dict[str, Any]:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚µãƒãƒªãƒ¼å–å¾—"""

        total = self.performance_stats['total_assessments']
        success_rate = (self.performance_stats['successful_assessments'] /
                       max(1, total))

        return {
            'total_assessments': total,
            'success_rate': success_rate,
            'avg_processing_time': self.performance_stats['avg_processing_time'],
            'component_usage': self.performance_stats['component_usage'],
            'risk_distribution': self.performance_stats['risk_distribution'],
            'recent_analyses': len(self.analysis_history),
            'generative_ai_stats': self.generative_ai_engine.get_performance_stats(),
            'fraud_detection_stats': self.fraud_engine.get_stats()
        }

    def get_recent_assessments(self, limit: int = 20) -> List[RiskAssessmentSummary]:
        """æœ€è¿‘ã®è©•ä¾¡çµæœå–å¾—"""
        return self.analysis_history[-limit:] if self.analysis_history else []

    async def batch_risk_assessment(
        self,
        transactions: List[Dict[str, Any]],
        concurrent_limit: int = 10
    ) -> List[RiskAssessmentSummary]:
        """ãƒãƒƒãƒãƒªã‚¹ã‚¯è©•ä¾¡"""

        logger.info(f"ãƒãƒƒãƒãƒªã‚¹ã‚¯è©•ä¾¡é–‹å§‹: {len(transactions)}ä»¶")

        semaphore = asyncio.Semaphore(concurrent_limit)

        async def assess_single(transaction):
            async with semaphore:
                return await self.comprehensive_risk_assessment(transaction)

        tasks = [assess_single(tx) for tx in transactions]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        valid_results = [r for r in results if not isinstance(r, Exception)]
        error_count = len(results) - len(valid_results)

        logger.info(f"ãƒãƒƒãƒè©•ä¾¡å®Œäº†: æˆåŠŸ{len(valid_results)}ä»¶, ã‚¨ãƒ©ãƒ¼{error_count}ä»¶")

        return valid_results

# ãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒ¢ç”¨é–¢æ•°
async def test_risk_coordinator():
    """ãƒªã‚¹ã‚¯ã‚³ãƒ¼ãƒ‡ã‚£ãƒãƒ¼ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ"""

    coordinator = RiskAnalysisCoordinator()

    # ãƒ†ã‚¹ãƒˆç”¨å–å¼•ãƒ‡ãƒ¼ã‚¿
    test_transaction = {
        'symbol': '7203',
        'type': 'buy',
        'amount': 5000000,  # 500ä¸‡å††
        'timestamp': datetime.now().isoformat(),
        'user_id': 'user_123',
        'account_balance': 10000000,
        'location': 'domestic',
        'device_info': {'type': 'mobile', 'os': 'ios'},
        'history': [],
        'market_conditions': {'volatility': 0.25}
    }

    print("ğŸ” åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯è©•ä¾¡ãƒ†ã‚¹ãƒˆé–‹å§‹...")

    # ãƒªã‚¹ã‚¯è©•ä¾¡å®Ÿè¡Œ
    assessment = await coordinator.comprehensive_risk_assessment(test_transaction)

    print(f"âœ… è©•ä¾¡å®Œäº†: {assessment.request_id}")
    print(f"ğŸ“Š ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢: {assessment.overall_risk_score:.3f}")
    print(f"âš ï¸ ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«: {assessment.risk_category}")
    print(f"ğŸ¯ ä¿¡é ¼åº¦: {assessment.confidence_score:.3f}")
    print(f"â±ï¸ å‡¦ç†æ™‚é–“: {assessment.processing_time_total:.3f}ç§’")
    print(f"ğŸ”§ ä½¿ç”¨æ‰‹æ³•: {', '.join(assessment.analysis_methods)}")
    print(f"ğŸ’° æ¨å®šæå¤±ãƒãƒ†ãƒ³ã‚·ãƒ£ãƒ«: Â¥{assessment.estimated_loss_potential:,.0f}")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
    stats = coordinator.get_performance_summary()
    print(f"\nğŸ“ˆ ã‚·ã‚¹ãƒ†ãƒ çµ±è¨ˆ:")
    print(f"  ç·è©•ä¾¡æ•°: {stats['total_assessments']}")
    print(f"  æˆåŠŸç‡: {stats['success_rate']:.1%}")
    print(f"  å¹³å‡å‡¦ç†æ™‚é–“: {stats['avg_processing_time']:.3f}ç§’")

if __name__ == "__main__":
    asyncio.run(test_risk_coordinator())
