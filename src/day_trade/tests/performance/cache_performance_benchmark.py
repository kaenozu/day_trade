#!/usr/bin/env python3
"""
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
Issue #377: é«˜åº¦ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ã®æ¤œè¨¼

æ§˜ã€…ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã®æ€§èƒ½æ¸¬å®šãƒ»æ¯”è¼ƒãƒ†ã‚¹ãƒˆ
"""

import gc
import json
import random
import statistics
import time
import tracemalloc
from concurrent.futures import ThreadPoolExecutor, as_completed
from dataclasses import asdict, dataclass
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional

import numpy as np
import pandas as pd
import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from ...cache.distributed_cache_system import get_distributed_cache
    from ...cache.persistent_cache_system import get_persistent_cache
    from ...cache.smart_invalidation_strategies import get_invalidation_manager
    from ...data.enhanced_stock_fetcher import (
        EnhancedStockFetcher,
        create_enhanced_stock_fetcher,
    )
    from ...utils.logging_config import get_context_logger
except ImportError:
    import logging

    logging.basicConfig(level=logging.INFO)

    def get_context_logger(name):
        return logging.getLogger(name)

    # ç°¡æ˜“ãƒ¢ãƒƒã‚¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    class EnhancedStockFetcher:
        def __init__(self, **kwargs):
            self.cache_config = kwargs

        def get_current_price(self, code):
            time.sleep(0.1)  # APIé…å»¶ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            return {"price": random.uniform(100, 1000), "timestamp": time.time()}

        def get_cache_stats(self):
            return {"hits": 50, "misses": 50, "hit_rate": 0.5}

    def create_enhanced_stock_fetcher(**kwargs):
        return EnhancedStockFetcher(**kwargs)

    def get_persistent_cache(**kwargs):
        return None

    def get_distributed_cache(**kwargs):
        return None


logger = get_context_logger(__name__)


@dataclass
class PerformanceMetrics:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šçµæœ"""

    operation_name: str
    total_operations: int
    success_operations: int
    failed_operations: int
    total_time_seconds: float
    avg_time_ms: float
    min_time_ms: float
    max_time_ms: float
    median_time_ms: float
    p95_time_ms: float
    p99_time_ms: float
    operations_per_second: float
    memory_usage_mb: float
    memory_delta_mb: float
    cache_hit_rate: Optional[float] = None
    cache_stats: Optional[Dict[str, Any]] = None


class BenchmarkRunner:
    """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self, results_dir: str = "benchmark_results"):
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True)
        self.results = []
        self.test_data = self._generate_test_data()

        logger.info(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œæº–å‚™å®Œäº†: {results_dir}")

    def _generate_test_data(self) -> List[str]:
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        # æ—¥æœ¬ã®ä¸»è¦æ ªå¼éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰
        major_stocks = [
            "7203",
            "6758",
            "9984",
            "9983",
            "6861",
            "8306",
            "9432",
            "4502",
            "8316",
            "7267",
            "6367",
            "9434",
            "4568",
            "6902",
            "6954",
            "8035",
            "9020",
            "4063",
            "6098",
            "3382",
            "6501",
            "7974",
            "4901",
            "9022",
        ]

        # è¿½åŠ ã®ãƒ©ãƒ³ãƒ€ãƒ éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ç”Ÿæˆ
        additional_stocks = [f"{random.randint(1000, 9999)}" for _ in range(176)]

        return major_stocks + additional_stocks

    def run_memory_benchmark(
        self, test_function: Callable, name: str, iterations: int = 100
    ) -> PerformanceMetrics:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æ¸¬å®šä»˜ããƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        logger.info(f"ãƒ¡ãƒ¢ãƒªãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹: {name} ({iterations}å›)")

        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        gc.collect()

        # ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ¼ã‚¹é–‹å§‹
        tracemalloc.start()
        process = psutil.Process()
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        execution_times = []
        success_count = 0
        failed_count = 0

        start_time = time.perf_counter()

        for i in range(iterations):
            try:
                operation_start = time.perf_counter()
                result = test_function()
                operation_end = time.perf_counter()

                execution_times.append((operation_end - operation_start) * 1000)  # ms
                success_count += 1

                if result is None:
                    failed_count += 1
                    success_count -= 1

            except Exception as e:
                logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ ({i}): {e}")
                failed_count += 1

        total_time = time.perf_counter() - start_time

        # ãƒ¡ãƒ¢ãƒªæ¸¬å®š
        current_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_delta = current_memory - initial_memory

        # ãƒ¡ãƒ¢ãƒªãƒˆãƒ¬ãƒ¼ã‚¹çµ‚äº†
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()

        # çµ±è¨ˆè¨ˆç®—
        if execution_times:
            avg_time = statistics.mean(execution_times)
            min_time = min(execution_times)
            max_time = max(execution_times)
            median_time = statistics.median(execution_times)
            p95_time = np.percentile(execution_times, 95)
            p99_time = np.percentile(execution_times, 99)
        else:
            avg_time = min_time = max_time = median_time = p95_time = p99_time = 0

        ops_per_second = success_count / total_time if total_time > 0 else 0

        metrics = PerformanceMetrics(
            operation_name=name,
            total_operations=iterations,
            success_operations=success_count,
            failed_operations=failed_count,
            total_time_seconds=total_time,
            avg_time_ms=avg_time,
            min_time_ms=min_time,
            max_time_ms=max_time,
            median_time_ms=median_time,
            p95_time_ms=p95_time,
            p99_time_ms=p99_time,
            operations_per_second=ops_per_second,
            memory_usage_mb=current_memory,
            memory_delta_mb=memory_delta,
        )

        self.results.append(metrics)
        logger.info(
            f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†: {name}, å¹³å‡æ™‚é–“: {avg_time:.2f}ms, OPS: {ops_per_second:.1f}"
        )

        return metrics

    def benchmark_enhanced_stock_fetcher(self) -> List[PerformanceMetrics]:
        """Enhanced Stock Fetcherãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("Enhanced Stock Fetcher ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")
        results = []

        # æ§˜ã€…ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥è¨­å®šã§ãƒ†ã‚¹ãƒˆ
        cache_configs = [
            {"persistent_cache_enabled": False, "distributed_cache_enabled": False},
            {"persistent_cache_enabled": True, "distributed_cache_enabled": False},
            {
                "persistent_cache_enabled": True,
                "distributed_cache_enabled": False,
                "smart_invalidation_enabled": True,
            },
            {
                "persistent_cache_enabled": True,
                "distributed_cache_enabled": False,
                "enable_multi_layer_cache": True,
                "l1_memory_size": 2000,
            },
        ]

        config_names = [
            "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãªã—",
            "æ°¸ç¶šã‚­ãƒ£ãƒƒã‚·ãƒ¥ã®ã¿",
            "ã‚¹ãƒãƒ¼ãƒˆç„¡åŠ¹åŒ–",
            "ãƒãƒ«ãƒãƒ¬ã‚¤ãƒ¤ãƒ¼",
        ]

        for config, name in zip(cache_configs, config_names):
            try:
                fetcher = create_enhanced_stock_fetcher(cache_config=config)

                # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ— (ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæ¸¬å®šç”¨)
                def warmup():
                    for code in self.test_data[:20]:
                        fetcher.get_current_price(code)

                warmup()

                # å®Ÿéš›ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
                def benchmark_operation():
                    code = random.choice(self.test_data)
                    return fetcher.get_current_price(code)

                metrics = self.run_memory_benchmark(
                    benchmark_operation, f"stock_fetcher_{name}", iterations=200
                )

                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆè¿½åŠ 
                try:
                    cache_stats = fetcher.get_cache_stats()
                    metrics.cache_hit_rate = cache_stats.get("performance_stats", {}).get(
                        "cache_hit_rate", 0
                    )
                    metrics.cache_stats = cache_stats
                except Exception as e:
                    logger.warning(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—å¤±æ•—: {e}")

                results.append(metrics)

            except Exception as e:
                logger.error(f"Stock Fetcherãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ ({name}): {e}")

        return results

    def benchmark_concurrent_access(self) -> PerformanceMetrics:
        """ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")

        fetcher = create_enhanced_stock_fetcher(
            cache_config={
                "persistent_cache_enabled": True,
                "enable_multi_layer_cache": True,
                "l1_memory_size": 1000,
            }
        )

        # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        for code in self.test_data[:10]:
            fetcher.get_current_price(code)

        def worker_function(worker_id: int) -> List[float]:
            """ãƒ¯ãƒ¼ã‚«ãƒ¼é–¢æ•°"""
            times = []
            for i in range(50):  # å„ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒ50å›å®Ÿè¡Œ
                code = random.choice(self.test_data)
                start_time = time.perf_counter()
                result = fetcher.get_current_price(code)
                end_time = time.perf_counter()

                if result is not None:
                    times.append((end_time - start_time) * 1000)

            return times

        # ä¸¦è¡Œå®Ÿè¡Œ
        num_workers = 10
        start_time = time.perf_counter()

        with ThreadPoolExecutor(max_workers=num_workers) as executor:
            futures = [executor.submit(worker_function, i) for i in range(num_workers)]
            all_times = []

            for future in as_completed(futures):
                try:
                    worker_times = future.result()
                    all_times.extend(worker_times)
                except Exception as e:
                    logger.error(f"ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¨ãƒ©ãƒ¼: {e}")

        total_time = time.perf_counter() - start_time

        if all_times:
            metrics = PerformanceMetrics(
                operation_name="ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹",
                total_operations=len(all_times),
                success_operations=len(all_times),
                failed_operations=0,
                total_time_seconds=total_time,
                avg_time_ms=statistics.mean(all_times),
                min_time_ms=min(all_times),
                max_time_ms=max(all_times),
                median_time_ms=statistics.median(all_times),
                p95_time_ms=np.percentile(all_times, 95),
                p99_time_ms=np.percentile(all_times, 99),
                operations_per_second=len(all_times) / total_time,
                memory_usage_mb=psutil.Process().memory_info().rss / 1024 / 1024,
                memory_delta_mb=0,
            )

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
            try:
                cache_stats = fetcher.get_cache_stats()
                metrics.cache_hit_rate = cache_stats.get("performance_stats", {}).get(
                    "cache_hit_rate", 0
                )
                metrics.cache_stats = cache_stats
            except Exception:
                pass

            self.results.append(metrics)
            return metrics

        return None

    def benchmark_cache_eviction(self) -> PerformanceMetrics:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€€é¿æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
        logger.info("ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€€é¿æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹")

        # å°ã•ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã§å¼·åˆ¶çš„ã«é€€é¿ã‚’ç™ºç”Ÿã•ã›ã‚‹
        fetcher = create_enhanced_stock_fetcher(
            cache_config={
                "persistent_cache_enabled": True,
                "l1_memory_size": 50,  # å°ã•ãªL1ã‚­ãƒ£ãƒƒã‚·ãƒ¥
                "enable_multi_layer_cache": True,
            }
        )

        def eviction_test():
            # å¤§é‡ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ãªãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’æº¢ã‚Œã•ã›ã‚‹
            code = f"{random.randint(10000, 99999)}"
            return fetcher.get_current_price(code)

        return self.run_memory_benchmark(eviction_test, "ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€€é¿", iterations=300)

    def generate_report(self, output_file: str = None) -> Dict[str, Any]:
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.results:
            logger.warning("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return {}

        # çµæœã‚’DataFrameã«å¤‰æ›
        df = pd.DataFrame([asdict(r) for r in self.results])

        # çµ±è¨ˆã‚µãƒãƒªãƒ¼ä½œæˆ
        summary = {
            "benchmark_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_benchmarks": len(self.results),
            "performance_rankings": {},
            "memory_analysis": {},
            "cache_effectiveness": {},
            "recommendations": [],
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        if "operations_per_second" in df.columns:
            perf_ranking = df.nlargest(5, "operations_per_second")[
                ["operation_name", "operations_per_second", "avg_time_ms"]
            ]
            summary["performance_rankings"] = perf_ranking.to_dict("records")

        # ãƒ¡ãƒ¢ãƒªåˆ†æ
        if "memory_delta_mb" in df.columns:
            memory_stats = {
                "max_memory_usage": df["memory_usage_mb"].max(),
                "avg_memory_delta": df["memory_delta_mb"].mean(),
                "high_memory_operations": df[df["memory_delta_mb"] > 10]["operation_name"].tolist(),
            }
            summary["memory_analysis"] = memory_stats

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœåˆ†æ
        cache_results = df[df["cache_hit_rate"].notna()]
        if not cache_results.empty:
            cache_analysis = {
                "avg_hit_rate": cache_results["cache_hit_rate"].mean(),
                "best_cache_config": cache_results.loc[
                    cache_results["cache_hit_rate"].idxmax(), "operation_name"
                ],
                "cache_performance_impact": cache_results["operations_per_second"].max()
                / cache_results["operations_per_second"].min(),
            }
            summary["cache_effectiveness"] = cache_analysis

        # æ¨å¥¨äº‹é …
        recommendations = []

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒä½ã„å ´åˆ
        if cache_results.empty or cache_results["cache_hit_rate"].mean() < 0.5:
            recommendations.append(
                "ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒä½ã„ã§ã™ã€‚TTLè¨­å®šã®è¦‹ç›´ã—ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºæ‹¡å¼µã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„å ´åˆ
        if df["memory_delta_mb"].max() > 50:
            recommendations.append(
                "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ã§ã™ã€‚ãƒ‡ãƒ¼ã‚¿åœ§ç¸®ã¾ãŸã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        # å¿œç­”æ™‚é–“ãŒé…ã„å ´åˆ
        if df["avg_time_ms"].max() > 1000:
            recommendations.append(
                "å¿œç­”æ™‚é–“ãŒé…ã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ¬ã‚¤ãƒ¤ãƒ¼ã®è¿½åŠ ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        summary["recommendations"] = recommendations

        # è©³ç´°ãƒ‡ãƒ¼ã‚¿ã‚‚å«ã‚ã‚‹
        summary["detailed_results"] = df.to_dict("records")

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output_file:
            output_path = self.results_dir / output_file
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(summary, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœä¿å­˜: {output_path}")

        return summary

    def run_full_benchmark(self) -> Dict[str, Any]:
        """ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        logger.info("=== ãƒ•ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯é–‹å§‹ ===")

        try:
            # å„ç¨®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
            logger.info("1. Enhanced Stock Fetcher ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            self.benchmark_enhanced_stock_fetcher()

            logger.info("2. ä¸¦è¡Œã‚¢ã‚¯ã‚»ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            self.benchmark_concurrent_access()

            logger.info("3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€€é¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯")
            self.benchmark_cache_eviction()

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            logger.info("4. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            report = self.generate_report("cache_performance_report.json")

            logger.info("=== ãƒ•ãƒ«ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº† ===")
            return report

        except Exception as e:
            logger.error(f"ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}


def run_cache_performance_analysis():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ€§èƒ½åˆ†æãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=== Issue #377 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ ===")

    # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ
    runner = BenchmarkRunner()
    report = runner.run_full_benchmark()

    # çµæœè¡¨ç¤º
    if "error" not in report:
        print("\nğŸ“Š ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯çµæœã‚µãƒãƒªãƒ¼:")
        print(f"å®Ÿè¡Œæ™‚åˆ»: {report.get('benchmark_timestamp')}")
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {report.get('total_benchmarks')}")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        rankings = report.get("performance_rankings", [])
        if rankings:
            print("\nğŸ† ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚° (OPS):")
            for i, result in enumerate(rankings, 1):
                print(
                    f"  {i}. {result['operation_name']}: {result['operations_per_second']:.1f} OPS "
                    f"(å¹³å‡ {result['avg_time_ms']:.2f}ms)"
                )

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ
        cache_effectiveness = report.get("cache_effectiveness", {})
        if cache_effectiveness:
            print("\nğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœ:")
            print(f"  å¹³å‡ãƒ’ãƒƒãƒˆç‡: {cache_effectiveness.get('avg_hit_rate', 0):.2%}")
            print(f"  æœ€é«˜æ€§èƒ½è¨­å®š: {cache_effectiveness.get('best_cache_config')}")
            print(f"  æ€§èƒ½å‘ä¸Šå€ç‡: {cache_effectiveness.get('cache_performance_impact', 1):.1f}x")

        # ãƒ¡ãƒ¢ãƒªåˆ†æ
        memory_analysis = report.get("memory_analysis", {})
        if memory_analysis:
            print("\nğŸ§  ãƒ¡ãƒ¢ãƒªåˆ†æ:")
            print(f"  æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {memory_analysis.get('max_memory_usage', 0):.1f} MB")
            print(f"  å¹³å‡ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_analysis.get('avg_memory_delta', 0):.1f} MB")

        # æ¨å¥¨äº‹é …
        recommendations = report.get("recommendations", [])
        if recommendations:
            print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")

        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {runner.results_dir}/cache_performance_report.json")
    else:
        print(f"âŒ ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {report['error']}")

    print("\n=== ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æå®Œäº† ===")
    return report


if __name__ == "__main__":
    run_cache_performance_analysis()
