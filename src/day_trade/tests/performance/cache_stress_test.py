#!/usr/bin/env python3
"""
ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ
Issue #377: é«˜åº¦ãªã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°æˆ¦ç•¥ã®è² è·ãƒ†ã‚¹ãƒˆ

é«˜è² è·çŠ¶æ³ã§ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚·ã‚¹ãƒ†ãƒ å®‰å®šæ€§ãƒ»æ€§èƒ½ãƒ†ã‚¹ãƒˆ
"""

import gc
import json
import random
import statistics
import threading
import time
from dataclasses import asdict, dataclass
from pathlib import Path
from queue import Empty, Queue
from typing import Any, Dict, List, Optional

import numpy as np
import pandas as pd
import psutil

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
try:
    from ...cache.persistent_cache_system import get_persistent_cache
    from ...data.enhanced_stock_fetcher import create_enhanced_stock_fetcher
    from ...utils.logging_config import get_context_logger
except ImportError:
    import logging

    logging.basicConfig(level=logging.INFO)

    def get_context_logger(name):
        return logging.getLogger(name)

    # ç°¡æ˜“ãƒ¢ãƒƒã‚¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
    def create_enhanced_stock_fetcher(**kwargs):
        class MockFetcher:
            def get_current_price(self, code):
                time.sleep(0.05)  # APIé…å»¶ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                return {"price": random.uniform(100, 1000), "timestamp": time.time()}

            def get_cache_stats(self):
                return {"hits": 100, "misses": 50, "hit_rate": 0.67}

        return MockFetcher()

    def get_persistent_cache(**kwargs):
        return None


logger = get_context_logger(__name__)


@dataclass
class StressTestResult:
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœ"""

    test_name: str
    duration_seconds: float
    total_operations: int
    successful_operations: int
    failed_operations: int
    operations_per_second: float
    avg_response_time_ms: float
    max_response_time_ms: float
    error_rate: float
    memory_usage_mb: float
    cpu_usage_percent: float
    concurrent_users: int
    cache_hit_rate: Optional[float] = None
    errors: List[str] = None


class StressTestRunner:
    """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self, results_dir: str = "stress_test_results"):
        self.results_dir = Path(results_dir)
        self.results_dir.mkdir(exist_ok=True)
        self.results = []
        self.stop_event = threading.Event()

        # ãƒ†ã‚¹ãƒˆç”¨æ ªå¼ã‚³ãƒ¼ãƒ‰
        self.test_codes = [f"{random.randint(1000, 9999)}" for _ in range(500)]

        logger.info(f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œæº–å‚™å®Œäº†: {results_dir}")

    def monitor_system_resources(self, duration_seconds: int) -> Dict[str, float]:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–"""
        process = psutil.Process()
        cpu_samples = []
        memory_samples = []

        start_time = time.time()

        while time.time() - start_time < duration_seconds:
            try:
                cpu_samples.append(process.cpu_percent())
                memory_samples.append(process.memory_info().rss / 1024 / 1024)  # MB
                time.sleep(0.5)
            except Exception as e:
                logger.debug(f"ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")

        return {
            "avg_cpu_percent": statistics.mean(cpu_samples) if cpu_samples else 0,
            "max_cpu_percent": max(cpu_samples) if cpu_samples else 0,
            "avg_memory_mb": statistics.mean(memory_samples) if memory_samples else 0,
            "max_memory_mb": max(memory_samples) if memory_samples else 0,
        }

    def stress_test_single_thread(
        self, duration_seconds: int = 60, operations_per_second: int = 10
    ) -> StressTestResult:
        """ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info(
            f"ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹: {duration_seconds}ç§’é–“, {operations_per_second}OPS"
        )

        # Enhanced Stock Fetcheræº–å‚™
        fetcher = create_enhanced_stock_fetcher(
            cache_config={
                "persistent_cache_enabled": True,
                "enable_multi_layer_cache": True,
                "l1_memory_size": 1000,
            }
        )

        # ã‚«ã‚¦ãƒ³ã‚¿ãƒ¼åˆæœŸåŒ–
        total_ops = 0
        successful_ops = 0
        failed_ops = 0
        response_times = []
        errors = []

        start_time = time.time()
        interval = 1.0 / operations_per_second

        # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–é–‹å§‹
        resource_monitor = threading.Thread(
            target=lambda: self.monitor_system_resources(duration_seconds), daemon=True
        )
        resource_stats = {}

        try:
            while time.time() - start_time < duration_seconds:
                operation_start = time.perf_counter()

                try:
                    code = random.choice(self.test_codes)
                    result = fetcher.get_current_price(code)

                    operation_end = time.perf_counter()
                    response_times.append((operation_end - operation_start) * 1000)

                    if result:
                        successful_ops += 1
                    else:
                        failed_ops += 1
                        errors.append("No result returned")

                except Exception as e:
                    failed_ops += 1
                    errors.append(str(e))
                    logger.debug(f"æ“ä½œã‚¨ãƒ©ãƒ¼: {e}")

                total_ops += 1

                # ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡
                elapsed = time.perf_counter() - operation_start
                if elapsed < interval:
                    time.sleep(interval - elapsed)

        except KeyboardInterrupt:
            logger.info("ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆä¸­æ–­")

        total_duration = time.time() - start_time

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆå–å¾—
        cache_hit_rate = None
        try:
            cache_stats = fetcher.get_cache_stats()
            cache_hit_rate = cache_stats.get("performance_stats", {}).get(
                "cache_hit_rate", 0
            )
        except Exception:
            pass

        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹å–å¾—
        process = psutil.Process()
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        cpu_usage = process.cpu_percent()

        result = StressTestResult(
            test_name="ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰",
            duration_seconds=total_duration,
            total_operations=total_ops,
            successful_operations=successful_ops,
            failed_operations=failed_ops,
            operations_per_second=total_ops / total_duration,
            avg_response_time_ms=statistics.mean(response_times)
            if response_times
            else 0,
            max_response_time_ms=max(response_times) if response_times else 0,
            error_rate=failed_ops / total_ops if total_ops > 0 else 0,
            memory_usage_mb=memory_usage,
            cpu_usage_percent=cpu_usage,
            concurrent_users=1,
            cache_hit_rate=cache_hit_rate,
            errors=list(set(errors)),  # é‡è¤‡é™¤å»
        )

        self.results.append(result)
        logger.info(
            f"ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ãƒ†ã‚¹ãƒˆå®Œäº†: {successful_ops}/{total_ops} æˆåŠŸ, OPS={result.operations_per_second:.1f}"
        )

        return result

    def stress_test_multi_thread(
        self,
        duration_seconds: int = 60,
        concurrent_threads: int = 10,
        operations_per_thread: int = 5,
    ) -> StressTestResult:
        """ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info(
            f"ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹: {concurrent_threads}ã‚¹ãƒ¬ãƒƒãƒ‰, {duration_seconds}ç§’é–“"
        )

        # å…±æœ‰çµæœåé›†
        results_queue = Queue()
        stop_event = threading.Event()

        def worker_thread(thread_id: int):
            """ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚¹ãƒ¬ãƒƒãƒ‰"""
            fetcher = create_enhanced_stock_fetcher(
                cache_config={
                    "persistent_cache_enabled": True,
                    "enable_multi_layer_cache": True,
                    "l1_memory_size": 500,
                }
            )

            local_stats = {
                "total": 0,
                "success": 0,
                "failed": 0,
                "response_times": [],
                "errors": [],
            }

            interval = 1.0 / operations_per_thread
            thread_start = time.time()

            while (
                not stop_event.is_set()
                and (time.time() - thread_start) < duration_seconds
            ):
                operation_start = time.perf_counter()

                try:
                    code = random.choice(self.test_codes)
                    result = fetcher.get_current_price(code)

                    operation_end = time.perf_counter()
                    local_stats["response_times"].append(
                        (operation_end - operation_start) * 1000
                    )

                    if result:
                        local_stats["success"] += 1
                    else:
                        local_stats["failed"] += 1
                        local_stats["errors"].append("No result")

                except Exception as e:
                    local_stats["failed"] += 1
                    local_stats["errors"].append(str(e))

                local_stats["total"] += 1

                # ãƒ¬ãƒ¼ãƒˆåˆ¶å¾¡
                elapsed = time.perf_counter() - operation_start
                if elapsed < interval:
                    time.sleep(interval - elapsed)

            # çµæœã‚’ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
            results_queue.put((thread_id, local_stats))

        # ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
        start_time = time.time()
        threads = []

        for i in range(concurrent_threads):
            thread = threading.Thread(target=worker_thread, args=(i,))
            thread.start()
            threads.append(thread)

        # æŒ‡å®šæ™‚é–“å¾…æ©Ÿ
        time.sleep(duration_seconds)
        stop_event.set()

        # ã‚¹ãƒ¬ãƒƒãƒ‰çµ‚äº†å¾…æ©Ÿ
        for thread in threads:
            thread.join(timeout=5)

        total_duration = time.time() - start_time

        # çµæœé›†ç´„
        total_ops = 0
        successful_ops = 0
        failed_ops = 0
        all_response_times = []
        all_errors = []

        while not results_queue.empty():
            try:
                thread_id, stats = results_queue.get_nowait()
                total_ops += stats["total"]
                successful_ops += stats["success"]
                failed_ops += stats["failed"]
                all_response_times.extend(stats["response_times"])
                all_errors.extend(stats["errors"])
            except Empty:
                break

        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
        process = psutil.Process()
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        cpu_usage = process.cpu_percent()

        result = StressTestResult(
            test_name=f"ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰_{concurrent_threads}",
            duration_seconds=total_duration,
            total_operations=total_ops,
            successful_operations=successful_ops,
            failed_operations=failed_ops,
            operations_per_second=total_ops / total_duration,
            avg_response_time_ms=statistics.mean(all_response_times)
            if all_response_times
            else 0,
            max_response_time_ms=max(all_response_times) if all_response_times else 0,
            error_rate=failed_ops / total_ops if total_ops > 0 else 0,
            memory_usage_mb=memory_usage,
            cpu_usage_percent=cpu_usage,
            concurrent_users=concurrent_threads,
            errors=list(set(all_errors)),
        )

        self.results.append(result)
        logger.info(
            f"ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ãƒ†ã‚¹ãƒˆå®Œäº†: {successful_ops}/{total_ops} æˆåŠŸ, OPS={result.operations_per_second:.1f}"
        )

        return result

    def stress_test_memory_pressure(
        self, duration_seconds: int = 30, memory_pressure_mb: int = 100
    ) -> StressTestResult:
        """ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info(
            f"ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆé–‹å§‹: {memory_pressure_mb}MBåœ§è¿«, {duration_seconds}ç§’é–“"
        )

        # ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ç”Ÿæˆï¼ˆå¤§é‡ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
        memory_hogs = []

        try:
            # æŒ‡å®šã•ã‚ŒãŸãƒ¡ãƒ¢ãƒªé‡ã®ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ä½œæˆ
            chunk_size = 10  # 10MBãšã¤
            chunks = memory_pressure_mb // chunk_size

            for i in range(chunks):
                # 10MBã®ãƒ©ãƒ³ãƒ€ãƒ ãƒ‡ãƒ¼ã‚¿
                dummy_data = np.random.bytes(chunk_size * 1024 * 1024)
                memory_hogs.append(dummy_data)

            logger.info(
                f"ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ç”Ÿæˆå®Œäº†: {len(memory_hogs) * chunk_size}MB"
            )

            # Enhanced Stock Fetcherï¼ˆå°ã•ãªã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºï¼‰
            fetcher = create_enhanced_stock_fetcher(
                cache_config={
                    "persistent_cache_enabled": True,
                    "l1_memory_size": 100,  # å°ã•ãªãƒ¡ãƒ¢ãƒªã‚­ãƒ£ãƒƒã‚·ãƒ¥
                    "enable_multi_layer_cache": True,
                }
            )

            # ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            total_ops = 0
            successful_ops = 0
            failed_ops = 0
            response_times = []
            errors = []

            start_time = time.time()

            while time.time() - start_time < duration_seconds:
                operation_start = time.perf_counter()

                try:
                    code = random.choice(self.test_codes)
                    result = fetcher.get_current_price(code)

                    operation_end = time.perf_counter()
                    response_times.append((operation_end - operation_start) * 1000)

                    if result:
                        successful_ops += 1
                    else:
                        failed_ops += 1
                        errors.append("No result")

                except Exception as e:
                    failed_ops += 1
                    errors.append(str(e))

                total_ops += 1
                time.sleep(0.1)  # 10OPSåˆ¶é™

            total_duration = time.time() - start_time

            # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
            process = psutil.Process()
            memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            cpu_usage = process.cpu_percent()

            result = StressTestResult(
                test_name=f"ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼_{memory_pressure_mb}MB",
                duration_seconds=total_duration,
                total_operations=total_ops,
                successful_operations=successful_ops,
                failed_operations=failed_ops,
                operations_per_second=total_ops / total_duration,
                avg_response_time_ms=statistics.mean(response_times)
                if response_times
                else 0,
                max_response_time_ms=max(response_times) if response_times else 0,
                error_rate=failed_ops / total_ops if total_ops > 0 else 0,
                memory_usage_mb=memory_usage,
                cpu_usage_percent=cpu_usage,
                concurrent_users=1,
                errors=list(set(errors)),
            )

            self.results.append(result)
            logger.info(
                f"ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆå®Œäº†: {successful_ops}/{total_ops} æˆåŠŸ"
            )

        finally:
            # ãƒ¡ãƒ¢ãƒªè§£æ”¾
            memory_hogs.clear()
            gc.collect()

        return result

    def stress_test_cache_invalidation(
        self, duration_seconds: int = 60
    ) -> StressTestResult:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹: {duration_seconds}ç§’é–“")

        fetcher = create_enhanced_stock_fetcher(
            cache_config={
                "persistent_cache_enabled": True,
                "smart_invalidation_enabled": True,
                "enable_multi_layer_cache": True,
                "l1_memory_size": 1000,
            }
        )

        # åˆæœŸãƒ‡ãƒ¼ã‚¿ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        for code in self.test_codes[:100]:
            fetcher.get_current_price(code)

        total_ops = 0
        successful_ops = 0
        failed_ops = 0
        response_times = []
        errors = []

        start_time = time.time()

        while time.time() - start_time < duration_seconds:
            operation_start = time.perf_counter()

            try:
                # 50%ã®ç¢ºç‡ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–
                if random.random() < 0.5:
                    # æ—¢å­˜ã®ã‚³ãƒ¼ãƒ‰ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‹™ã„
                    code = random.choice(self.test_codes[:100])
                else:
                    # æ–°ã—ã„ã‚³ãƒ¼ãƒ‰ã§ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ç™ºç”Ÿ
                    code = f"{random.randint(10000, 99999)}"

                result = fetcher.get_current_price(code)

                # 10%ã®ç¢ºç‡ã§ç‰¹å®šéŠ˜æŸ„ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–
                if random.random() < 0.1:
                    invalidate_code = random.choice(self.test_codes[:50])
                    fetcher.invalidate_symbol_cache(invalidate_code)

                operation_end = time.perf_counter()
                response_times.append((operation_end - operation_start) * 1000)

                if result:
                    successful_ops += 1
                else:
                    failed_ops += 1
                    errors.append("No result")

            except Exception as e:
                failed_ops += 1
                errors.append(str(e))

            total_ops += 1
            time.sleep(0.05)  # 20OPS

        total_duration = time.time() - start_time

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
        cache_hit_rate = None
        try:
            cache_stats = fetcher.get_cache_stats()
            cache_hit_rate = cache_stats.get("performance_stats", {}).get(
                "cache_hit_rate", 0
            )
        except Exception:
            pass

        # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
        process = psutil.Process()
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        cpu_usage = process.cpu_percent()

        result = StressTestResult(
            test_name="ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–",
            duration_seconds=total_duration,
            total_operations=total_ops,
            successful_operations=successful_ops,
            failed_operations=failed_ops,
            operations_per_second=total_ops / total_duration,
            avg_response_time_ms=statistics.mean(response_times)
            if response_times
            else 0,
            max_response_time_ms=max(response_times) if response_times else 0,
            error_rate=failed_ops / total_ops if total_ops > 0 else 0,
            memory_usage_mb=memory_usage,
            cpu_usage_percent=cpu_usage,
            concurrent_users=1,
            cache_hit_rate=cache_hit_rate,
            errors=list(set(errors)),
        )

        self.results.append(result)
        logger.info(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ãƒ†ã‚¹ãƒˆå®Œäº†: ãƒ’ãƒƒãƒˆç‡={cache_hit_rate:.2%}")

        return result

    def generate_stress_report(self, output_file: str = None) -> Dict[str, Any]:
        """ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        if not self.results:
            logger.warning("ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœãŒã‚ã‚Šã¾ã›ã‚“")
            return {}

        # çµæœã‚’DataFrameã«å¤‰æ›
        df = pd.DataFrame([asdict(r) for r in self.results])

        report = {
            "stress_test_timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "total_tests": len(self.results),
            "test_summary": {},
            "stability_analysis": {},
            "resource_usage": {},
            "error_analysis": {},
            "recommendations": [],
        }

        # ãƒ†ã‚¹ãƒˆã‚µãƒãƒªãƒ¼
        report["test_summary"] = {
            "best_performance_ops": df["operations_per_second"].max(),
            "worst_performance_ops": df["operations_per_second"].min(),
            "avg_error_rate": df["error_rate"].mean(),
            "max_error_rate": df["error_rate"].max(),
            "avg_response_time": df["avg_response_time_ms"].mean(),
            "max_response_time": df["max_response_time_ms"].max(),
        }

        # å®‰å®šæ€§åˆ†æ
        stable_tests = df[df["error_rate"] < 0.01]  # ã‚¨ãƒ©ãƒ¼ç‡1%æœªæº€
        report["stability_analysis"] = {
            "stable_tests_count": len(stable_tests),
            "stability_rate": len(stable_tests) / len(df) * 100,
            "most_stable_test": stable_tests.loc[
                stable_tests["error_rate"].idxmin(), "test_name"
            ]
            if not stable_tests.empty
            else None,
            "least_stable_test": df.loc[df["error_rate"].idxmax(), "test_name"],
        }

        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
        report["resource_usage"] = {
            "max_memory_usage": df["memory_usage_mb"].max(),
            "avg_memory_usage": df["memory_usage_mb"].mean(),
            "max_cpu_usage": df["cpu_usage_percent"].max(),
            "avg_cpu_usage": df["cpu_usage_percent"].mean(),
            "high_resource_tests": df[df["memory_usage_mb"] > 100][
                "test_name"
            ].tolist(),
        }

        # ã‚¨ãƒ©ãƒ¼åˆ†æ
        all_errors = []
        for result in self.results:
            if result.errors:
                all_errors.extend(result.errors)

        if all_errors:
            error_counts = {}
            for error in all_errors:
                error_counts[error] = error_counts.get(error, 0) + 1

            report["error_analysis"] = {
                "total_unique_errors": len(error_counts),
                "most_common_errors": sorted(
                    error_counts.items(), key=lambda x: x[1], reverse=True
                )[:5],
            }

        # æ¨å¥¨äº‹é …
        recommendations = []

        if df["error_rate"].mean() > 0.05:
            recommendations.append(
                "ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºã®æ‹¡å¼µã¾ãŸã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šã®è¦‹ç›´ã—ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        if df["max_response_time_ms"].max() > 5000:
            recommendations.append(
                "å¿œç­”æ™‚é–“ãŒé•·ã™ãã¾ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ã®æ”¹å–„ã¾ãŸã¯APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®èª¿æ•´ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        if df["memory_usage_mb"].max() > 200:
            recommendations.append(
                "ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãŒå¤šã„ã§ã™ã€‚ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºåˆ¶é™ã¾ãŸã¯ãƒ‡ãƒ¼ã‚¿åœ§ç¸®ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
            )

        multithread_results = df[df["test_name"].str.contains("ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰")]
        if not multithread_results.empty:
            single_ops = df[df["concurrent_users"] == 1]["operations_per_second"].max()
            multi_ops = multithread_results["operations_per_second"].max()

            if multi_ops < single_ops * 2:  # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãŒæ‚ªã„
                recommendations.append(
                    "ä¸¦è¡Œå‡¦ç†ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ãŒä½ã„ã§ã™ã€‚ãƒ­ãƒƒã‚¯ç«¶åˆã®è»½æ¸›ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚"
                )

        report["recommendations"] = recommendations

        # è©³ç´°çµæœ
        report["detailed_results"] = df.to_dict("records")

        # ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
        if output_file:
            output_path = self.results_dir / output_file
            with open(output_path, "w", encoding="utf-8") as f:
                json.dump(report, f, indent=2, ensure_ascii=False, default=str)

            logger.info(f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœä¿å­˜: {output_path}")

        return report

    def run_full_stress_test(self) -> Dict[str, Any]:
        """ãƒ•ãƒ«ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
        logger.info("=== ãƒ•ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆé–‹å§‹ ===")

        try:
            # å„ç¨®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            logger.info("1. ã‚·ãƒ³ã‚°ãƒ«ã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
            self.stress_test_single_thread(
                duration_seconds=30, operations_per_second=20
            )

            logger.info("2. ãƒãƒ«ãƒã‚¹ãƒ¬ãƒƒãƒ‰ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
            self.stress_test_multi_thread(duration_seconds=30, concurrent_threads=5)
            self.stress_test_multi_thread(duration_seconds=30, concurrent_threads=10)

            logger.info("3. ãƒ¡ãƒ¢ãƒªãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ãƒ†ã‚¹ãƒˆ")
            self.stress_test_memory_pressure(duration_seconds=20, memory_pressure_mb=50)

            logger.info("4. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç„¡åŠ¹åŒ–ãƒ†ã‚¹ãƒˆ")
            self.stress_test_cache_invalidation(duration_seconds=30)

            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            logger.info("5. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ")
            report = self.generate_stress_report("cache_stress_test_report.json")

            logger.info("=== ãƒ•ãƒ«ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº† ===")
            return report

        except Exception as e:
            logger.error(f"ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            return {"error": str(e)}


def run_cache_stress_test():
    """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    print("=== Issue #377 ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ ===")

    runner = StressTestRunner()
    report = runner.run_full_stress_test()

    # çµæœè¡¨ç¤º
    if "error" not in report:
        print("\nğŸ”¥ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
        print(f"å®Ÿè¡Œæ™‚åˆ»: {report.get('stress_test_timestamp')}")
        print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {report.get('total_tests')}")

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹
        summary = report.get("test_summary", {})
        print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹:")
        print(f"  æœ€é«˜æ€§èƒ½: {summary.get('best_performance_ops', 0):.1f} OPS")
        print(f"  æœ€ä½æ€§èƒ½: {summary.get('worst_performance_ops', 0):.1f} OPS")
        print(f"  å¹³å‡å¿œç­”æ™‚é–“: {summary.get('avg_response_time', 0):.2f}ms")
        print(f"  æœ€å¤§å¿œç­”æ™‚é–“: {summary.get('max_response_time', 0):.2f}ms")

        # å®‰å®šæ€§
        stability = report.get("stability_analysis", {})
        print("\nğŸ›¡ï¸ å®‰å®šæ€§:")
        print(f"  å®‰å®šãƒ†ã‚¹ãƒˆç‡: {stability.get('stability_rate', 0):.1f}%")
        print(f"  å¹³å‡ã‚¨ãƒ©ãƒ¼ç‡: {summary.get('avg_error_rate', 0):.2%}")
        print(f"  æœ€å¤§ã‚¨ãƒ©ãƒ¼ç‡: {summary.get('max_error_rate', 0):.2%}")

        # ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡
        resources = report.get("resource_usage", {})
        print("\nğŸ’¾ ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡:")
        print(f"  æœ€å¤§ãƒ¡ãƒ¢ãƒª: {resources.get('max_memory_usage', 0):.1f}MB")
        print(f"  å¹³å‡CPU: {resources.get('avg_cpu_usage', 0):.1f}%")

        # æ¨å¥¨äº‹é …
        recommendations = report.get("recommendations", [])
        if recommendations:
            print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
            for i, rec in enumerate(recommendations, 1):
                print(f"  {i}. {rec}")
        else:
            print("\nâœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã§è‰¯å¥½ãªçµæœã§ã™")

        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {runner.results_dir}/cache_stress_test_report.json")
    else:
        print(f"âŒ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {report['error']}")

    print("\n=== ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆå®Œäº† ===")
    return report


if __name__ == "__main__":
    run_cache_stress_test()
