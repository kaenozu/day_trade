#!/usr/bin/env python3
"""
å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

Issue #487å¯¾å¿œ: å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£… - Phase 2
VaRãƒ»CVaRè¨ˆç®—ãƒ»ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ãƒ»ç›¸é–¢ãƒªã‚¹ã‚¯ç®¡ç†ãƒ»å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹
"""

import asyncio
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Tuple
from enum import Enum
from datetime import datetime, timedelta
import scipy.optimize as optimize
from scipy import stats
import warnings
warnings.filterwarnings("ignore")

from ..utils.logging_config import get_context_logger
from .adaptive_optimization_system import MarketRegime
from .notification_system import get_notification_system

logger = get_context_logger(__name__)


class RiskLevel(Enum):
    """ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«"""
    CONSERVATIVE = "conservative"   # ä¿å®ˆçš„
    MODERATE = "moderate"          # ä¸­ç¨‹åº¦
    AGGRESSIVE = "aggressive"      # ç©æ¥µçš„
    DYNAMIC = "dynamic"           # å‹•çš„èª¿æ•´


class RiskMetric(Enum):
    """ãƒªã‚¹ã‚¯æŒ‡æ¨™"""
    VAR = "var"                   # Value at Risk
    CVAR = "cvar"                 # Conditional Value at Risk
    MAX_DRAWDOWN = "max_drawdown" # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    VOLATILITY = "volatility"     # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    BETA = "beta"                 # ãƒ™ãƒ¼ã‚¿
    SHARPE_RATIO = "sharpe_ratio" # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª


@dataclass
class RiskMetrics:
    """ãƒªã‚¹ã‚¯æŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿"""
    symbol: str
    var_95: float                 # 95% VaR
    var_99: float                 # 99% VaR
    cvar_95: float               # 95% CVaR
    cvar_99: float               # 99% CVaR
    max_drawdown: float          # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
    volatility: float            # å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    beta: float                  # ãƒ™ãƒ¼ã‚¿ï¼ˆå¸‚å ´å¯¾æ¯”ï¼‰
    sharpe_ratio: float          # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
    correlation_risk: float      # ç›¸é–¢ãƒªã‚¹ã‚¯
    liquidity_risk: float        # æµå‹•æ€§ãƒªã‚¹ã‚¯
    calculated_at: datetime


@dataclass
class PortfolioOptimizationResult:
    """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–çµæœ"""
    symbols: List[str]
    weights: np.ndarray
    expected_return: float
    portfolio_risk: float
    sharpe_ratio: float
    risk_metrics: RiskMetrics
    optimization_method: str
    constraints_met: bool
    optimization_time: float


@dataclass
class StopLossConfig:
    """ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š"""
    symbol: str
    entry_price: float
    stop_loss_price: float
    stop_loss_pct: float
    atr_multiplier: float
    volatility_adjusted: bool
    dynamic_update: bool
    last_updated: datetime


@dataclass
class RiskManagementConfig:
    """ãƒªã‚¹ã‚¯ç®¡ç†è¨­å®š"""
    max_portfolio_risk: float = 0.15      # æœ€å¤§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯(15%)
    max_position_size: float = 0.10       # æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚º(10%)
    max_correlation: float = 0.7          # æœ€å¤§ç›¸é–¢ä¿‚æ•°
    var_confidence: float = 0.95          # VaRä¿¡é ¼æ°´æº–
    rebalance_threshold: float = 0.05     # ãƒªãƒãƒ©ãƒ³ã‚¹é–¾å€¤
    stop_loss_atr_multiplier: float = 2.0 # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ATRå€æ•°
    min_liquidity_score: float = 50.0     # æœ€å°æµå‹•æ€§ã‚¹ã‚³ã‚¢
    risk_level: RiskLevel = RiskLevel.MODERATE


class DynamicRiskManagementSystem:
    """
    Issue #487å¯¾å¿œ: å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

    Phase 2ã®ãƒªã‚¹ã‚¯ç®¡ç†æ©Ÿèƒ½:
    - VaRãƒ»CVaRè‡ªå‹•è¨ˆç®—
    - Markowitzãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–
    - ç›¸é–¢ãƒªã‚¹ã‚¯ç›£è¦–
    - å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š
    - ãƒªã‚¹ã‚¯ã‚¢ãƒ©ãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ 
    """

    def __init__(self, config: RiskManagementConfig = None):
        """åˆæœŸåŒ–"""
        self.config = config or RiskManagementConfig()
        self.risk_history: List[RiskMetrics] = []
        self.portfolio_history: List[PortfolioOptimizationResult] = []
        self.stop_loss_configs: Dict[str, StopLossConfig] = {}

        # é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
        self.notification = get_notification_system()

        # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ï¼ˆæ—¥çµŒå¹³å‡ãªã©ï¼‰ã®ãƒ‡ãƒ¼ã‚¿
        self.benchmark_returns = None

        logger.info("å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

    async def calculate_risk_metrics(self, symbol: str, price_data: pd.DataFrame,
                                   benchmark_data: pd.DataFrame = None) -> RiskMetrics:
        """
        åŒ…æ‹¬çš„ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            benchmark_data: ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ‡ãƒ¼ã‚¿

        Returns:
            ãƒªã‚¹ã‚¯æŒ‡æ¨™
        """
        try:
            if price_data.empty or len(price_data) < 30:
                raise ValueError("è¨ˆç®—ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            # ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
            close_col = 'Close' if 'Close' in price_data.columns else price_data.columns[-1]
            prices = price_data[close_col]
            returns = prices.pct_change().dropna()

            if len(returns) < 10:
                raise ValueError("ãƒªã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")

            # 1. VaRè¨ˆç®— (Historical Method)
            var_95 = self._calculate_var(returns, confidence=0.95)
            var_99 = self._calculate_var(returns, confidence=0.99)

            # 2. CVaRè¨ˆç®—
            cvar_95 = self._calculate_cvar(returns, confidence=0.95)
            cvar_99 = self._calculate_cvar(returns, confidence=0.99)

            # 3. æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³è¨ˆç®—
            max_drawdown = self._calculate_max_drawdown(prices)

            # 4. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®—ï¼ˆå¹´ç‡åŒ–ï¼‰
            volatility = returns.std() * np.sqrt(252)

            # 5. ãƒ™ãƒ¼ã‚¿è¨ˆç®—
            beta = self._calculate_beta(returns, benchmark_data) if benchmark_data is not None else 1.0

            # 6. ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªè¨ˆç®—
            risk_free_rate = 0.02  # 2%ã¨ä»®å®š
            mean_return = returns.mean() * 252  # å¹´ç‡åŒ–
            sharpe_ratio = (mean_return - risk_free_rate) / volatility if volatility > 0 else 0.0

            # 7. ç›¸é–¢ãƒªã‚¹ã‚¯è¨ˆç®—ï¼ˆä»–ã®ä¿æœ‰éŠ˜æŸ„ã¨ã®ç›¸é–¢ï¼‰
            correlation_risk = self._calculate_correlation_risk(symbol, returns)

            # 8. æµå‹•æ€§ãƒªã‚¹ã‚¯è¨ˆç®—
            liquidity_risk = self._calculate_liquidity_risk(price_data)

            risk_metrics = RiskMetrics(
                symbol=symbol,
                var_95=var_95,
                var_99=var_99,
                cvar_95=cvar_95,
                cvar_99=cvar_99,
                max_drawdown=max_drawdown,
                volatility=volatility,
                beta=beta,
                sharpe_ratio=sharpe_ratio,
                correlation_risk=correlation_risk,
                liquidity_risk=liquidity_risk,
                calculated_at=datetime.now()
            )

            # å±¥æ­´ã«è¿½åŠ 
            self.risk_history.append(risk_metrics)
            if len(self.risk_history) > 1000:  # æœ€æ–°1000ä»¶ä¿æŒ
                self.risk_history = self.risk_history[-1000:]

            logger.info(f"ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—å®Œäº†: {symbol}")
            logger.info(f"  VaR(95%): {var_95:.4f}, CVaR(95%): {cvar_95:.4f}")
            logger.info(f"  æœ€å¤§DD: {max_drawdown:.4f}, ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {volatility:.4f}")
            logger.info(f"  ã‚·ãƒ£ãƒ¼ãƒ—: {sharpe_ratio:.4f}, ãƒ™ãƒ¼ã‚¿: {beta:.4f}")

            return risk_metrics

        except Exception as e:
            logger.error(f"ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({symbol}): {e}")
            raise

    def _calculate_var(self, returns: pd.Series, confidence: float = 0.95) -> float:
        """VaRè¨ˆç®— (Historical Method)"""
        if len(returns) == 0:
            return 0.0

        alpha = 1 - confidence
        var = np.percentile(returns, alpha * 100)
        return abs(var)  # æ­£å€¤ã¨ã—ã¦è¿”ã™

    def _calculate_cvar(self, returns: pd.Series, confidence: float = 0.95) -> float:
        """CVaRè¨ˆç®— (Expected Shortfall)"""
        if len(returns) == 0:
            return 0.0

        var = self._calculate_var(returns, confidence)
        # VaRã‚’è¶…ãˆã‚‹æå¤±ã®å¹³å‡
        tail_losses = returns[returns <= -var]

        if len(tail_losses) == 0:
            return var

        cvar = abs(tail_losses.mean())
        return cvar

    def _calculate_max_drawdown(self, prices: pd.Series) -> float:
        """æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³è¨ˆç®—"""
        if len(prices) == 0:
            return 0.0

        # ç´¯ç©æœ€å¤§å€¤
        peak = prices.expanding().max()

        # ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        drawdown = (prices - peak) / peak

        # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³
        max_dd = abs(drawdown.min())
        return max_dd

    def _calculate_beta(self, returns: pd.Series, benchmark_data: pd.DataFrame) -> float:
        """ãƒ™ãƒ¼ã‚¿è¨ˆç®—"""
        if benchmark_data is None or benchmark_data.empty:
            return 1.0

        try:
            # ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—
            bench_close = 'Close' if 'Close' in benchmark_data.columns else benchmark_data.columns[-1]
            bench_returns = benchmark_data[bench_close].pct_change().dropna()

            # æœŸé–“ã‚’åˆã‚ã›ã‚‹
            min_len = min(len(returns), len(bench_returns))
            if min_len < 10:
                return 1.0

            aligned_returns = returns.iloc[-min_len:]
            aligned_bench = bench_returns.iloc[-min_len:]

            # ç·šå½¢å›å¸°ã§ãƒ™ãƒ¼ã‚¿è¨ˆç®—
            covariance = np.cov(aligned_returns, aligned_bench)[0, 1]
            benchmark_variance = np.var(aligned_bench)

            if benchmark_variance == 0:
                return 1.0

            beta = covariance / benchmark_variance
            return beta

        except Exception as e:
            logger.debug(f"ãƒ™ãƒ¼ã‚¿è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0

    def _calculate_correlation_risk(self, symbol: str, returns: pd.Series) -> float:
        """ç›¸é–¢ãƒªã‚¹ã‚¯è¨ˆç®—"""
        # ä»–ã®ä¿æœ‰éŠ˜æŸ„ã¨ã®ç›¸é–¢ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“å®Ÿè£…ï¼‰
        # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªå†…ã®ä»–éŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ã¨æ¯”è¼ƒ

        # ãƒ‡ãƒ¢å®Ÿè£…: ãƒ©ãƒ³ãƒ€ãƒ ãªç›¸é–¢ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢
        np.random.seed(hash(symbol) % 2**32)
        correlation_risk = np.random.uniform(0.3, 0.8)
        return correlation_risk

    def _calculate_liquidity_risk(self, price_data: pd.DataFrame) -> float:
        """æµå‹•æ€§ãƒªã‚¹ã‚¯è¨ˆç®—"""
        try:
            if 'Volume' not in price_data.columns:
                return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¸­ç¨‹åº¦ãƒªã‚¹ã‚¯

            volumes = price_data['Volume']

            # ãƒœãƒªãƒ¥ãƒ¼ãƒ å¤‰å‹•ä¿‚æ•°
            vol_cv = volumes.std() / volumes.mean() if volumes.mean() > 0 else 1.0

            # ä½ãƒœãƒªãƒ¥ãƒ¼ãƒ æ—¥ã®å‰²åˆ
            low_volume_days = len(volumes[volumes < volumes.median() * 0.5]) / len(volumes)

            # æµå‹•æ€§ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢ (0-1, 1ãŒæœ€ã‚‚ãƒªã‚¹ã‚¯é«˜)
            liquidity_risk = min((vol_cv * 0.5 + low_volume_days * 0.5), 1.0)
            return liquidity_risk

        except Exception as e:
            logger.debug(f"æµå‹•æ€§ãƒªã‚¹ã‚¯è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.5

    async def optimize_portfolio(self, symbols: List[str],
                               expected_returns: np.ndarray,
                               covariance_matrix: np.ndarray,
                               method: str = "max_sharpe") -> PortfolioOptimizationResult:
        """
        ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ– (Markowitzç†è«–)

        Args:
            symbols: éŠ˜æŸ„ãƒªã‚¹ãƒˆ
            expected_returns: æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³é…åˆ—
            covariance_matrix: å…±åˆ†æ•£è¡Œåˆ—
            method: æœ€é©åŒ–æ‰‹æ³• ("max_sharpe", "min_risk", "efficient_frontier")

        Returns:
            ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–çµæœ
        """
        logger.info(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–é–‹å§‹: {method}")
        start_time = datetime.now()

        try:
            n_assets = len(symbols)

            # åˆ¶ç´„æ¡ä»¶
            constraints = [
                {'type': 'eq', 'fun': lambda w: np.sum(w) - 1.0},  # é‡ã¿åˆè¨ˆ=1
            ]

            # å¢ƒç•Œæ¡ä»¶ï¼ˆå„è³‡ç”£ã®é‡ã¿ 0-max_position_sizeï¼‰
            bounds = [(0.0, self.config.max_position_size) for _ in range(n_assets)]

            # åˆæœŸé‡ã¿ï¼ˆç­‰åˆ†æ•£ï¼‰
            initial_weights = np.ones(n_assets) / n_assets

            # æœ€é©åŒ–å®Ÿè¡Œ
            if method == "max_sharpe":
                result = self._maximize_sharpe_ratio(
                    expected_returns, covariance_matrix, constraints, bounds, initial_weights
                )
            elif method == "min_risk":
                result = self._minimize_portfolio_risk(
                    covariance_matrix, constraints, bounds, initial_weights
                )
            else:
                raise ValueError(f"æœªã‚µãƒãƒ¼ãƒˆã®æœ€é©åŒ–æ‰‹æ³•: {method}")

            if not result.success:
                raise Exception(f"æœ€é©åŒ–å¤±æ•—: {result.message}")

            optimal_weights = result.x

            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæŒ‡æ¨™è¨ˆç®—
            portfolio_return = np.dot(optimal_weights, expected_returns)
            portfolio_risk = np.sqrt(np.dot(optimal_weights, np.dot(covariance_matrix, optimal_weights)))

            # ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª
            risk_free_rate = 0.02  # 2%
            portfolio_sharpe = (portfolio_return - risk_free_rate) / portfolio_risk if portfolio_risk > 0 else 0.0

            # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—
            portfolio_risk_metrics = self._calculate_portfolio_risk_metrics(
                optimal_weights, symbols, expected_returns, covariance_matrix
            )

            # åˆ¶ç´„ãƒã‚§ãƒƒã‚¯
            constraints_met = self._check_portfolio_constraints(optimal_weights, portfolio_risk_metrics)

            optimization_time = (datetime.now() - start_time).total_seconds()

            optimization_result = PortfolioOptimizationResult(
                symbols=symbols,
                weights=optimal_weights,
                expected_return=portfolio_return,
                portfolio_risk=portfolio_risk,
                sharpe_ratio=portfolio_sharpe,
                risk_metrics=portfolio_risk_metrics,
                optimization_method=method,
                constraints_met=constraints_met,
                optimization_time=optimization_time
            )

            # å±¥æ­´ã«è¿½åŠ 
            self.portfolio_history.append(optimization_result)
            if len(self.portfolio_history) > 100:  # æœ€æ–°100ä»¶ä¿æŒ
                self.portfolio_history = self.portfolio_history[-100:]

            logger.info(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–å®Œäº†")
            logger.info(f"  æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: {portfolio_return:.4f}")
            logger.info(f"  ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯: {portfolio_risk:.4f}")
            logger.info(f"  ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {portfolio_sharpe:.4f}")

            # é‡ã¿è¡¨ç¤º
            for i, (symbol, weight) in enumerate(zip(symbols, optimal_weights)):
                if weight > 0.01:  # 1%ä»¥ä¸Šã®é‡ã¿ã®ã¿è¡¨ç¤º
                    logger.info(f"  {symbol}: {weight:.3f} ({weight*100:.1f}%)")

            # é€šçŸ¥é€ä¿¡
            await self._send_portfolio_optimization_notification(optimization_result)

            return optimization_result

        except Exception as e:
            logger.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _maximize_sharpe_ratio(self, expected_returns: np.ndarray, covariance_matrix: np.ndarray,
                              constraints: List[Dict], bounds: List[Tuple],
                              initial_weights: np.ndarray) -> optimize.OptimizeResult:
        """ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ªæœ€å¤§åŒ–"""

        def negative_sharpe(weights):
            portfolio_return = np.dot(weights, expected_returns)
            portfolio_risk = np.sqrt(np.dot(weights, np.dot(covariance_matrix, weights)))

            if portfolio_risk == 0:
                return -1000.0  # éå¸¸ã«æ‚ªã„ã‚¹ã‚³ã‚¢

            risk_free_rate = 0.02
            sharpe = (portfolio_return - risk_free_rate) / portfolio_risk
            return -sharpe  # æœ€å°åŒ–ã®ãŸã‚ç¬¦å·åè»¢

        return optimize.minimize(
            negative_sharpe,
            initial_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints,
            options={'maxiter': 1000}
        )

    def _minimize_portfolio_risk(self, covariance_matrix: np.ndarray,
                                constraints: List[Dict], bounds: List[Tuple],
                                initial_weights: np.ndarray) -> optimize.OptimizeResult:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯æœ€å°åŒ–"""

        def portfolio_variance(weights):
            return np.dot(weights, np.dot(covariance_matrix, weights))

        return optimize.minimize(
            portfolio_variance,
            initial_weights,
            method='SLSQP',
            bounds=bounds,
            constraints=constraints,
            options={'maxiter': 1000}
        )

    def _calculate_portfolio_risk_metrics(self, weights: np.ndarray, symbols: List[str],
                                        expected_returns: np.ndarray,
                                        covariance_matrix: np.ndarray) -> RiskMetrics:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—"""

        # ç°¡æ˜“ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯æŒ‡æ¨™
        portfolio_return = np.dot(weights, expected_returns)
        portfolio_risk = np.sqrt(np.dot(weights, np.dot(covariance_matrix, weights)))

        # VaRãƒ»CVaRæ¨å®šï¼ˆæ­£è¦åˆ†å¸ƒä»®å®šï¼‰
        var_95 = abs(stats.norm.ppf(0.05, portfolio_return, portfolio_risk))
        var_99 = abs(stats.norm.ppf(0.01, portfolio_return, portfolio_risk))
        cvar_95 = var_95 * 1.2  # ç°¡æ˜“æ¨å®š
        cvar_99 = var_99 * 1.15  # ç°¡æ˜“æ¨å®š

        # æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³æ¨å®š
        max_drawdown = portfolio_risk * 2.0  # ç°¡æ˜“æ¨å®š

        risk_free_rate = 0.02
        sharpe_ratio = (portfolio_return - risk_free_rate) / portfolio_risk if portfolio_risk > 0 else 0.0

        return RiskMetrics(
            symbol="PORTFOLIO",
            var_95=var_95,
            var_99=var_99,
            cvar_95=cvar_95,
            cvar_99=cvar_99,
            max_drawdown=max_drawdown,
            volatility=portfolio_risk,
            beta=1.0,
            sharpe_ratio=sharpe_ratio,
            correlation_risk=0.5,
            liquidity_risk=0.3,
            calculated_at=datetime.now()
        )

    def _check_portfolio_constraints(self, weights: np.ndarray,
                                   risk_metrics: RiskMetrics) -> bool:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªåˆ¶ç´„ãƒã‚§ãƒƒã‚¯"""

        # 1. æœ€å¤§ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯åˆ¶ç´„
        if risk_metrics.volatility > self.config.max_portfolio_risk:
            logger.warning(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯åˆ¶ç´„é•å: {risk_metrics.volatility:.4f} > {self.config.max_portfolio_risk}")
            return False

        # 2. æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºåˆ¶ç´„
        if np.max(weights) > self.config.max_position_size:
            logger.warning(f"æœ€å¤§ãƒã‚¸ã‚·ãƒ§ãƒ³åˆ¶ç´„é•å: {np.max(weights):.4f} > {self.config.max_position_size}")
            return False

        # 3. é‡ã¿åˆè¨ˆåˆ¶ç´„
        if abs(np.sum(weights) - 1.0) > 0.01:
            logger.warning(f"é‡ã¿åˆè¨ˆåˆ¶ç´„é•å: {np.sum(weights):.4f} != 1.0")
            return False

        return True

    async def calculate_dynamic_stop_loss(self, symbol: str, price_data: pd.DataFrame,
                                        entry_price: float,
                                        market_regime: MarketRegime = None) -> StopLossConfig:
        """
        å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨ˆç®—

        Args:
            symbol: éŠ˜æŸ„ã‚·ãƒ³ãƒœãƒ«
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
            entry_price: ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼
            market_regime: å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ 

        Returns:
            ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š
        """
        try:
            if price_data.empty or len(price_data) < 14:
                raise ValueError("ATRè¨ˆç®—ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

            # ATR (Average True Range) è¨ˆç®—
            atr = self._calculate_atr(price_data, period=14)

            # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ATRå€æ•°èª¿æ•´
            atr_multiplier = self._get_regime_adjusted_atr_multiplier(market_regime)

            # ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼è¨ˆç®—
            stop_loss_distance = atr * atr_multiplier
            stop_loss_price = entry_price - stop_loss_distance  # ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³æƒ³å®š
            stop_loss_pct = stop_loss_distance / entry_price

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´
            volatility_adjustment = self._calculate_volatility_adjustment(price_data)
            adjusted_stop_loss_price = entry_price * (1 - stop_loss_pct * volatility_adjustment)

            stop_loss_config = StopLossConfig(
                symbol=symbol,
                entry_price=entry_price,
                stop_loss_price=adjusted_stop_loss_price,
                stop_loss_pct=stop_loss_pct * volatility_adjustment,
                atr_multiplier=atr_multiplier,
                volatility_adjusted=True,
                dynamic_update=True,
                last_updated=datetime.now()
            )

            # è¨­å®šä¿å­˜
            self.stop_loss_configs[symbol] = stop_loss_config

            logger.info(f"å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨­å®š: {symbol}")
            logger.info(f"  ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼: {entry_price:.2f}")
            logger.info(f"  ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼: {adjusted_stop_loss_price:.2f}")
            logger.info(f"  ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç‡: {stop_loss_pct * volatility_adjustment * 100:.2f}%")
            logger.info(f"  ATRå€æ•°: {atr_multiplier:.2f}")

            return stop_loss_config

        except Exception as e:
            logger.error(f"å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹è¨ˆç®—ã‚¨ãƒ©ãƒ¼ ({symbol}): {e}")
            raise

    def _calculate_atr(self, price_data: pd.DataFrame, period: int = 14) -> float:
        """ATRè¨ˆç®—"""
        try:
            high = price_data['High']
            low = price_data['Low']
            close = price_data['Close']

            # True Rangeè¨ˆç®—
            tr1 = high - low
            tr2 = abs(high - close.shift(1))
            tr3 = abs(low - close.shift(1))

            true_range = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

            # ATRï¼ˆTrue Rangeã®ç§»å‹•å¹³å‡ï¼‰
            atr = true_range.rolling(period).mean().iloc[-1]

            return atr if not np.isnan(atr) else 0.0

        except Exception as e:
            logger.debug(f"ATRè¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 0.01  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

    def _get_regime_adjusted_atr_multiplier(self, regime: MarketRegime = None) -> float:
        """ãƒ¬ã‚¸ãƒ¼ãƒ èª¿æ•´ATRå€æ•°"""
        base_multiplier = self.config.stop_loss_atr_multiplier

        if regime == MarketRegime.VOLATILE:
            return base_multiplier * 1.5  # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£é«˜æ™‚ã¯åºƒã‚ã«è¨­å®š
        elif regime == MarketRegime.BEAR:
            return base_multiplier * 0.8  # å¼±æ°—ç›¸å ´ã¯ç‹­ã‚ã«è¨­å®š
        elif regime == MarketRegime.BULL:
            return base_multiplier * 1.2  # å¼·æ°—ç›¸å ´ã¯å°‘ã—åºƒã‚ã«è¨­å®š
        else:
            return base_multiplier

    def _calculate_volatility_adjustment(self, price_data: pd.DataFrame) -> float:
        """ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´ä¿‚æ•°"""
        try:
            close = price_data['Close']
            returns = close.pct_change().dropna()

            if len(returns) < 10:
                return 1.0

            # æœ€è¿‘ã®ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ vs é•·æœŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            recent_vol = returns.tail(10).std()
            long_term_vol = returns.std()

            if long_term_vol == 0:
                return 1.0

            vol_ratio = recent_vol / long_term_vol

            # èª¿æ•´ä¿‚æ•° (0.5-2.0ã®ç¯„å›²)
            adjustment = np.clip(vol_ratio, 0.5, 2.0)
            return adjustment

        except Exception as e:
            logger.debug(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´è¨ˆç®—ã‚¨ãƒ©ãƒ¼: {e}")
            return 1.0

    async def _send_portfolio_optimization_notification(self, result: PortfolioOptimizationResult):
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–çµæœé€šçŸ¥"""
        try:
            # é‡ã¿è¡¨ç¤ºæ–‡å­—åˆ—ç”Ÿæˆ
            weights_text = ""
            for symbol, weight in zip(result.symbols, result.weights):
                if weight > 0.01:  # 1%ä»¥ä¸Šã®ã¿è¡¨ç¤º
                    weights_text += f"  {symbol}: {weight:.3f} ({weight*100:.1f}%)\n"

            notification_data = {
                'optimization_method': result.optimization_method,
                'expected_return': result.expected_return,
                'portfolio_risk': result.portfolio_risk,
                'sharpe_ratio': result.sharpe_ratio,
                'n_assets': len(result.symbols),
                'weights_distribution': weights_text,
                'constraints_met': 'æº€è¶³' if result.constraints_met else 'é•å',
                'optimization_time': result.optimization_time
            }

            # é€šçŸ¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
            from .notification_system import NotificationTemplate, NotificationType, NotificationChannel

            template = NotificationTemplate(
                template_id="portfolio_optimization",
                subject_template="[ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–] {optimization_method}æœ€é©åŒ–å®Œäº†",
                body_template="""
ğŸ“Š ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–çµæœ

ğŸ¯ æœ€é©åŒ–æ‰‹æ³•: {optimization_method}
ğŸ“ˆ æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: {expected_return:.4f}
ğŸ“‰ ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯: {portfolio_risk:.4f}
âš¡ ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {sharpe_ratio:.4f}
ğŸ›ï¸ è³‡ç”£æ•°: {n_assets}
âœ… åˆ¶ç´„: {constraints_met}
â±ï¸ æœ€é©åŒ–æ™‚é–“: {optimization_time:.1f}ç§’

ğŸ’¼ é‡ã¿é…åˆ†:
{weights_distribution}

---
Issue #487 Phase 2: å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
""",
                notification_type=NotificationType.SUCCESS,
                channels=[NotificationChannel.LOG, NotificationChannel.FILE]
            )

            self.notification.templates["portfolio_optimization"] = template
            self.notification.send_notification("portfolio_optimization", notification_data)

        except Exception as e:
            logger.error(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–é€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    def get_portfolio_risk_summary(self) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯ã‚µãƒãƒªãƒ¼å–å¾—"""
        if not self.portfolio_history:
            return {"status": "no_data"}

        latest_portfolio = self.portfolio_history[-1]

        return {
            "timestamp": latest_portfolio.risk_metrics.calculated_at,
            "portfolio_risk": latest_portfolio.portfolio_risk,
            "expected_return": latest_portfolio.expected_return,
            "sharpe_ratio": latest_portfolio.sharpe_ratio,
            "var_95": latest_portfolio.risk_metrics.var_95,
            "max_drawdown": latest_portfolio.risk_metrics.max_drawdown,
            "constraints_met": latest_portfolio.constraints_met,
            "n_assets": len(latest_portfolio.symbols),
            "optimization_method": latest_portfolio.optimization_method
        }


# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    """ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ã‚¤ãƒ³"""
    logger.info("å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")

    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    risk_manager = DynamicRiskManagementSystem()

    # ãƒ†ã‚¹ãƒˆç”¨ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_days = 100
    dates = pd.date_range('2023-01-01', periods=n_days, freq='D')

    # ãƒªã‚¢ãƒ«ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    returns = np.random.normal(0.001, 0.02, n_days)
    prices = [100.0]
    for r in returns[1:]:
        prices.append(prices[-1] * (1 + r))

    # OHLCV ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    test_data = pd.DataFrame({
        'Date': dates,
        'Close': prices,
        'High': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
        'Low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
        'Volume': np.random.lognormal(10, 0.5, n_days)
    })

    # ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ
    print("=" * 60)
    print("ãƒªã‚¹ã‚¯æŒ‡æ¨™è¨ˆç®—ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    risk_metrics = await risk_manager.calculate_risk_metrics("TEST", test_data)

    print(f"éŠ˜æŸ„: {risk_metrics.symbol}")
    print(f"VaR(95%): {risk_metrics.var_95:.4f}")
    print(f"CVaR(95%): {risk_metrics.cvar_95:.4f}")
    print(f"æœ€å¤§ãƒ‰ãƒ­ãƒ¼ãƒ€ã‚¦ãƒ³: {risk_metrics.max_drawdown:.4f}")
    print(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {risk_metrics.volatility:.4f}")
    print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {risk_metrics.sharpe_ratio:.4f}")

    # ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªæœ€é©åŒ–ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
    symbols = ["ASSET_A", "ASSET_B", "ASSET_C"]
    expected_returns = np.array([0.10, 0.12, 0.08])  # æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³

    # å…±åˆ†æ•£è¡Œåˆ—ï¼ˆç›¸é–¢ã‚’å«ã‚€ï¼‰
    correlations = np.array([
        [1.0, 0.3, 0.2],
        [0.3, 1.0, 0.4],
        [0.2, 0.4, 1.0]
    ])
    volatilities = np.array([0.15, 0.20, 0.12])
    covariance_matrix = np.outer(volatilities, volatilities) * correlations

    # æœ€é©åŒ–å®Ÿè¡Œ
    optimization_result = await risk_manager.optimize_portfolio(
        symbols, expected_returns, covariance_matrix, method="max_sharpe"
    )

    print(f"æœ€é©åŒ–æ‰‹æ³•: {optimization_result.optimization_method}")
    print(f"æœŸå¾…ãƒªã‚¿ãƒ¼ãƒ³: {optimization_result.expected_return:.4f}")
    print(f"ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒªã‚ªãƒªã‚¹ã‚¯: {optimization_result.portfolio_risk:.4f}")
    print(f"ã‚·ãƒ£ãƒ¼ãƒ—ãƒ¬ã‚·ã‚ª: {optimization_result.sharpe_ratio:.4f}")
    print(f"åˆ¶ç´„æº€è¶³: {optimization_result.constraints_met}")

    print("\né‡ã¿é…åˆ†:")
    for symbol, weight in zip(symbols, optimization_result.weights):
        print(f"  {symbol}: {weight:.3f} ({weight*100:.1f}%)")

    # å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ†ã‚¹ãƒˆ
    print("\n" + "=" * 60)
    print("å‹•çš„ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    entry_price = 100.0
    stop_loss_config = await risk_manager.calculate_dynamic_stop_loss(
        "TEST", test_data, entry_price, MarketRegime.VOLATILE
    )

    print(f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼: {stop_loss_config.entry_price:.2f}")
    print(f"ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ä¾¡æ ¼: {stop_loss_config.stop_loss_price:.2f}")
    print(f"ã‚¹ãƒˆãƒƒãƒ—ãƒ­ã‚¹ç‡: {stop_loss_config.stop_loss_pct*100:.2f}%")
    print(f"ATRå€æ•°: {stop_loss_config.atr_multiplier:.2f}")
    print(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£èª¿æ•´: {stop_loss_config.volatility_adjusted}")

    logger.info("å‹•çš„ãƒªã‚¹ã‚¯ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    asyncio.run(main())