#!/usr/bin/env python3
"""
é©å¿œçš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 

Issue #487å¯¾å¿œ: å®Œå…¨è‡ªå‹•åŒ–ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£… - Phase 2
ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–ãƒ»å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºãƒ»å‹•çš„ãƒ¢ãƒ‡ãƒ«èª¿æ•´
"""

import asyncio
import time
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any, Callable, Tuple
from enum import Enum
from datetime import datetime, timedelta
import optuna
from optuna.samplers import TPESampler
from optuna.pruners import MedianPruner
import pickle
import json
import os

from ..utils.logging_config import get_context_logger
from ..ml.ensemble_system import EnsembleSystem, EnsembleConfig
from .smart_symbol_selector import SmartSymbolSelector
from .notification_system import get_notification_system

logger = get_context_logger(__name__)


class MarketRegime(Enum):
    """å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ """
    BULL = "bull"           # å¼·æ°—ç›¸å ´
    BEAR = "bear"           # å¼±æ°—ç›¸å ´
    SIDEWAYS = "sideways"   # æ¨ªã°ã„ç›¸å ´
    VOLATILE = "volatile"   # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç›¸å ´
    UNKNOWN = "unknown"     # åˆ¤å®šä¸å¯


class OptimizationScope(Enum):
    """æœ€é©åŒ–ã‚¹ã‚³ãƒ¼ãƒ—"""
    HYPERPARAMETERS = "hyperparameters"     # ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    ENSEMBLE_WEIGHTS = "ensemble_weights"   # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–
    FEATURE_SELECTION = "feature_selection" # ç‰¹å¾´é‡é¸æŠæœ€é©åŒ–
    FULL_OPTIMIZATION = "full_optimization" # å…¨ä½“æœ€é©åŒ–


@dataclass
class OptimizationConfig:
    """æœ€é©åŒ–è¨­å®š"""
    n_trials: int = 100                    # è©¦è¡Œå›æ•°
    timeout: int = 3600                    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ(ç§’)
    n_jobs: int = 1                        # ä¸¦åˆ—ã‚¸ãƒ§ãƒ–æ•°
    sampler: str = "TPE"                   # ã‚µãƒ³ãƒ—ãƒ©ãƒ¼ç¨®åˆ¥
    pruner: str = "MedianPruner"          # ãƒ—ãƒ«ãƒ¼ãƒŠãƒ¼ç¨®åˆ¥
    cv_folds: int = 5                      # ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³åˆ†å‰²æ•°
    optimization_metric: str = "r2_score"  # æœ€é©åŒ–æŒ‡æ¨™
    min_trials_for_pruning: int = 10       # ãƒ—ãƒ«ãƒ¼ãƒ‹ãƒ³ã‚°é–‹å§‹è©¦è¡Œæ•°


@dataclass
class MarketRegimeMetrics:
    """å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æŒ‡æ¨™"""
    regime: MarketRegime
    confidence: float                      # ä¿¡é ¼åº¦ (0-1)
    volatility: float                      # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
    trend_strength: float                  # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦ (-1ã‹ã‚‰1)
    momentum: float                        # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ 
    regime_duration_days: int              # ãƒ¬ã‚¸ãƒ¼ãƒ ç¶™ç¶šæ—¥æ•°
    transition_probability: float          # ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡


@dataclass
class OptimizationResult:
    """æœ€é©åŒ–çµæœ"""
    best_params: Dict[str, Any]
    best_score: float
    n_trials: int
    optimization_time: float
    market_regime: MarketRegime
    timestamp: datetime
    model_performance: Dict[str, float]
    convergence_achieved: bool


class AdaptiveOptimizationSystem:
    """
    Issue #487å¯¾å¿œ: é©å¿œçš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 

    Phase 2ã®æ ¸å¿ƒæ©Ÿèƒ½:
    - Optunaçµ±åˆãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–
    - å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ è‡ªå‹•æ¤œå‡º
    - é©å¿œçš„ãƒ¢ãƒ‡ãƒ«èª¿æ•´
    - é•·æœŸçš„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¿½è·¡
    """

    def __init__(self, config: OptimizationConfig = None):
        """åˆæœŸåŒ–"""
        self.config = config or OptimizationConfig()
        self.optimization_history: List[OptimizationResult] = []
        self.current_regime: MarketRegime = MarketRegime.UNKNOWN
        self.regime_history: List[MarketRegimeMetrics] = []

        # æœ€é©åŒ–çµæœä¿å­˜ãƒ‘ã‚¹
        self.results_path = "optimization_results"
        os.makedirs(self.results_path, exist_ok=True)

        # Optunaè¨­å®š
        optuna.logging.set_verbosity(optuna.logging.WARNING)
        self.study = None

        # é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ 
        self.notification = get_notification_system()

    def detect_market_regime(self, price_data: pd.DataFrame) -> MarketRegimeMetrics:
        """
        å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ è‡ªå‹•æ¤œå‡º

        Args:
            price_data: ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ (OHLCV)

        Returns:
            å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æŒ‡æ¨™
        """
        try:
            if price_data.empty or len(price_data) < 30:
                return MarketRegimeMetrics(
                    regime=MarketRegime.UNKNOWN,
                    confidence=0.0,
                    volatility=0.0,
                    trend_strength=0.0,
                    momentum=0.0,
                    regime_duration_days=0,
                    transition_probability=0.5
                )

            # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
            closes = price_data['Close'] if 'Close' in price_data.columns else price_data.iloc[:, -1]
            returns = closes.pct_change().dropna()

            # 1. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£è¨ˆç®— (å¹´ç‡åŒ–)
            volatility = returns.std() * np.sqrt(252)

            # 2. ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦è¨ˆç®— (ç·šå½¢å›å¸°ã®å‚¾ã)
            x = np.arange(len(closes))
            trend_slope = np.polyfit(x, closes.values, 1)[0]
            price_range = closes.max() - closes.min()
            trend_strength = trend_slope / price_range if price_range > 0 else 0
            trend_strength = np.clip(trend_strength * 100, -1, 1)  # -1ã‹ã‚‰1ã«æ­£è¦åŒ–

            # 3. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ è¨ˆç®— (çŸ­æœŸãƒ»é•·æœŸç§»å‹•å¹³å‡ã®é–¢ä¿‚)
            if len(closes) >= 50:
                ma_short = closes.rolling(10).mean().iloc[-1]
                ma_long = closes.rolling(50).mean().iloc[-1]
                momentum = (ma_short - ma_long) / ma_long if ma_long != 0 else 0
            else:
                momentum = 0

            # 4. ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯
            regime, confidence = self._classify_regime(
                volatility, trend_strength, momentum, returns
            )

            # 5. ãƒ¬ã‚¸ãƒ¼ãƒ ç¶™ç¶šæœŸé–“æ¨å®š
            regime_duration = self._estimate_regime_duration()

            # 6. ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡è¨ˆç®—
            transition_prob = self._calculate_transition_probability(
                volatility, abs(trend_strength), abs(momentum)
            )

            metrics = MarketRegimeMetrics(
                regime=regime,
                confidence=confidence,
                volatility=volatility,
                trend_strength=trend_strength,
                momentum=momentum,
                regime_duration_days=regime_duration,
                transition_probability=transition_prob
            )

            # å±¥æ­´ã«è¿½åŠ 
            self.regime_history.append(metrics)
            if len(self.regime_history) > 365:  # 1å¹´åˆ†ä¿æŒ
                self.regime_history = self.regime_history[-365:]

            self.current_regime = regime

            logger.info(f"å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡º: {regime.value} (ä¿¡é ¼åº¦: {confidence:.2f})")
            logger.info(f"  ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {volatility:.3f}")
            logger.info(f"  ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {trend_strength:.3f}")
            logger.info(f"  ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ : {momentum:.3f}")

            return metrics

        except Exception as e:
            logger.error(f"å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºã‚¨ãƒ©ãƒ¼: {e}")
            return MarketRegimeMetrics(
                regime=MarketRegime.UNKNOWN,
                confidence=0.0,
                volatility=0.0,
                trend_strength=0.0,
                momentum=0.0,
                regime_duration_days=0,
                transition_probability=0.5
            )

    def _classify_regime(self, volatility: float, trend_strength: float,
                        momentum: float, returns: pd.Series) -> Tuple[MarketRegime, float]:
        """ãƒ¬ã‚¸ãƒ¼ãƒ åˆ†é¡"""

        # é–¾å€¤è¨­å®š
        high_vol_threshold = 0.25  # 25%å¹´ç‡ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        trend_threshold = 0.3      # ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦é–¾å€¤
        momentum_threshold = 0.05   # ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ é–¾å€¤

        confidence_scores = {}

        # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£åˆ¤å®š
        if volatility > high_vol_threshold:
            confidence_scores[MarketRegime.VOLATILE] = min(volatility / high_vol_threshold, 2.0) - 1.0

        # å¼·æ°—ãƒ»å¼±æ°—åˆ¤å®š
        if trend_strength > trend_threshold and momentum > momentum_threshold:
            strength = min((trend_strength + momentum) / 2, 1.0)
            confidence_scores[MarketRegime.BULL] = strength
        elif trend_strength < -trend_threshold and momentum < -momentum_threshold:
            strength = min(abs(trend_strength + momentum) / 2, 1.0)
            confidence_scores[MarketRegime.BEAR] = strength

        # æ¨ªã°ã„åˆ¤å®š
        if abs(trend_strength) < trend_threshold / 2 and abs(momentum) < momentum_threshold / 2:
            sideways_strength = 1.0 - max(abs(trend_strength), abs(momentum)) * 2
            confidence_scores[MarketRegime.SIDEWAYS] = max(sideways_strength, 0.0)

        # æœ€ã‚‚ç¢ºä¿¡åº¦ã®é«˜ã„ãƒ¬ã‚¸ãƒ¼ãƒ ã‚’é¸æŠ
        if confidence_scores:
            best_regime = max(confidence_scores.keys(), key=lambda k: confidence_scores[k])
            confidence = min(confidence_scores[best_regime], 1.0)
            return best_regime, confidence
        else:
            return MarketRegime.UNKNOWN, 0.0

    def _estimate_regime_duration(self) -> int:
        """ãƒ¬ã‚¸ãƒ¼ãƒ ç¶™ç¶šæœŸé–“æ¨å®š"""
        if len(self.regime_history) < 2:
            return 1

        current_regime = self.current_regime
        duration = 1

        for i in range(len(self.regime_history) - 2, -1, -1):
            if self.regime_history[i].regime == current_regime:
                duration += 1
            else:
                break

        return duration

    def _calculate_transition_probability(self, volatility: float,
                                        trend_strength: float, momentum: float) -> float:
        """ãƒ¬ã‚¸ãƒ¼ãƒ å¤‰åŒ–ç¢ºç‡è¨ˆç®—"""
        # å¤‰åŒ–è¦å› ã®ã‚¹ã‚³ã‚¢åŒ–
        volatility_factor = min(volatility / 0.3, 1.0)  # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã»ã©å¤‰åŒ–ç¢ºç‡é«˜
        trend_factor = min(trend_strength, 1.0)         # å¼·ãƒˆãƒ¬ãƒ³ãƒ‰ã»ã©å¤‰åŒ–ç¢ºç‡é«˜
        momentum_factor = min(momentum, 1.0)            # å¼·ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ã»ã©å¤‰åŒ–ç¢ºç‡é«˜

        # ç¶™ç¶šæœŸé–“ã«ã‚ˆã‚‹å¤‰åŒ–ç¢ºç‡èª¿æ•´
        duration = self._estimate_regime_duration()
        duration_factor = min(duration / 30, 1.0)       # 30æ—¥ä»¥ä¸Šç¶™ç¶šã§å¤‰åŒ–ç¢ºç‡ä¸Šæ˜‡

        # ç·åˆå¤‰åŒ–ç¢ºç‡ (0-1)
        transition_prob = (volatility_factor * 0.4 +
                          (trend_factor + momentum_factor) * 0.3 +
                          duration_factor * 0.3)

        return min(transition_prob, 0.95)  # æœ€å¤§95%

    async def optimize_hyperparameters(self, ensemble_system: EnsembleSystem,
                                     X_train: np.ndarray, y_train: np.ndarray,
                                     X_val: np.ndarray, y_val: np.ndarray,
                                     market_regime: MarketRegime = None) -> OptimizationResult:
        """
        ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–

        Args:
            ensemble_system: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ 
            X_train: è¨“ç·´ãƒ‡ãƒ¼ã‚¿
            y_train: è¨“ç·´ç›®æ¨™
            X_val: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿
            y_val: æ¤œè¨¼ç›®æ¨™
            market_regime: å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ 

        Returns:
            æœ€é©åŒ–çµæœ
        """
        logger.info("ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–é–‹å§‹")
        start_time = time.time()

        try:
            # Optunaã‚¹ã‚¿ãƒ‡ã‚£ä½œæˆ
            regime_suffix = f"_{market_regime.value}" if market_regime else ""
            study_name = f"ensemble_optimization{regime_suffix}_{int(start_time)}"

            self.study = optuna.create_study(
                direction="maximize",
                sampler=TPESampler(seed=42),
                pruner=MedianPruner(n_startup_trials=self.config.min_trials_for_pruning),
                study_name=study_name
            )

            # æœ€é©åŒ–å®Ÿè¡Œ
            objective = self._create_objective_function(
                ensemble_system, X_train, y_train, X_val, y_val
            )

            self.study.optimize(
                objective,
                n_trials=self.config.n_trials,
                timeout=self.config.timeout,
                n_jobs=self.config.n_jobs
            )

            optimization_time = time.time() - start_time

            # æœ€é©åŒ–çµæœ
            best_trial = self.study.best_trial
            best_params = best_trial.params
            best_score = best_trial.value

            # ãƒ¢ãƒ‡ãƒ«æ€§èƒ½è©•ä¾¡
            performance_metrics = await self._evaluate_optimized_model(
                ensemble_system, best_params, X_train, y_train, X_val, y_val
            )

            # åæŸåˆ¤å®š
            convergence_achieved = self._check_convergence()

            result = OptimizationResult(
                best_params=best_params,
                best_score=best_score,
                n_trials=len(self.study.trials),
                optimization_time=optimization_time,
                market_regime=market_regime or self.current_regime,
                timestamp=datetime.now(),
                model_performance=performance_metrics,
                convergence_achieved=convergence_achieved
            )

            # çµæœä¿å­˜
            self._save_optimization_result(result)

            # å±¥æ­´ã«è¿½åŠ 
            self.optimization_history.append(result)

            logger.info(f"æœ€é©åŒ–å®Œäº†: ã‚¹ã‚³ã‚¢={best_score:.4f}, æ™‚é–“={optimization_time:.1f}ç§’")
            logger.info(f"æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {best_params}")

            # é€šçŸ¥é€ä¿¡
            await self._send_optimization_notification(result)

            return result

        except Exception as e:
            logger.error(f"ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _create_objective_function(self, ensemble_system: EnsembleSystem,
                                  X_train: np.ndarray, y_train: np.ndarray,
                                  X_val: np.ndarray, y_val: np.ndarray) -> Callable:
        """Optunaç›®çš„é–¢æ•°ä½œæˆ"""

        def objective(trial: optuna.Trial) -> float:
            try:
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                params = self._sample_hyperparameters(trial, self.current_regime)

                # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šæ›´æ–°
                config = self._create_ensemble_config(params)
                optimized_ensemble = EnsembleSystem(config)

                # è¨“ç·´å®Ÿè¡Œ
                feature_names = [f"feature_{i}" for i in range(X_train.shape[1])]
                optimized_ensemble.fit(
                    X_train, y_train,
                    validation_data=(X_val, y_val),
                    feature_names=feature_names
                )

                # äºˆæ¸¬ãƒ»è©•ä¾¡
                predictions = optimized_ensemble.predict(X_val)

                # ã‚¹ã‚³ã‚¢è¨ˆç®—
                from sklearn.metrics import r2_score, mean_squared_error
                if self.config.optimization_metric == "r2_score":
                    score = r2_score(y_val, predictions.final_predictions)
                elif self.config.optimization_metric == "neg_mse":
                    score = -mean_squared_error(y_val, predictions.final_predictions)
                else:
                    score = r2_score(y_val, predictions.final_predictions)

                return score

            except Exception as e:
                logger.warning(f"è©¦è¡Œå¤±æ•—: {e}")
                return -1000.0  # éå¸¸ã«æ‚ªã„ã‚¹ã‚³ã‚¢

        return objective

    def _sample_hyperparameters(self, trial: optuna.Trial, regime: MarketRegime) -> Dict[str, Any]:
        """ãƒ¬ã‚¸ãƒ¼ãƒ é©å¿œçš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°"""

        params = {}

        # XGBoost ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        if regime == MarketRegime.VOLATILE:
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç’°å¢ƒ: éå­¦ç¿’æŠ‘åˆ¶é‡è¦–
            params['xgboost_n_estimators'] = trial.suggest_int('xgboost_n_estimators', 50, 200)
            params['xgboost_max_depth'] = trial.suggest_int('xgboost_max_depth', 3, 6)
            params['xgboost_learning_rate'] = trial.suggest_float('xgboost_learning_rate', 0.01, 0.1)
            params['xgboost_reg_alpha'] = trial.suggest_float('xgboost_reg_alpha', 0.1, 1.0)
            params['xgboost_reg_lambda'] = trial.suggest_float('xgboost_reg_lambda', 1.0, 5.0)
        elif regime == MarketRegime.BULL:
            # å¼·æ°—ç›¸å ´: ãƒˆãƒ¬ãƒ³ãƒ‰è¿½å¾“é‡è¦–
            params['xgboost_n_estimators'] = trial.suggest_int('xgboost_n_estimators', 200, 500)
            params['xgboost_max_depth'] = trial.suggest_int('xgboost_max_depth', 6, 10)
            params['xgboost_learning_rate'] = trial.suggest_float('xgboost_learning_rate', 0.05, 0.15)
            params['xgboost_reg_alpha'] = trial.suggest_float('xgboost_reg_alpha', 0.01, 0.5)
            params['xgboost_reg_lambda'] = trial.suggest_float('xgboost_reg_lambda', 0.5, 2.0)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            params['xgboost_n_estimators'] = trial.suggest_int('xgboost_n_estimators', 100, 400)
            params['xgboost_max_depth'] = trial.suggest_int('xgboost_max_depth', 4, 8)
            params['xgboost_learning_rate'] = trial.suggest_float('xgboost_learning_rate', 0.03, 0.12)
            params['xgboost_reg_alpha'] = trial.suggest_float('xgboost_reg_alpha', 0.01, 1.0)
            params['xgboost_reg_lambda'] = trial.suggest_float('xgboost_reg_lambda', 0.5, 3.0)

        # CatBoost ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params['catboost_iterations'] = trial.suggest_int('catboost_iterations', 100, 800)
        params['catboost_depth'] = trial.suggest_int('catboost_depth', 4, 10)
        params['catboost_learning_rate'] = trial.suggest_float('catboost_learning_rate', 0.02, 0.15)
        params['catboost_l2_leaf_reg'] = trial.suggest_float('catboost_l2_leaf_reg', 1.0, 10.0)

        # RandomForest ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params['rf_n_estimators'] = trial.suggest_int('rf_n_estimators', 50, 300)
        params['rf_max_depth'] = trial.suggest_int('rf_max_depth', 5, 20)
        params['rf_min_samples_split'] = trial.suggest_int('rf_min_samples_split', 2, 10)

        return params

    def _create_ensemble_config(self, params: Dict[str, Any]) -> EnsembleConfig:
        """æœ€é©åŒ–ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®šä½œæˆ"""

        config = EnsembleConfig(
            use_xgboost=True,
            use_catboost=True,
            use_random_forest=True,
            use_lstm_transformer=False,
            use_gradient_boosting=False,
            use_svr=False,

            xgboost_params={
                'n_estimators': params.get('xgboost_n_estimators', 300),
                'max_depth': params.get('xgboost_max_depth', 8),
                'learning_rate': params.get('xgboost_learning_rate', 0.05),
                'reg_alpha': params.get('xgboost_reg_alpha', 0.01),
                'reg_lambda': params.get('xgboost_reg_lambda', 1.0),
                'enable_hyperopt': False
            },

            catboost_params={
                'iterations': params.get('catboost_iterations', 500),
                'depth': params.get('catboost_depth', 8),
                'learning_rate': params.get('catboost_learning_rate', 0.05),
                'l2_leaf_reg': params.get('catboost_l2_leaf_reg', 3.0),
                'enable_hyperopt': False,
                'verbose': 0
            },

            random_forest_params={
                'n_estimators': params.get('rf_n_estimators', 200),
                'max_depth': params.get('rf_max_depth', 15),
                'min_samples_split': params.get('rf_min_samples_split', 2),
                'enable_hyperopt': False
            }
        )

        return config

    async def _evaluate_optimized_model(self, ensemble_system: EnsembleSystem,
                                       best_params: Dict[str, Any],
                                       X_train: np.ndarray, y_train: np.ndarray,
                                       X_val: np.ndarray, y_val: np.ndarray) -> Dict[str, float]:
        """æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«ã®è©³ç´°è©•ä¾¡"""

        try:
            # æœ€é©ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«å†è¨“ç·´
            config = self._create_ensemble_config(best_params)
            optimized_ensemble = EnsembleSystem(config)

            feature_names = [f"feature_{i}" for i in range(X_train.shape[1])]
            optimized_ensemble.fit(
                X_train, y_train,
                validation_data=(X_val, y_val),
                feature_names=feature_names
            )

            # äºˆæ¸¬
            predictions = optimized_ensemble.predict(X_val)

            # è©³ç´°è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
            from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

            metrics = {
                'r2_score': r2_score(y_val, predictions.final_predictions),
                'rmse': np.sqrt(mean_squared_error(y_val, predictions.final_predictions)),
                'mae': mean_absolute_error(y_val, predictions.final_predictions),
                'direction_accuracy': np.mean(
                    (y_val > 0) == (predictions.final_predictions > 0)
                ) * 100
            }

            return metrics

        except Exception as e:
            logger.error(f"æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def _check_convergence(self) -> bool:
        """æœ€é©åŒ–åæŸåˆ¤å®š"""
        if not self.study or len(self.study.trials) < 20:
            return False

        # æœ€æ–°20è©¦è¡Œã®æ”¹å–„ç‡ã‚’ç¢ºèª
        recent_values = [trial.value for trial in self.study.trials[-20:] if trial.value is not None]

        if len(recent_values) < 10:
            return False

        # ä¸Šä½10%ã®å€¤ã®åˆ†æ•£ãŒå°ã•ã‘ã‚Œã°åæŸã¨åˆ¤å®š
        top_values = sorted(recent_values, reverse=True)[:max(1, len(recent_values) // 10)]

        if len(top_values) > 1:
            variance = np.var(top_values)
            return variance < 0.001  # åˆ†æ•£ãŒå°ã•ã‘ã‚Œã°åæŸ

        return False

    def _save_optimization_result(self, result: OptimizationResult):
        """æœ€é©åŒ–çµæœä¿å­˜"""
        try:
            filename = f"optimization_{result.timestamp.strftime('%Y%m%d_%H%M%S')}.json"
            filepath = os.path.join(self.results_path, filename)

            # JSONç”¨ã«ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            result_dict = {
                'best_params': result.best_params,
                'best_score': result.best_score,
                'n_trials': result.n_trials,
                'optimization_time': result.optimization_time,
                'market_regime': result.market_regime.value,
                'timestamp': result.timestamp.isoformat(),
                'model_performance': result.model_performance,
                'convergence_achieved': result.convergence_achieved
            }

            with open(filepath, 'w', encoding='utf-8') as f:
                json.dump(result_dict, f, indent=2, ensure_ascii=False)

            logger.info(f"æœ€é©åŒ–çµæœä¿å­˜: {filepath}")

        except Exception as e:
            logger.error(f"æœ€é©åŒ–çµæœä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    async def _send_optimization_notification(self, result: OptimizationResult):
        """æœ€é©åŒ–çµæœé€šçŸ¥"""
        try:
            notification_data = {
                'optimization_score': result.best_score,
                'n_trials': result.n_trials,
                'optimization_time': result.optimization_time,
                'market_regime': result.market_regime.value,
                'convergence_status': 'åæŸ' if result.convergence_achieved else 'æœªåæŸ',
                'performance_summary': ', '.join([
                    f"{k}: {v:.3f}" for k, v in result.model_performance.items()
                ])
            }

            # ã‚«ã‚¹ã‚¿ãƒ é€šçŸ¥ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆä½œæˆ
            from .notification_system import NotificationTemplate, NotificationType, NotificationChannel

            template = NotificationTemplate(
                template_id="optimization_result",
                subject_template="[æœ€é©åŒ–å®Œäº†] ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–çµæœ - {market_regime}ç›¸å ´",
                body_template="""
ğŸ¤– ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è‡ªå‹•æœ€é©åŒ–å®Œäº†

ğŸ“Š æœ€é©åŒ–çµæœ:
- ã‚¹ã‚³ã‚¢: {optimization_score:.4f}
- è©¦è¡Œå›æ•°: {n_trials}å›
- æœ€é©åŒ–æ™‚é–“: {optimization_time:.1f}ç§’
- å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ : {market_regime}
- åæŸçŠ¶æ³: {convergence_status}

ğŸ“ˆ ãƒ¢ãƒ‡ãƒ«æ€§èƒ½:
{performance_summary}

---
Issue #487 Phase 2: é©å¿œçš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ 
""",
                notification_type=NotificationType.SUCCESS,
                channels=[NotificationChannel.LOG, NotificationChannel.CONSOLE, NotificationChannel.FILE]
            )

            self.notification.templates["optimization_result"] = template
            self.notification.send_notification("optimization_result", notification_data)

        except Exception as e:
            logger.error(f"æœ€é©åŒ–çµæœé€šçŸ¥ã‚¨ãƒ©ãƒ¼: {e}")

    def get_regime_adapted_config(self, regime: MarketRegime = None) -> EnsembleConfig:
        """ãƒ¬ã‚¸ãƒ¼ãƒ é©å¿œè¨­å®šå–å¾—"""
        if not regime:
            regime = self.current_regime

        # æœ€æ–°ã®æœ€é©åŒ–çµæœã‹ã‚‰è©²å½“ãƒ¬ã‚¸ãƒ¼ãƒ è¨­å®šã‚’å–å¾—
        regime_optimizations = [
            result for result in self.optimization_history
            if result.market_regime == regime
        ]

        if regime_optimizations:
            # æœ€æ–°ã®æœ€é©åŒ–çµæœã‚’ä½¿ç”¨
            latest_result = max(regime_optimizations, key=lambda x: x.timestamp)
            return self._create_ensemble_config(latest_result.best_params)
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã«ãƒ¬ã‚¸ãƒ¼ãƒ é©å¿œèª¿æ•´
            return self._get_default_regime_config(regime)

    def _get_default_regime_config(self, regime: MarketRegime) -> EnsembleConfig:
        """ãƒ¬ã‚¸ãƒ¼ãƒ åˆ¥ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š"""

        base_config = EnsembleConfig(
            use_xgboost=True,
            use_catboost=True,
            use_random_forest=True,
            use_lstm_transformer=False,
            use_gradient_boosting=False,
            use_svr=False
        )

        if regime == MarketRegime.VOLATILE:
            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: éå­¦ç¿’æŠ‘åˆ¶
            base_config.xgboost_params = {
                'n_estimators': 150, 'max_depth': 4, 'learning_rate': 0.05,
                'reg_alpha': 0.5, 'reg_lambda': 2.0, 'enable_hyperopt': False
            }
            base_config.catboost_params = {
                'iterations': 300, 'depth': 6, 'learning_rate': 0.03,
                'l2_leaf_reg': 5.0, 'enable_hyperopt': False, 'verbose': 0
            }
        elif regime == MarketRegime.BULL:
            # å¼·æ°—ç›¸å ´: ãƒˆãƒ¬ãƒ³ãƒ‰è¿½å¾“
            base_config.xgboost_params = {
                'n_estimators': 400, 'max_depth': 8, 'learning_rate': 0.08,
                'reg_alpha': 0.1, 'reg_lambda': 1.0, 'enable_hyperopt': False
            }
            base_config.catboost_params = {
                'iterations': 600, 'depth': 8, 'learning_rate': 0.06,
                'l2_leaf_reg': 2.0, 'enable_hyperopt': False, 'verbose': 0
            }
        elif regime == MarketRegime.BEAR:
            # å¼±æ°—ç›¸å ´: å®‰å®šæ€§é‡è¦–
            base_config.xgboost_params = {
                'n_estimators': 300, 'max_depth': 6, 'learning_rate': 0.04,
                'reg_alpha': 0.3, 'reg_lambda': 1.5, 'enable_hyperopt': False
            }
            base_config.catboost_params = {
                'iterations': 500, 'depth': 7, 'learning_rate': 0.04,
                'l2_leaf_reg': 3.0, 'enable_hyperopt': False, 'verbose': 0
            }

        return base_config


# ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ã‚¤ãƒ³é–¢æ•°
async def main():
    """ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ¡ã‚¤ãƒ³"""
    logger.info("é©å¿œçš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ")

    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    optimizer = AdaptiveOptimizationSystem()

    # ãƒ†ã‚¹ãƒˆç”¨å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 300
    dates = pd.date_range('2023-01-01', periods=n_samples, freq='D')

    # ã‚ˆã‚Šãƒªã‚¢ãƒ«ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    returns = np.random.normal(0.001, 0.02, n_samples)
    prices = [100.0]
    for r in returns[1:]:
        prices.append(prices[-1] * (1 + r))

    market_data = pd.DataFrame({
        'Date': dates,
        'Close': prices,
        'High': [p * (1 + abs(np.random.normal(0, 0.01))) for p in prices],
        'Low': [p * (1 - abs(np.random.normal(0, 0.01))) for p in prices],
        'Volume': np.random.lognormal(10, 0.5, n_samples)
    })

    # å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºãƒ†ã‚¹ãƒˆ
    logger.info("å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
    regime_metrics = optimizer.detect_market_regime(market_data)

    # æ¤œå‡ºçµæœè¡¨ç¤º
    print("=" * 50)
    print("å¸‚å ´ãƒ¬ã‚¸ãƒ¼ãƒ æ¤œå‡ºçµæœ")
    print("=" * 50)
    print(f"ãƒ¬ã‚¸ãƒ¼ãƒ : {regime_metrics.regime.value}")
    print(f"ä¿¡é ¼åº¦: {regime_metrics.confidence:.2f}")
    print(f"ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£: {regime_metrics.volatility:.3f}")
    print(f"ãƒˆãƒ¬ãƒ³ãƒ‰å¼·åº¦: {regime_metrics.trend_strength:.3f}")
    print(f"ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ : {regime_metrics.momentum:.3f}")
    print(f"ç¶™ç¶šæœŸé–“: {regime_metrics.regime_duration_days}æ—¥")
    print(f"å¤‰åŒ–ç¢ºç‡: {regime_metrics.transition_probability:.2f}")

    # ãƒ¬ã‚¸ãƒ¼ãƒ é©å¿œè¨­å®šå–å¾—
    adapted_config = optimizer.get_regime_adapted_config(regime_metrics.regime)
    print(f"\nãƒ¬ã‚¸ãƒ¼ãƒ é©å¿œè¨­å®š:")
    print(f"XGBoostè¨­å®š: {adapted_config.xgboost_params}")
    print(f"CatBoostè¨­å®š: {adapted_config.catboost_params}")

    logger.info("é©å¿œçš„æœ€é©åŒ–ã‚·ã‚¹ãƒ†ãƒ  ãƒ†ã‚¹ãƒˆå®Œäº†")


if __name__ == "__main__":
    asyncio.run(main())