#!/usr/bin/env python3
"""
Ensemble Learning System for Stock Prediction

Issue #462: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³å®Ÿè£…
è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã—ã€äºˆæ¸¬ç²¾åº¦95%è¶…ã‚’ç›®æŒ‡ã™
"""

import time
from typing import Dict, List, Any, Tuple, Optional, Union
import numpy as np
import pandas as pd
from dataclasses import dataclass, field
from enum import Enum
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings("ignore")

from .base_models import RandomForestModel, GradientBoostingModel, SVRModel, BaseModelInterface
from .base_models.base_model_interface import ModelPrediction, ModelMetrics
from .stacking_ensemble import StackingEnsemble, StackingConfig
from .dynamic_weighting_system import DynamicWeightingSystem, DynamicWeightingConfig
from .advanced_ml_interface import (
    AdvancedMLEngineInterface,
    LSTMTransformerEngine,
    AdvancedModelType,
    create_advanced_ml_engine
)
from ..utils.logging_config import get_context_logger

logger = get_context_logger(__name__)


class EnsembleMethod(Enum):
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•"""
    VOTING = "voting"
    STACKING = "stacking"
    BAGGING = "bagging"
    WEIGHTED = "weighted"


@dataclass
class EnsembleConfig:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š"""
    # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
    use_lstm_transformer: bool = True
    use_random_forest: bool = True
    use_gradient_boosting: bool = True
    use_svr: bool = True

    # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•
    ensemble_methods: List[EnsembleMethod] = field(
        default_factory=lambda: [EnsembleMethod.VOTING, EnsembleMethod.WEIGHTED]
    )

    # é‡ã¿ä»˜ã‘è¨­å®š
    enable_dynamic_weighting: bool = True
    weight_update_frequency: int = 100  # ã‚µãƒ³ãƒ—ãƒ«æ•°
    performance_window: int = 500  # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è©•ä¾¡ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦

    # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°è¨­å®š
    enable_stacking: bool = True
    stacking_config: Optional[StackingConfig] = None

    # å‹•çš„é‡ã¿èª¿æ•´è¨­å®š
    dynamic_weighting_config: Optional[DynamicWeightingConfig] = None

    # äº¤å·®æ¤œè¨¼è¨­å®š
    cv_folds: int = 5
    train_test_split: float = 0.8

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨­å®š
    n_jobs: int = -1
    verbose: bool = True

    # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    random_forest_params: Dict[str, Any] = field(default_factory=lambda: {
        'n_estimators': 200,
        'max_depth': 15,
        'enable_hyperopt': True
    })
    gradient_boosting_params: Dict[str, Any] = field(default_factory=lambda: {
        'n_estimators': 200,
        'learning_rate': 0.1,
        'enable_hyperopt': True,
        'early_stopping': True
    })
    svr_params: Dict[str, Any] = field(default_factory=lambda: {
        'kernel': 'rbf',
        'enable_hyperopt': True
    })


@dataclass
class EnsemblePrediction:
    """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬çµæœ"""
    final_predictions: np.ndarray
    individual_predictions: Dict[str, np.ndarray]
    ensemble_confidence: np.ndarray
    model_weights: Dict[str, float]
    processing_time: float
    method_used: str


class EnsembleSystem:
    """
    ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 

    è¤‡æ•°ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’çµ±åˆã—ã€é«˜ç²¾åº¦ãªæ ªä¾¡äºˆæ¸¬ã‚’å®Ÿç¾
    """

    def __init__(self, config: Optional[EnsembleConfig] = None):
        """
        åˆæœŸåŒ–

        Args:
            config: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
        """
        self.config = config or EnsembleConfig()
        self.base_models: Dict[str, BaseModelInterface] = {}
        self.model_weights: Dict[str, float] = {}
        self.performance_history: List[Dict[str, Any]] = []
        self.is_trained = False

        # é«˜åº¦ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿèƒ½
        self.stacking_ensemble = None
        self.dynamic_weighting = None

        # Issue #473å¯¾å¿œ: Advanced ML Engineï¼ˆæ˜ç¢ºãªã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼‰
        self.advanced_ml_engine: "Optional[AdvancedMLEngineInterface]" = None
        if self.config.use_lstm_transformer:
            try:
                self.advanced_ml_engine = create_advanced_ml_engine(
                    AdvancedModelType.LSTM_TRANSFORMER
                )
                logger.info(f"Advanced ML EngineåˆæœŸåŒ–å®Œäº†: {self.advanced_ml_engine.get_model_type().value}")

                # èƒ½åŠ›æƒ…å ±ã‚’ãƒ­ã‚°å‡ºåŠ›
                capabilities = self.advanced_ml_engine.get_capabilities()
                logger.info(f"Engineèƒ½åŠ›: ã‚·ãƒ¼ã‚±ãƒ³ã‚¹äºˆæ¸¬={capabilities.supports_sequence_prediction}, "
                          f"ä¸ç¢ºå®Ÿæ€§å®šé‡åŒ–={capabilities.supports_uncertainty_quantification}, "
                          f"æ¨è«–ç›®æ¨™æ™‚é–“={capabilities.inference_time_target_ms}ms")
            except Exception as e:
                logger.warning(f"Advanced ML EngineåˆæœŸåŒ–å¤±æ•—: {e}")

        # ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–
        self._initialize_base_models()

        # é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿèƒ½åˆæœŸåŒ–
        self._initialize_advanced_features()

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        self.ensemble_metrics = {}

        logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†: {len(self.base_models)}å€‹ã®ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«")

    def _initialize_base_models(self):
        """ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–"""
        try:
            # Random Forest
            if self.config.use_random_forest:
                self.base_models["random_forest"] = RandomForestModel(self.config.random_forest_params)

            # Gradient Boosting
            if self.config.use_gradient_boosting:
                self.base_models["gradient_boosting"] = GradientBoostingModel(self.config.gradient_boosting_params)

            # SVR
            if self.config.use_svr:
                self.base_models["svr"] = SVRModel(self.config.svr_params)

            # å‡ç­‰é‡ã¿ã§åˆæœŸåŒ–
            n_models = len(self.base_models)
            # Issue #473å¯¾å¿œ: Advanced ML Engine ã®çµ±åˆ
            if self.advanced_ml_engine and self.advanced_ml_engine.is_trained():
                n_models += 1
                self.model_weights["lstm_transformer"] = 1.0 / n_models

            for model_name in self.base_models.keys():
                self.model_weights[model_name] = 1.0 / n_models

            logger.info(f"åˆæœŸé‡ã¿è¨­å®š: {self.model_weights}")

        except Exception as e:
            logger.error(f"ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _initialize_advanced_features(self):
        """é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿèƒ½åˆæœŸåŒ–"""
        try:
            # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆæœŸåŒ–
            if self.config.enable_stacking and len(self.base_models) >= 2:
                stacking_config = self.config.stacking_config or StackingConfig()
                self.stacking_ensemble = StackingEnsemble(self.base_models, stacking_config)
                logger.info("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«åˆæœŸåŒ–å®Œäº†")

            # å‹•çš„é‡ã¿èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
            if self.config.enable_dynamic_weighting:
                model_names = list(self.base_models.keys())
                # Issue #473å¯¾å¿œ: Advanced ML Engine ã®çµ±åˆ
                if self.advanced_ml_engine:
                    model_names.append("lstm_transformer")

                dw_config = self.config.dynamic_weighting_config or DynamicWeightingConfig()
                self.dynamic_weighting = DynamicWeightingSystem(model_names, dw_config)
                logger.info("å‹•çš„é‡ã¿èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–å®Œäº†")

        except Exception as e:
            logger.warning(f"é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ©Ÿèƒ½åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def fit(self, X: np.ndarray, y: np.ndarray,
            validation_data: Optional[Tuple[np.ndarray, np.ndarray]] = None,
            feature_names: Optional[List[str]] = None) -> Dict[str, Any]:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ å­¦ç¿’

        Args:
            X: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ (n_samples, n_features)
            y: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç›®æ¨™å¤‰æ•° (n_samples,)
            validation_data: æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ (X_val, y_val)
            feature_names: ç‰¹å¾´é‡åãƒªã‚¹ãƒˆ

        Returns:
            å­¦ç¿’çµæœè¾æ›¸
        """
        start_time = time.time()
        logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’é–‹å§‹: ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ {X.shape}")

        try:
            # ç‰¹å¾´é‡åè¨­å®š
            if feature_names:
                for model in self.base_models.values():
                    model.set_feature_names(feature_names)

            # å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’
            model_results = {}

            # 1. Advanced ML Engineå­¦ç¿’ï¼ˆIssue #473å¯¾å¿œï¼‰
            if self.advanced_ml_engine:
                try:
                    logger.info(f"Advanced ML Engineå­¦ç¿’é–‹å§‹: {self.advanced_ml_engine.get_model_type().value}")

                    # ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ã®æ¤œè¨¼
                    if not self.advanced_ml_engine.validate_input_shape(X):
                        logger.warning("Advanced ML Engine: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶ãŒä¸é©åˆ‡ã§ã™")

                    # å­¦ç¿’å®Ÿè¡Œ
                    training_metrics = self.advanced_ml_engine.train(X, y, validation_data)
                    model_results["lstm_transformer"] = {
                        "status": "å­¦ç¿’å®Œäº†",
                        "metrics": training_metrics,
                        "model_type": self.advanced_ml_engine.get_model_type().value
                    }
                    logger.info(f"Advanced ML Engineå­¦ç¿’å®Œäº†: ç²¾åº¦={training_metrics.accuracy:.4f}")

                except Exception as e:
                    logger.warning(f"Advanced ML Engineå­¦ç¿’å¤±æ•—: {e}")
                    model_results["lstm_transformer"] = {"status": "å­¦ç¿’å¤±æ•—", "error": str(e)}

            # 2. å¾“æ¥MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’
            for model_name, model in self.base_models.items():
                try:
                    logger.info(f"{model_name}å­¦ç¿’é–‹å§‹")
                    result = model.fit(X, y, validation_data=validation_data)
                    model_results[model_name] = result
                    logger.info(f"{model_name}å­¦ç¿’å®Œäº†")
                except Exception as e:
                    logger.error(f"{model_name}å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
                    model_results[model_name] = {"status": "å¤±æ•—", "error": str(e)}

            # 3. ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
            if self.stacking_ensemble and validation_data:
                logger.info("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’é–‹å§‹")
                stacking_results = self.stacking_ensemble.fit(X, y, validation_data)
                model_results["stacking_ensemble"] = stacking_results

            # 4. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–
            if validation_data and self.config.enable_dynamic_weighting:
                self._optimize_ensemble_weights(validation_data[0], validation_data[1])

            # å­¦ç¿’çµæœã¾ã¨ã‚
            training_results = {
                'total_training_time': time.time() - start_time,
                'model_results': model_results,
                'final_weights': self.model_weights.copy(),
                'ensemble_methods': [method.value for method in self.config.ensemble_methods]
            }

            # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
            if validation_data:
                X_val, y_val = validation_data
                ensemble_metrics = self._evaluate_ensemble(X_val, y_val)
                training_results['ensemble_validation_metrics'] = ensemble_metrics

                logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ¤œè¨¼RMSE: {ensemble_metrics.get('rmse', 'N/A'):.4f}")
                logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ« Hit Rate: {ensemble_metrics.get('hit_rate', 'N/A'):.3f}")

            self.is_trained = True
            self.performance_history.append(training_results)

            logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’å®Œäº†: {time.time() - start_time:.2f}ç§’")
            return training_results

        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def predict(self, X: np.ndarray, method: Optional[EnsembleMethod] = None) -> EnsemblePrediction:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œ

        Args:
            X: äºˆæ¸¬å¯¾è±¡ã®ç‰¹å¾´é‡ (n_samples, n_features)
            method: ä½¿ç”¨ã™ã‚‹ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æ‰‹æ³•

        Returns:
            EnsemblePrediction: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬çµæœ
        """
        if not self.is_trained:
            raise ValueError("ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã•ã‚Œã¦ã„ã¾ã›ã‚“")

        start_time = time.time()

        try:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæ‰‹æ³•é¸æŠ
            if method is None:
                method = self.config.ensemble_methods[0]

            # å„ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã®äºˆæ¸¬åé›†
            individual_predictions = {}

            # 1. Advanced ML Engineäºˆæ¸¬ï¼ˆIssue #473å¯¾å¿œï¼‰
            if self.advanced_ml_engine and self.advanced_ml_engine.is_trained() and "lstm_transformer" in self.model_weights:
                try:
                    # Issue #473å¯¾å¿œ: çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã«ã‚ˆã‚‹äºˆæ¸¬
                    if not self.advanced_ml_engine.validate_input_shape(X):
                        logger.warning("Advanced ML Engine: å…¥åŠ›å½¢çŠ¶ãŒç„¡åŠ¹")
                        lstm_pred = np.zeros(len(X))  # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                    else:
                        transformed_X = self.advanced_ml_engine.prepare_data(X)
                        prediction_result = self.advanced_ml_engine.predict(
                            transformed_X,
                            return_confidence=True,
                            return_attention=False
                        )

                        if hasattr(prediction_result, 'predictions') and prediction_result.predictions is not None:
                            lstm_pred = prediction_result.predictions.flatten()
                            logger.debug(f"Advanced ML Engineäºˆæ¸¬: å½¢çŠ¶{prediction_result.predictions.shape}, "
                                      f"ä¿¡é ¼åº¦å¹³å‡={getattr(prediction_result, 'confidence', 'N/A')}")
                        else:
                            lstm_pred = np.zeros(len(X))

                    individual_predictions["lstm_transformer"] = lstm_pred
                except Exception as e:
                    logger.warning(f"LSTM-Transformeräºˆæ¸¬å¤±æ•—: {e}")

            # 2. å¾“æ¥MLãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
            for model_name, model in self.base_models.items():
                if not model.is_trained:
                    continue
                try:
                    pred_result = model.predict(X)
                    individual_predictions[model_name] = pred_result.predictions
                except Exception as e:
                    logger.warning(f"{model_name}äºˆæ¸¬å¤±æ•—: {e}")

            # 3. ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«çµ±åˆ
            if method == EnsembleMethod.VOTING:
                final_predictions = self._voting_ensemble(individual_predictions)
            elif method == EnsembleMethod.WEIGHTED:
                final_predictions = self._weighted_ensemble(individual_predictions)
            elif method == EnsembleMethod.STACKING:
                final_predictions = self._stacking_ensemble(individual_predictions, X)
            else:
                final_predictions = self._voting_ensemble(individual_predictions)

            # ä¿¡é ¼åº¦è¨ˆç®—
            ensemble_confidence = self._calculate_ensemble_confidence(individual_predictions)

            # å‹•çš„é‡ã¿èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ ã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
            if self.dynamic_weighting:
                self.dynamic_weighting.current_weights = self.model_weights.copy()

            processing_time = time.time() - start_time

            return EnsemblePrediction(
                final_predictions=final_predictions,
                individual_predictions=individual_predictions,
                ensemble_confidence=ensemble_confidence,
                model_weights=self.model_weights.copy(),
                processing_time=processing_time,
                method_used=method.value
            )

        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ã‚¨ãƒ©ãƒ¼: {e}")
            raise

    def _voting_ensemble(self, predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """æŠ•ç¥¨ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå˜ç´”å¹³å‡ï¼‰"""
        if not predictions:
            raise ValueError("äºˆæ¸¬çµæœãŒç©ºã§ã™")

        # å…¨äºˆæ¸¬ã‚’é…åˆ—ã«å¤‰æ›
        pred_array = np.array(list(predictions.values()))

        # å˜ç´”å¹³å‡
        return np.mean(pred_array, axis=0)

    def _weighted_ensemble(self, predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«"""
        if not predictions:
            raise ValueError("äºˆæ¸¬çµæœãŒç©ºã§ã™")

        weighted_sum = np.zeros_like(list(predictions.values())[0])
        total_weight = 0.0

        for model_name, pred in predictions.items():
            if model_name in self.model_weights:
                weight = self.model_weights[model_name]
                weighted_sum += weight * pred
                total_weight += weight

        if total_weight > 0:
            return weighted_sum / total_weight
        else:
            return self._voting_ensemble(predictions)

    def _stacking_ensemble(self, predictions: Dict[str, np.ndarray], X: np.ndarray) -> np.ndarray:
        """ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆãƒ¡ã‚¿å­¦ç¿’ï¼‰"""
        if self.stacking_ensemble and self.stacking_ensemble.is_fitted:
            try:
                # ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§äºˆæ¸¬
                stacking_result = self.stacking_ensemble.predict(X)
                return stacking_result.predictions
            except Exception as e:
                logger.warning(f"ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°äºˆæ¸¬å¤±æ•—: {e}, é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ä»£æ›¿")
                return self._weighted_ensemble(predictions)
        else:
            logger.warning("ã‚¹ã‚¿ãƒƒã‚­ãƒ³ã‚°ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æœªå­¦ç¿’ã€é‡ã¿ä»˜ãã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã§ä»£æ›¿")
            return self._weighted_ensemble(predictions)

    def _calculate_ensemble_confidence(self, predictions: Dict[str, np.ndarray]) -> np.ndarray:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ä¿¡é ¼åº¦è¨ˆç®—"""
        if len(predictions) < 2:
            return np.ones(len(list(predictions.values())[0])) * 0.5

        # äºˆæ¸¬ã®åˆ†æ•£ã‚’ä¿¡é ¼åº¦ã¨ã™ã‚‹ï¼ˆåˆ†æ•£ãŒå°ã•ã„ã»ã©ä¿¡é ¼åº¦ãŒé«˜ã„ï¼‰
        pred_array = np.array(list(predictions.values()))
        prediction_variance = np.var(pred_array, axis=0)

        # æ­£è¦åŒ–ã—ã¦ä¿¡é ¼åº¦ã«å¤‰æ›ï¼ˆåˆ†æ•£ãŒå¤§ãã„ã»ã©ä¿¡é ¼åº¦ã¯ä½ã„ï¼‰
        max_var = np.max(prediction_variance)
        if max_var > 0:
            confidence = 1.0 - (prediction_variance / max_var)
        else:
            confidence = np.ones_like(prediction_variance)

        return confidence

    def _optimize_ensemble_weights(self, X_val: np.ndarray, y_val: np.ndarray):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«é‡ã¿æœ€é©åŒ–"""
        try:
            from scipy.optimize import minimize

            # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å–å¾—
            model_predictions = {}
            for model_name, model in self.base_models.items():
                if model.is_trained:
                    pred_result = model.predict(X_val)
                    model_predictions[model_name] = pred_result.predictions

            if len(model_predictions) < 2:
                logger.warning("é‡ã¿æœ€é©åŒ–ã«ååˆ†ãªãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
                return

            model_names = list(model_predictions.keys())
            pred_matrix = np.array([model_predictions[name] for name in model_names]).T

            # ç›®çš„é–¢æ•°ï¼šé‡ã¿ä»˜ãäºˆæ¸¬ã®MSEæœ€å°åŒ–
            def objective(weights):
                weights = weights / np.sum(weights)  # æ­£è¦åŒ–
                ensemble_pred = np.dot(pred_matrix, weights)
                mse = np.mean((y_val - ensemble_pred) ** 2)
                return mse

            # åˆ¶ç´„ï¼šé‡ã¿ã®åˆè¨ˆ=1ã€å„é‡ã¿>=0
            constraints = {'type': 'eq', 'fun': lambda w: np.sum(w) - 1}
            bounds = [(0.0, 1.0) for _ in model_names]

            # åˆæœŸé‡ã¿ï¼ˆå‡ç­‰ï¼‰
            initial_weights = np.ones(len(model_names)) / len(model_names)

            # æœ€é©åŒ–å®Ÿè¡Œ
            result = minimize(objective, initial_weights,
                            method='SLSQP', bounds=bounds, constraints=constraints)

            if result.success:
                optimal_weights = result.x / np.sum(result.x)  # æ­£è¦åŒ–

                # é‡ã¿æ›´æ–°
                for i, model_name in enumerate(model_names):
                    self.model_weights[model_name] = optimal_weights[i]

                logger.info(f"é‡ã¿æœ€é©åŒ–å®Œäº†: {dict(zip(model_names, optimal_weights))}")
            else:
                logger.warning("é‡ã¿æœ€é©åŒ–å¤±æ•—ã€ç¾åœ¨ã®é‡ã¿ã‚’ç¶­æŒ")

        except ImportError:
            logger.warning("scipy.optimizeæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã€é‡ã¿æœ€é©åŒ–ã‚¹ã‚­ãƒƒãƒ—")
        except Exception as e:
            logger.error(f"é‡ã¿æœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def _evaluate_ensemble(self, X: np.ndarray, y: np.ndarray) -> Dict[str, float]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡"""
        try:
            ensemble_pred = self.predict(X, method=EnsembleMethod.WEIGHTED)
            y_pred = ensemble_pred.final_predictions

            # åŸºæœ¬æŒ‡æ¨™
            mse = mean_squared_error(y, y_pred)
            rmse = np.sqrt(mse)
            mae = mean_absolute_error(y, y_pred)
            r2 = r2_score(y, y_pred)

            # Hit Rate
            if len(y) > 1:
                y_diff = np.diff(y)
                pred_diff = np.diff(y_pred)
                direction_match = np.sign(y_diff) == np.sign(pred_diff)
                hit_rate = np.mean(direction_match)
            else:
                hit_rate = 0.5

            return {
                'mse': mse,
                'rmse': rmse,
                'mae': mae,
                'r2_score': r2,
                'hit_rate': hit_rate
            }

        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡ã‚¨ãƒ©ãƒ¼: {e}")
            return {}

    def get_model_performance_comparison(self, X: np.ndarray, y: np.ndarray) -> pd.DataFrame:
        """å€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æ€§èƒ½æ¯”è¼ƒ"""
        results = []

        # å„ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
        for model_name, model in self.base_models.items():
            if not model.is_trained:
                continue
            try:
                metrics = model.evaluate(X, y)
                results.append({
                    'model': model_name,
                    'rmse': metrics.rmse,
                    'mae': metrics.mae,
                    'r2_score': metrics.r2_score,
                    'hit_rate': metrics.hit_rate,
                    'weight': self.model_weights.get(model_name, 0.0)
                })
            except Exception as e:
                logger.warning(f"{model_name}è©•ä¾¡å¤±æ•—: {e}")

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è©•ä¾¡
        ensemble_metrics = self._evaluate_ensemble(X, y)
        if ensemble_metrics:
            results.append({
                'model': 'ensemble',
                'rmse': ensemble_metrics['rmse'],
                'mae': ensemble_metrics['mae'],
                'r2_score': ensemble_metrics['r2_score'],
                'hit_rate': ensemble_metrics['hit_rate'],
                'weight': 1.0
            })

        return pd.DataFrame(results).sort_values('rmse')

    def save_ensemble(self, filepath: str, compress: bool = True) -> bool:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ä¿å­˜ - Issue #706å¯¾å¿œæœ€é©åŒ–ç‰ˆ

        Args:
            filepath: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            compress: åœ§ç¸®ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã‹

        Returns:
            bool: ä¿å­˜æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            import pickle
            import gzip
            from pathlib import Path

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèªã¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
            save_path = Path(filepath)
            save_path.parent.mkdir(parents=True, exist_ok=True)

            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ã¿ä¿å­˜ï¼ˆè»½é‡åŒ–ï¼‰
            ensemble_data = {
                'config': self.config,
                'model_weights': self.model_weights,
                'performance_history': self.performance_history,
                'is_trained': self.is_trained,
                'ensemble_metrics': self.ensemble_metrics,
                'version': '2.0',  # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
                'save_timestamp': time.time()
            }

            # å„ãƒ¢ãƒ‡ãƒ«ã¯è»½é‡ãªçŠ¶æ…‹æƒ…å ±ã®ã¿ä¿å­˜
            model_data = {}
            for model_name, model in self.base_models.items():
                # å¤§ããªãƒ¢ãƒ‡ãƒ«ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ãªãã€å†æ§‹ç¯‰å¯èƒ½ãªæƒ…å ±ã®ã¿
                model_info = {
                    'model_type': type(model).__name__,
                    'config': model.config,
                    'is_trained': model.is_trained,
                    'feature_names': getattr(model, 'feature_names', []),
                    'training_metrics': getattr(model, 'training_metrics', {}),
                }

                # scikit-learn ãƒ¢ãƒ‡ãƒ«ã®å ´åˆã€å­¦ç¿’æ¸ˆã¿ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                if hasattr(model, 'model') and hasattr(model.model, 'get_params'):
                    model_info['sklearn_params'] = model.model.get_params()

                model_data[model_name] = model_info

            ensemble_data['models'] = model_data

            # åœ§ç¸®ä¿å­˜ã¾ãŸã¯é€šå¸¸ä¿å­˜
            if compress:
                with gzip.open(f"{filepath}.gz", 'wb') as f:
                    pickle.dump(ensemble_data, f, protocol=pickle.HIGHEST_PROTOCOL)
                saved_path = f"{filepath}.gz"
            else:
                with open(filepath, 'wb') as f:
                    pickle.dump(ensemble_data, f, protocol=pickle.HIGHEST_PROTOCOL)
                saved_path = filepath

            logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ä¿å­˜å®Œäº†: {saved_path}")
            return True

        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def load_ensemble(self, filepath: str) -> bool:
        """
        ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ - Issue #706å¯¾å¿œæ–°æ©Ÿèƒ½

        Args:
            filepath: èª­ã¿è¾¼ã¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Returns:
            bool: èª­ã¿è¾¼ã¿æˆåŠŸãƒ•ãƒ©ã‚°
        """
        try:
            import pickle
            import gzip
            from pathlib import Path

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            load_path = Path(filepath)
            gz_path = Path(f"{filepath}.gz")

            if gz_path.exists():
                # åœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                with gzip.open(gz_path, 'rb') as f:
                    ensemble_data = pickle.load(f)
                loaded_from = gz_path
            elif load_path.exists():
                # éåœ§ç¸®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
                with open(load_path, 'rb') as f:
                    ensemble_data = pickle.load(f)
                loaded_from = load_path
            else:
                raise FileNotFoundError(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")

            # ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª
            version = ensemble_data.get('version', '1.0')
            if version != '2.0':
                logger.warning(f"å¤ã„ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«: {version}")

            # åŸºæœ¬æƒ…å ±ã®å¾©å…ƒ
            self.config = ensemble_data['config']
            self.model_weights = ensemble_data['model_weights']
            self.performance_history = ensemble_data['performance_history']
            self.is_trained = ensemble_data['is_trained']
            self.ensemble_metrics = ensemble_data.get('ensemble_metrics', {})

            # ãƒ¢ãƒ‡ãƒ«ã®å†æ§‹ç¯‰ï¼ˆè»½é‡ç‰ˆï¼‰
            self.base_models = {}
            model_data = ensemble_data['models']

            for model_name, model_info in model_data.items():
                # ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—ã«åŸºã¥ã„ã¦å†æ§‹ç¯‰
                model_type = model_info['model_type']
                model_config = model_info['config']

                if model_type == 'RandomForestModel':
                    model = RandomForestModel(model_config)
                elif model_type == 'GradientBoostingModel':
                    model = GradientBoostingModel(model_config)
                elif model_type == 'SVRModel':
                    model = SVRModel(model_config)
                else:
                    logger.warning(f"æœªå¯¾å¿œã®ãƒ¢ãƒ‡ãƒ«ã‚¿ã‚¤ãƒ—: {model_type}")
                    continue

                # åŸºæœ¬æƒ…å ±ã®å¾©å…ƒ
                model.is_trained = model_info['is_trained']
                if 'feature_names' in model_info:
                    model.set_feature_names(model_info['feature_names'])
                model.training_metrics = model_info.get('training_metrics', {})

                self.base_models[model_name] = model

            # ã‚µãƒ–ã‚·ã‚¹ãƒ†ãƒ ã®åˆæœŸåŒ–ï¼ˆè¨­å®šã®ã¿ï¼‰
            self._initialize_subsystems()

            logger.info(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿å®Œäº†: {loaded_from}")
            logger.info(f"èª­ã¿è¾¼ã¾ã‚ŒãŸãƒ¢ãƒ‡ãƒ«æ•°: {len(self.base_models)}")
            return True

        except Exception as e:
            logger.error(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False

    def update_dynamic_weights(self, predictions: Dict[str, np.ndarray],
                              actuals: np.ndarray, timestamp: int = None):
        """
        Issue #472å¯¾å¿œ: ç°¡ç´ åŒ–ã•ã‚ŒãŸå‹•çš„é‡ã¿æ›´æ–°

        DynamicWeightingSystemãŒå†…éƒ¨ã§å®Œçµã—ãŸé‡ã¿æ›´æ–°ãƒ»åŒæœŸã‚’å®Ÿè¡Œ

        Args:
            predictions: ãƒ¢ãƒ‡ãƒ«åˆ¥äºˆæ¸¬å€¤
            actuals: å®Ÿéš›ã®å€¤
            timestamp: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
        """
        if self.dynamic_weighting:
            try:
                # Issue #472å¯¾å¿œ: ä¸€æ‹¬æ›´æ–°ãƒ»åŒæœŸå‡¦ç†
                updated_weights = self.dynamic_weighting.sync_and_update_performance(
                    predictions, actuals, self.model_weights, timestamp
                )

                logger.debug(f"å‹•çš„é‡ã¿æ›´æ–°å®Œäº†: {len(updated_weights)}ãƒ¢ãƒ‡ãƒ«")

            except Exception as e:
                logger.warning(f"å‹•çš„é‡ã¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")

    def create_simplified_weight_updater(self):
        """
        Issue #472å¯¾å¿œ: ç°¡æ½”ãªé‡ã¿æ›´æ–°é–¢æ•°ã®ç”Ÿæˆ

        Returns:
            ç°¡æ½”ãªé‡ã¿æ›´æ–°é–¢æ•°
        """
        if not self.dynamic_weighting:
            return lambda *args, **kwargs: False

        return self.dynamic_weighting.create_weight_updater()

    def get_dynamic_weight_update_strategy(self) -> str:
        """
        Issue #472å¯¾å¿œ: å‹•çš„é‡ã¿æ›´æ–°æˆ¦ç•¥ã®å–å¾—

        Returns:
            ç¾åœ¨ã®é‡ã¿æ›´æ–°æˆ¦ç•¥ã®èª¬æ˜
        """
        if not self.dynamic_weighting:
            return "å‹•çš„é‡ã¿èª¿æ•´ã¯ç„¡åŠ¹ã§ã™"

        strategy_info = [
            "çµ±åˆé‡ã¿æ›´æ–°æˆ¦ç•¥:",
            "1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è“„ç©",
            "2. é‡ã¿å†è¨ˆç®—ï¼ˆé–¾å€¤é”æˆæ™‚ï¼‰",
            "3. EnsembleSystemé‡ã¿ç›´æ¥åŒæœŸ",
            "4. æ‰‹å‹•ãƒãƒ¼ã‚¸å‡¦ç†ã®æ’é™¤"
        ]

        return " â†’ ".join(strategy_info)

    def get_ensemble_info(self) -> Dict[str, Any]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«æƒ…å ±å–å¾—"""
        info = {
            'is_trained': self.is_trained,
            'n_base_models': len(self.base_models),
            'model_names': list(self.base_models.keys()),
            'model_weights': self.model_weights,
            'ensemble_methods': [method.value for method in self.config.ensemble_methods],
            'performance_history_count': len(self.performance_history)
        }

        # é«˜åº¦æ©Ÿèƒ½ã®æƒ…å ±è¿½åŠ 
        if self.stacking_ensemble:
            info['stacking_info'] = self.stacking_ensemble.get_stacking_info()

        if self.dynamic_weighting:
            info['dynamic_weighting_info'] = self.dynamic_weighting.get_performance_summary()

        return info


def run_ensemble_demo():
    """
    Issue #471å¯¾å¿œ: EnsembleSystemç°¡æ˜“ãƒ‡ãƒ¢å®Ÿè¡Œ

    åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã¯ tests/ml/test_ensemble_system_comprehensive.py ã§å®Ÿè¡Œ
    """
    print("=== Ensemble System ç°¡æ˜“ãƒ‡ãƒ¢ ===")
    print("è©³ç´°ãªãƒ†ã‚¹ãƒˆã¯ tests/ml/test_ensemble_system_comprehensive.py ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„")

    try:
        # æœ€å°é™ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        np.random.seed(42)
        n_samples, n_features = 100, 10  # ã‚µã‚¤ã‚ºã‚’ç¸®å°
        X = np.random.randn(n_samples, n_features)
        y = np.sum(X[:, :3], axis=1) + 0.1 * np.random.randn(n_samples)

        # ç°¡å˜ãªã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«è¨­å®š
        config = EnsembleConfig(
            use_random_forest=True,
            use_gradient_boosting=False,  # ãƒ‡ãƒ¢ã§ã¯ç„¡åŠ¹åŒ–
            use_svr=False,
            use_lstm_transformer=False,
            enable_stacking=False,
            enable_dynamic_weighting=False,
        )

        ensemble = EnsembleSystem(config)

        print(f"âœ… EnsembleSystemåˆæœŸåŒ–æˆåŠŸ")
        print(f"   - ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æ•°: {len(ensemble.base_models)}")
        print(f"   - è¨­å®š: {config}")

        # æœ€å°é™ã®å­¦ç¿’ãƒ†ã‚¹ãƒˆ
        feature_names = [f"feature_{i}" for i in range(n_features)]

        print("ğŸ“Š ç°¡æ˜“å­¦ç¿’ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        results = ensemble.fit(X[:50], y[:50], feature_names=feature_names)

        print(f"âœ… å­¦ç¿’å®Œäº†")
        print(f"   - å­¦ç¿’æ™‚é–“: {results.get('total_training_time', 'N/A')}")
        print(f"   - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«: {len([k for k, v in results.items() if isinstance(v, dict) and v.get('status') != 'å¤±æ•—'])}")

        # æœ€å°é™ã®äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
        prediction = ensemble.predict(X[50:60])

        print(f"âœ… äºˆæ¸¬å®Œäº†")
        print(f"   - äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(prediction.final_predictions)}")
        print(f"   - ä½¿ç”¨æ‰‹æ³•: {prediction.method_used}")

        print("\nğŸ¯ ãƒ‡ãƒ¢å®Œäº†: EnsembleSystemãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        print("   è©³ç´°ãªãƒ†ã‚¹ãƒˆã¨ã‚«ãƒãƒ¬ãƒƒã‚¸ã¯ä»¥ä¸‹ã§å®Ÿè¡Œ:")
        print("   python -m pytest tests/ml/test_ensemble_system_comprehensive.py -v")

        return True

    except Exception as e:
        print(f"âŒ ãƒ‡ãƒ¢å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        print("   è©³ç´°ãªã‚¨ãƒ©ãƒ¼è§£æã¯åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã§ç¢ºèªã—ã¦ãã ã•ã„")
        return False


if __name__ == "__main__":
    success = run_ensemble_demo()
    exit(0 if success else 1)