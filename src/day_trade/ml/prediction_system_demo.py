#!/usr/bin/env python3
"""
Issue #870 äºˆæ¸¬ç²¾åº¦å‘ä¸Šã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
æ–°æ©Ÿèƒ½ã®å®Ÿç”¨ä¾‹ã¨ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯æ¯”è¼ƒ
"""

import numpy as np
import pandas as pd
import logging
import time
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# æ–°å®Ÿè£…ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from advanced_feature_selector import create_advanced_feature_selector
    from advanced_ensemble_system import create_advanced_ensemble_system, EnsembleMethod
    from meta_learning_system import create_meta_learning_system, TaskType
    from comprehensive_prediction_evaluation import create_comprehensive_evaluator
    NEW_SYSTEMS_AVAILABLE = True
except ImportError as e:
    print(f"æ–°ã‚·ã‚¹ãƒ†ãƒ ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    NEW_SYSTEMS_AVAILABLE = False

# åŸºæœ¬ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from sklearn.model_selection import train_test_split


def create_realistic_stock_data(n_samples: int = 1000, n_features: int = 30,
                               noise_level: float = 0.1) -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame]:
    """ãƒªã‚¢ãƒ«ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
    np.random.seed(42)

    # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    dates = pd.date_range(start='2020-01-01', periods=n_samples, freq='D')

    # ãƒ™ãƒ¼ã‚¹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿
    base_price = 100
    price_changes = np.cumsum(np.random.randn(n_samples) * 0.02)
    prices = base_price + price_changes

    # æŠ€è¡“æŒ‡æ¨™é¢¨ç‰¹å¾´é‡
    features = {}

    # 1. ç§»å‹•å¹³å‡ç³»
    for period in [5, 10, 20, 50]:
        ma = pd.Series(prices).rolling(window=period).mean()
        features[f'ma_{period}'] = ma.values
        features[f'price_ma_{period}_ratio'] = prices / ma.values

    # 2. ãƒ¢ãƒ¡ãƒ³ã‚¿ãƒ ç³»
    for period in [5, 10, 20]:
        momentum = pd.Series(prices).pct_change(period)
        features[f'momentum_{period}'] = momentum.values

        rsi_like = 50 + 50 * np.tanh(momentum.values * 10)  # RSIé¢¨
        features[f'rsi_{period}'] = rsi_like

    # 3. ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ç³»
    for period in [5, 10, 20]:
        volatility = pd.Series(prices).rolling(window=period).std()
        features[f'volatility_{period}'] = volatility.values

    # 4. å‡ºæ¥é«˜é¢¨ãƒ‡ãƒ¼ã‚¿
    volume = np.random.exponential(10000, n_samples) * (1 + np.abs(price_changes) * 2)
    features['volume'] = volume
    features['volume_ma_ratio'] = volume / pd.Series(volume).rolling(window=20).mean().values

    # 5. å¤–éƒ¨è¦å› ï¼ˆãƒã‚¯ãƒ­çµŒæ¸ˆæŒ‡æ¨™é¢¨ï¼‰
    for i in range(5):
        features[f'macro_{i}'] = np.cumsum(np.random.randn(n_samples) * 0.01)

    # 6. ãƒ©ãƒ³ãƒ€ãƒ ç‰¹å¾´é‡ï¼ˆãƒã‚¤ã‚ºï¼‰
    for i in range(8):
        features[f'noise_{i}'] = np.random.randn(n_samples) * 0.5

    # DataFrameä½œæˆ
    X = pd.DataFrame(features, index=dates)
    X = X.fillna(method='bfill').fillna(0)  # æ¬ æå€¤å‡¦ç†

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆï¼ˆæ¬¡ã®æ—¥ã®ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
    returns = pd.Series(prices).pct_change().shift(-1)
    y = returns.fillna(0)

    # ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ï¼ˆå¸‚å ´çŠ¶æ³æ¤œå‡ºç”¨ï¼‰
    price_data = pd.DataFrame({
        'close': prices,
        'volume': volume,
        'high': prices * (1 + np.abs(np.random.randn(n_samples)) * 0.01),
        'low': prices * (1 - np.abs(np.random.randn(n_samples)) * 0.01),
        'open': prices + np.random.randn(n_samples) * 0.005
    }, index=dates)

    return X, y, price_data


def run_traditional_models(X_train: pd.DataFrame, y_train: pd.Series,
                          X_test: pd.DataFrame, y_test: pd.Series) -> Dict[str, Dict]:
    """å¾“æ¥æ‰‹æ³•ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯"""
    results = {}

    models = {
        'linear_regression': LinearRegression(),
        'random_forest': RandomForestRegressor(n_estimators=100, random_state=42),
        'simple_ensemble': None  # æ‰‹å‹•ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
    }

    for name, model in models.items():
        if name == 'simple_ensemble':
            # æ‰‹å‹•ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ï¼ˆå˜ç´”å¹³å‡ï¼‰
            lr = LinearRegression()
            rf = RandomForestRegressor(n_estimators=50, random_state=42)

            lr.fit(X_train, y_train)
            rf.fit(X_train, y_train)

            lr_pred = lr.predict(X_test)
            rf_pred = rf.predict(X_test)
            predictions = (lr_pred + rf_pred) / 2

        else:
            start_time = time.time()
            model.fit(X_train, y_train)
            training_time = time.time() - start_time

            start_time = time.time()
            predictions = model.predict(X_test)
            prediction_time = time.time() - start_time

        # è©•ä¾¡
        r2 = r2_score(y_test, predictions)
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)

        # æ–¹å‘æ€§ç²¾åº¦
        actual_direction = np.sign(y_test.values[1:] - y_test.values[:-1])
        pred_direction = np.sign(predictions[1:] - predictions[:-1])
        directional_accuracy = np.mean(actual_direction == pred_direction)

        results[name] = {
            'r2': r2,
            'mse': mse,
            'mae': mae,
            'directional_accuracy': directional_accuracy,
            'training_time': training_time if name != 'simple_ensemble' else 0.1,
            'prediction_time': prediction_time if name != 'simple_ensemble' else 0.01
        }

    return results


def run_advanced_systems(X_train: pd.DataFrame, y_train: pd.Series,
                        X_test: pd.DataFrame, y_test: pd.Series,
                        price_data: pd.DataFrame) -> Dict[str, Dict]:
    """æ–°ã‚·ã‚¹ãƒ†ãƒ ã§ã®äºˆæ¸¬"""
    if not NEW_SYSTEMS_AVAILABLE:
        return {}

    results = {}

    # 1. ç‰¹å¾´é‡é¸æŠ + åŸºæœ¬ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
    try:
        start_time = time.time()

        # ç‰¹å¾´é‡é¸æŠ
        selector = create_advanced_feature_selector(max_features=20)
        selected_X_train, selection_info = selector.select_features(
            X_train, y_train, price_data, method='ensemble'
        )
        selected_X_test = X_test[selection_info['selected_features']]

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬
        ensemble = create_advanced_ensemble_system(
            method=EnsembleMethod.STACKING, cv_folds=3
        )
        ensemble.fit(selected_X_train, y_train)
        predictions = ensemble.predict(selected_X_test)

        total_time = time.time() - start_time

        # è©•ä¾¡
        r2 = r2_score(y_test, predictions)
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)

        actual_direction = np.sign(y_test.values[1:] - y_test.values[:-1])
        pred_direction = np.sign(predictions[1:] - predictions[:-1])
        directional_accuracy = np.mean(actual_direction == pred_direction)

        results['advanced_ensemble'] = {
            'r2': r2,
            'mse': mse,
            'mae': mae,
            'directional_accuracy': directional_accuracy,
            'training_time': total_time * 0.8,
            'prediction_time': total_time * 0.2,
            'selected_features': len(selection_info['selected_features']),
            'market_regime': selection_info.get('market_regime', 'unknown')
        }

    except Exception as e:
        print(f"é«˜åº¦ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

    # 2. ãƒ¡ã‚¿ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 
    try:
        start_time = time.time()

        meta_system = create_meta_learning_system(repository_size=30)
        model, predictions, result_info = meta_system.fit_predict(
            X_train, y_train, price_data,
            task_type=TaskType.REGRESSION,
            X_predict=X_test
        )

        total_time = time.time() - start_time

        # è©•ä¾¡
        r2 = r2_score(y_test, predictions)
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)

        actual_direction = np.sign(y_test.values[1:] - y_test.values[:-1])
        pred_direction = np.sign(predictions[1:] - predictions[:-1])
        directional_accuracy = np.mean(actual_direction == pred_direction)

        results['meta_learning'] = {
            'r2': r2,
            'mse': mse,
            'mae': mae,
            'directional_accuracy': directional_accuracy,
            'training_time': result_info.get('training_time', total_time * 0.8),
            'prediction_time': total_time * 0.2,
            'selected_model': result_info.get('model_type', 'unknown'),
            'market_condition': result_info.get('market_condition', 'unknown')
        }

    except Exception as e:
        print(f"ãƒ¡ã‚¿ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {e}")

    return results


def print_comparison_report(traditional_results: Dict, advanced_results: Dict):
    """æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›"""
    print("\n" + "="*80)
    print("äºˆæ¸¬ç²¾åº¦å‘ä¸Šã‚·ã‚¹ãƒ†ãƒ åŠ¹æœæ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ")
    print("="*80)

    print(f"\nè©•ä¾¡æ—¥æ™‚: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    # å¾“æ¥æ‰‹æ³•çµæœ
    print(f"\nå¾“æ¥æ‰‹æ³•çµæœ:")
    print("-" * 50)
    for name, metrics in traditional_results.items():
        print(f"{name:20s}: R2={metrics['r2']:6.3f}, MSE={metrics['mse']:8.5f}, "
              f"æ–¹å‘ç²¾åº¦={metrics['directional_accuracy']:5.1%}, "
              f"è¨“ç·´æ™‚é–“={metrics['training_time']:5.2f}ç§’")

    # æ–°ã‚·ã‚¹ãƒ†ãƒ çµæœ
    if advanced_results:
        print(f"\næ–°ã‚·ã‚¹ãƒ†ãƒ çµæœ:")
        print("-" * 50)
        for name, metrics in advanced_results.items():
            extra_info = ""
            if 'selected_features' in metrics:
                extra_info += f", ç‰¹å¾´é‡{metrics['selected_features']}å€‹"
            if 'selected_model' in metrics:
                extra_info += f", {metrics['selected_model']}"
            if 'market_regime' in metrics:
                extra_info += f", {metrics['market_regime']}"

            print(f"{name:20s}: R2={metrics['r2']:6.3f}, MSE={metrics['mse']:8.5f}, "
                  f"æ–¹å‘ç²¾åº¦={metrics['directional_accuracy']:5.1%}, "
                  f"è¨“ç·´æ™‚é–“={metrics['training_time']:5.2f}ç§’{extra_info}")

    # æ”¹å–„åˆ†æ
    if advanced_results and traditional_results:
        print(f"\næ”¹å–„åˆ†æ:")
        print("-" * 50)

        # ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆæœ€è‰¯ã®å¾“æ¥æ‰‹æ³•ï¼‰
        best_traditional = max(traditional_results.items(), key=lambda x: x[1]['r2'])
        baseline_r2 = best_traditional[1]['r2']
        baseline_name = best_traditional[0]

        print(f"ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆ{baseline_name}ï¼‰: R2={baseline_r2:.3f}")

        for name, metrics in advanced_results.items():
            improvement = ((metrics['r2'] - baseline_r2) / max(abs(baseline_r2), 1e-6)) * 100
            mse_reduction = ((best_traditional[1]['mse'] - metrics['mse']) /
                           best_traditional[1]['mse']) * 100

            print(f"{name:20s}: R2æ”¹å–„ {improvement:+6.1f}%, MSEå‰Šæ¸› {mse_reduction:+6.1f}%")

    # æ¨å¥¨äº‹é …
    print(f"\næ¨å¥¨äº‹é …:")
    print("-" * 50)

    if advanced_results:
        best_system = max(advanced_results.items(), key=lambda x: x[1]['r2'])
        best_name, best_metrics = best_system

        print(f"1. æœ€å„ªç§€ã‚·ã‚¹ãƒ†ãƒ : {best_name}")
        print(f"   - R2ã‚¹ã‚³ã‚¢: {best_metrics['r2']:.3f}")
        print(f"   - æ–¹å‘æ€§ç²¾åº¦: {best_metrics['directional_accuracy']:.1%}")

        if best_metrics['directional_accuracy'] > 0.55:
            print("   â†’ å–å¼•æˆ¦ç•¥ã§ã®æ´»ç”¨ã‚’æ¨å¥¨")
        else:
            print("   â†’ ã•ã‚‰ãªã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒå¿…è¦")

        print(f"2. è¨ˆç®—åŠ¹ç‡æ€§:")
        print(f"   - è¨“ç·´æ™‚é–“: {best_metrics['training_time']:.2f}ç§’")
        print(f"   - äºˆæ¸¬æ™‚é–“: {best_metrics['prediction_time']:.2f}ç§’")

        if best_metrics['training_time'] < 10:
            print("   â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ã«é©ç”¨å¯èƒ½")
        else:
            print("   â†’ ãƒãƒƒãƒå‡¦ç†ã§ã®åˆ©ç”¨æ¨å¥¨")

        print(f"3. ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ:")
        print(f"   - æ–°æ©Ÿèƒ½ã¯æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨äº’æ›æ€§ãŒã‚ã‚Šã¾ã™")
        print(f"   - æ®µéšçš„å°å…¥ãŒå¯èƒ½ã§ã™")
        print(f"   - è¨­å®šãƒ™ãƒ¼ã‚¹ã§ã®ã‚ªãƒ³/ã‚ªãƒ•åˆ‡æ›¿ãŒå¯èƒ½ã§ã™")

    else:
        print("æ–°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚å°å…¥ã®æ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")

    print("\n" + "="*80)


def run_performance_benchmark():
    """æ€§èƒ½ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("äºˆæ¸¬ç²¾åº¦å‘ä¸Šã‚·ã‚¹ãƒ†ãƒ  ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    print("="*60)

    # ãƒ‡ãƒ¼ã‚¿ä½œæˆ
    print("1. ãƒªã‚¢ãƒ«ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä½œæˆä¸­...")
    X, y, price_data = create_realistic_stock_data(n_samples=800, n_features=30)

    # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, shuffle=False  # æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ãªã®ã§ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ãªã„
    )

    print(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ä»¶, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)}ä»¶")
    print(f"   ç‰¹å¾´é‡æ•°: {X_train.shape[1]}å€‹")
    print(f"   ã‚¿ãƒ¼ã‚²ãƒƒãƒˆçµ±è¨ˆ: å¹³å‡={y_train.mean():.4f}, æ¨™æº–åå·®={y_train.std():.4f}")

    # å¾“æ¥æ‰‹æ³•ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯
    print("\n2. å¾“æ¥æ‰‹æ³•ã§ã®ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œä¸­...")
    traditional_results = run_traditional_models(X_train, y_train, X_test, y_test)

    # æ–°ã‚·ã‚¹ãƒ†ãƒ ã§ã®äºˆæ¸¬
    print("\n3. æ–°ã‚·ã‚¹ãƒ†ãƒ ã§ã®äºˆæ¸¬å®Ÿè¡Œä¸­...")
    advanced_results = run_advanced_systems(X_train, y_train, X_test, y_test, price_data)

    # æ¯”è¼ƒãƒ¬ãƒãƒ¼ãƒˆ
    print_comparison_report(traditional_results, advanced_results)

    return traditional_results, advanced_results


if __name__ == "__main__":
    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger().setLevel(logging.WARNING)

    try:
        traditional, advanced = run_performance_benchmark()

        if advanced:
            print("\nğŸ¯ ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†")
            print("Issue #870ã®äºˆæ¸¬ç²¾åº¦å‘ä¸Šã‚·ã‚¹ãƒ†ãƒ ã®åŠ¹æœãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
        else:
            print("\nâš ï¸ æ–°ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
            print("ç’°å¢ƒã®ç¢ºèªã¨ã‚·ã‚¹ãƒ†ãƒ å°å…¥ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚")

    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()