#!/usr/bin/env python3
"""
93%ç²¾åº¦ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰æ¤œè¨¼
Day Trade ML System EnsembleSystemç²¾åº¦å®Ÿç’°å¢ƒæ¤œè¨¼

æ¤œè¨¼å¯¾è±¡:
- Issue #487: EnsembleSystem 93%ç²¾åº¦é”æˆç¢ºèª
- å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿ã§ã®ç²¾åº¦æ¤œè¨¼
- ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ç²¾åº¦ç›£è¦–
"""

import os
import sys
import time
import json
import logging
import asyncio
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict
import yfinance as yf
import ta
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import seaborn as sns

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ã‚·ã‚¹ãƒ†ãƒ ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@dataclass
class AccuracyTestResult:
    """ç²¾åº¦ãƒ†ã‚¹ãƒˆçµæœ"""
    test_name: str
    symbol: str
    test_period: str
    total_predictions: int
    correct_predictions: int
    accuracy: float
    precision: float
    recall: float
    f1_score: float
    confusion_matrix: List[List[int]]
    timestamp: datetime
    details: Optional[Dict] = None

@dataclass
class MarketDataPoint:
    """å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ"""
    symbol: str
    timestamp: datetime
    open_price: float
    high_price: float
    low_price: float
    close_price: float
    volume: int
    features: Dict[str, float]
    actual_direction: int  # 0: down, 1: up

class AccuracyValidator:
    """93%ç²¾åº¦æ¤œè¨¼ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.test_results: List[AccuracyTestResult] = []
        self.market_data_cache: Dict[str, pd.DataFrame] = {}

        # æ¤œè¨¼è¨­å®š
        self.validation_config = {
            'target_accuracy': 0.93,
            'test_symbols': ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'NVDA', 'AMZN'],
            'test_periods': ['1mo', '3mo', '6mo', '1y'],
            'feature_windows': [5, 10, 20, 50],
            'prediction_horizons': [1, 5, 10],  # days
            'min_test_samples': 100,
            'confidence_threshold': 0.8
        }

        # ç‰¹å¾´é‡è¨­å®š
        self.feature_config = {
            'technical_indicators': [
                'rsi', 'macd', 'bollinger_bands', 'moving_averages',
                'volume_indicators', 'momentum_indicators'
            ],
            'price_features': [
                'price_change', 'price_volatility', 'high_low_ratio',
                'open_close_ratio', 'volume_price_trend'
            ]
        }

    async def run_comprehensive_accuracy_validation(self) -> Dict:
        """åŒ…æ‹¬çš„ç²¾åº¦æ¤œè¨¼å®Ÿè¡Œ"""
        logger.info("Starting comprehensive 93% accuracy validation...")

        validation_start = datetime.utcnow()

        # 1. å¸‚å ´ãƒ‡ãƒ¼ã‚¿åé›†
        await self._collect_market_data()

        # 2. è¤‡æ•°éŠ˜æŸ„ã§ã®ç²¾åº¦æ¤œè¨¼
        multi_symbol_results = await self._validate_multi_symbol_accuracy()

        # 3. æ™‚ç³»åˆ—ç²¾åº¦æ¤œè¨¼
        time_series_results = await self._validate_time_series_accuracy()

        # 4. ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç²¾åº¦æ¤œè¨¼
        realtime_results = await self._validate_realtime_accuracy()

        # 5. ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆå¸‚å ´å¤‰å‹•æœŸï¼‰
        stress_test_results = await self._validate_stress_conditions()

        # 6. ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        feature_analysis = await self._analyze_feature_importance()

        # 7. ç²¾åº¦åŠ£åŒ–æ¤œå‡º
        degradation_analysis = await self._analyze_accuracy_degradation()

        validation_duration = (datetime.utcnow() - validation_start).total_seconds()

        # å…¨ä½“çµæœçµ±åˆ
        all_results = (multi_symbol_results + time_series_results +
                      realtime_results + stress_test_results)

        # çµ±è¨ˆã‚µãƒãƒªãƒ¼
        validation_summary = self._generate_accuracy_summary(all_results)

        validation_report = {
            'validation_start': validation_start.isoformat(),
            'validation_duration_seconds': validation_duration,
            'target_accuracy': self.validation_config['target_accuracy'],
            'total_tests': len(all_results),
            'test_results': [asdict(result) for result in all_results],
            'feature_analysis': feature_analysis,
            'degradation_analysis': degradation_analysis,
            'summary': validation_summary,
            'accuracy_achievement': validation_summary['overall_accuracy'] >= self.validation_config['target_accuracy'],
            'recommendations': self._generate_accuracy_recommendations(validation_summary)
        }

        return validation_report

    async def _collect_market_data(self):
        """å¸‚å ´ãƒ‡ãƒ¼ã‚¿åé›†"""
        logger.info("Collecting market data for validation...")

        for symbol in self.validation_config['test_symbols']:
            try:
                # Yahoo Finance ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—
                ticker = yf.Ticker(symbol)

                # æœ€é•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—
                data = ticker.history(period="2y", interval="1d")

                if len(data) > 0:
                    # ç‰¹å¾´é‡è¨ˆç®—
                    enhanced_data = self._calculate_technical_features(data, symbol)
                    self.market_data_cache[symbol] = enhanced_data

                    logger.info(f"Collected {len(enhanced_data)} data points for {symbol}")
                else:
                    logger.warning(f"No data collected for {symbol}")

            except Exception as e:
                logger.error(f"Failed to collect data for {symbol}: {str(e)}")

    def _calculate_technical_features(self, data: pd.DataFrame, symbol: str) -> pd.DataFrame:
        """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«ç‰¹å¾´é‡è¨ˆç®—"""
        df = data.copy()

        # åŸºæœ¬ä¾¡æ ¼ç‰¹å¾´é‡
        df['price_change'] = df['Close'].pct_change()
        df['high_low_ratio'] = (df['High'] - df['Low']) / df['Close']
        df['open_close_ratio'] = (df['Close'] - df['Open']) / df['Open']
        df['volume_change'] = df['Volume'].pct_change()

        # ç§»å‹•å¹³å‡
        for window in [5, 10, 20, 50]:
            df[f'ma_{window}'] = df['Close'].rolling(window=window).mean()
            df[f'ma_{window}_ratio'] = df['Close'] / df[f'ma_{window}']

        # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰
        df['bb_upper'], df['bb_middle'], df['bb_lower'] = ta.volatility.bollinger_hband(df['Close']), \
                                                          ta.volatility.bollinger_mavg(df['Close']), \
                                                          ta.volatility.bollinger_lband(df['Close'])
        df['bb_position'] = (df['Close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])

        # RSI
        df['rsi'] = ta.momentum.rsi(df['Close'])

        # MACD
        df['macd'] = ta.trend.macd_diff(df['Close'])
        df['macd_signal'] = ta.trend.macd_signal(df['Close'])

        # ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚¤ãƒ³ãƒ‡ã‚£ã‚±ãƒ¼ã‚¿
        df['volume_sma'] = df['Volume'].rolling(window=20).mean()
        df['volume_ratio'] = df['Volume'] / df['volume_sma']

        # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
        for window in [5, 10, 20]:
            df[f'volatility_{window}'] = df['price_change'].rolling(window=window).std()

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•°ï¼ˆç¿Œæ—¥ã®æ–¹å‘ï¼‰
        df['future_return'] = df['Close'].shift(-1) / df['Close'] - 1
        df['target'] = (df['future_return'] > 0).astype(int)

        # æ¬ æå€¤é™¤å»
        df = df.dropna()

        return df

    async def _validate_multi_symbol_accuracy(self) -> List[AccuracyTestResult]:
        """è¤‡æ•°éŠ˜æŸ„ç²¾åº¦æ¤œè¨¼"""
        logger.info("Validating accuracy across multiple symbols...")

        results = []

        for symbol in self.validation_config['test_symbols']:
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            for period in self.validation_config['test_periods']:
                # æœŸé–“ãƒ‡ãƒ¼ã‚¿æŠ½å‡º
                period_data = self._extract_period_data(data, period)

                if len(period_data) < self.validation_config['min_test_samples']:
                    continue

                # äºˆæ¸¬å®Ÿè¡Œ
                predictions, actuals = await self._run_ensemble_predictions(period_data, symbol)

                if len(predictions) > 0:
                    # ç²¾åº¦è¨ˆç®—
                    accuracy = accuracy_score(actuals, predictions)
                    precision = precision_score(actuals, predictions, average='weighted', zero_division=0)
                    recall = recall_score(actuals, predictions, average='weighted', zero_division=0)
                    f1 = f1_score(actuals, predictions, average='weighted', zero_division=0)

                    # æ··åŒè¡Œåˆ—
                    confusion_matrix = self._calculate_confusion_matrix(actuals, predictions)

                    result = AccuracyTestResult(
                        test_name=f"multi_symbol_accuracy",
                        symbol=symbol,
                        test_period=period,
                        total_predictions=len(predictions),
                        correct_predictions=sum(1 for p, a in zip(predictions, actuals) if p == a),
                        accuracy=accuracy,
                        precision=precision,
                        recall=recall,
                        f1_score=f1,
                        confusion_matrix=confusion_matrix,
                        timestamp=datetime.utcnow(),
                        details={'data_points': len(period_data)}
                    )

                    results.append(result)

                    logger.info(f"Symbol: {symbol}, Period: {period}, "
                               f"Accuracy: {accuracy:.4f}, Samples: {len(predictions)}")

        return results

    async def _validate_time_series_accuracy(self) -> List[AccuracyTestResult]:
        """æ™‚ç³»åˆ—ç²¾åº¦æ¤œè¨¼ï¼ˆã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ï¼‰"""
        logger.info("Validating time-series accuracy with walk-forward analysis...")

        results = []

        for symbol in self.validation_config['test_symbols'][:3]:  # ä¸»è¦3éŠ˜æŸ„
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            # ã‚¦ã‚©ãƒ¼ã‚¯ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰æ¤œè¨¼
            train_size = len(data) // 2
            test_size = 50  # 50æ—¥ãšã¤ãƒ†ã‚¹ãƒˆ
            step_size = 10  # 10æ—¥ãšã¤é€²ã‚€

            for start_idx in range(train_size, len(data) - test_size, step_size):
                train_data = data.iloc[:start_idx]
                test_data = data.iloc[start_idx:start_idx + test_size]

                if len(test_data) < 20:  # æœ€å°ãƒ†ã‚¹ãƒˆã‚µã‚¤ã‚º
                    continue

                # äºˆæ¸¬å®Ÿè¡Œ
                predictions, actuals = await self._run_ensemble_predictions(test_data, symbol)

                if len(predictions) > 0:
                    accuracy = accuracy_score(actuals, predictions)

                    result = AccuracyTestResult(
                        test_name="time_series_accuracy",
                        symbol=symbol,
                        test_period=f"walk_forward_{start_idx}",
                        total_predictions=len(predictions),
                        correct_predictions=sum(1 for p, a in zip(predictions, actuals) if p == a),
                        accuracy=accuracy,
                        precision=precision_score(actuals, predictions, average='weighted', zero_division=0),
                        recall=recall_score(actuals, predictions, average='weighted', zero_division=0),
                        f1_score=f1_score(actuals, predictions, average='weighted', zero_division=0),
                        confusion_matrix=self._calculate_confusion_matrix(actuals, predictions),
                        timestamp=datetime.utcnow(),
                        details={
                            'train_size': len(train_data),
                            'test_size': len(test_data),
                            'start_date': test_data.index[0].strftime('%Y-%m-%d'),
                            'end_date': test_data.index[-1].strftime('%Y-%m-%d')
                        }
                    )

                    results.append(result)

        return results

    async def _validate_realtime_accuracy(self) -> List[AccuracyTestResult]:
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç²¾åº¦æ¤œè¨¼"""
        logger.info("Validating real-time prediction accuracy...")

        results = []

        # æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¤œè¨¼
        for symbol in self.validation_config['test_symbols'][:2]:  # ä¸»è¦2éŠ˜æŸ„
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            # æœ€æ–°30æ—¥é–“ã§ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ äºˆæ¸¬ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            recent_data = data.tail(30)

            realtime_predictions = []
            realtime_actuals = []

            for i in range(10, len(recent_data)):
                # iæ—¥æ™‚ç‚¹ã§ã®äºˆæ¸¬ï¼ˆi+1æ—¥ã®æ–¹å‘ï¼‰
                historical_data = recent_data.iloc[:i]
                target_actual = recent_data.iloc[i]['target']

                # äºˆæ¸¬å®Ÿè¡Œï¼ˆå˜ç™ºï¼‰
                prediction = await self._single_prediction(historical_data, symbol)

                if prediction is not None:
                    realtime_predictions.append(prediction)
                    realtime_actuals.append(target_actual)

            if len(realtime_predictions) > 0:
                accuracy = accuracy_score(realtime_actuals, realtime_predictions)

                result = AccuracyTestResult(
                    test_name="realtime_accuracy",
                    symbol=symbol,
                    test_period="realtime_30d",
                    total_predictions=len(realtime_predictions),
                    correct_predictions=sum(1 for p, a in zip(realtime_predictions, realtime_actuals) if p == a),
                    accuracy=accuracy,
                    precision=precision_score(realtime_actuals, realtime_predictions, average='weighted', zero_division=0),
                    recall=recall_score(realtime_actuals, realtime_predictions, average='weighted', zero_division=0),
                    f1_score=f1_score(realtime_actuals, realtime_predictions, average='weighted', zero_division=0),
                    confusion_matrix=self._calculate_confusion_matrix(realtime_actuals, realtime_predictions),
                    timestamp=datetime.utcnow(),
                    details={'prediction_type': 'realtime_simulation'}
                )

                results.append(result)

                logger.info(f"Realtime accuracy for {symbol}: {accuracy:.4f}")

        return results

    async def _validate_stress_conditions(self) -> List[AccuracyTestResult]:
        """ã‚¹ãƒˆãƒ¬ã‚¹æ¡ä»¶ä¸‹ã§ã®ç²¾åº¦æ¤œè¨¼"""
        logger.info("Validating accuracy under stress conditions...")

        results = []

        for symbol in self.validation_config['test_symbols'][:2]:
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            # é«˜ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£æœŸé–“ã®æ¤œå‡º
            data['volatility'] = data['price_change'].rolling(window=20).std()
            high_vol_threshold = data['volatility'].quantile(0.8)

            stress_periods = data[data['volatility'] > high_vol_threshold]

            if len(stress_periods) > self.validation_config['min_test_samples']:
                # ã‚¹ãƒˆãƒ¬ã‚¹æœŸé–“ã§ã®äºˆæ¸¬
                predictions, actuals = await self._run_ensemble_predictions(stress_periods, symbol)

                if len(predictions) > 0:
                    accuracy = accuracy_score(actuals, predictions)

                    result = AccuracyTestResult(
                        test_name="stress_conditions_accuracy",
                        symbol=symbol,
                        test_period="high_volatility",
                        total_predictions=len(predictions),
                        correct_predictions=sum(1 for p, a in zip(predictions, actuals) if p == a),
                        accuracy=accuracy,
                        precision=precision_score(actuals, predictions, average='weighted', zero_division=0),
                        recall=recall_score(actuals, predictions, average='weighted', zero_division=0),
                        f1_score=f1_score(actuals, predictions, average='weighted', zero_division=0),
                        confusion_matrix=self._calculate_confusion_matrix(actuals, predictions),
                        timestamp=datetime.utcnow(),
                        details={
                            'condition_type': 'high_volatility',
                            'volatility_threshold': high_vol_threshold,
                            'avg_volatility': stress_periods['volatility'].mean()
                        }
                    )

                    results.append(result)

                    logger.info(f"Stress test accuracy for {symbol}: {accuracy:.4f}")

        return results

    async def _analyze_feature_importance(self) -> Dict:
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""
        logger.info("Analyzing feature importance...")

        # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æï¼ˆç°¡æ˜“ç‰ˆï¼‰
        feature_importance = {}

        for symbol in self.validation_config['test_symbols'][:3]:
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            # ç‰¹å¾´é‡æŠ½å‡º
            feature_columns = [col for col in data.columns if col not in ['target', 'future_return']]
            features = data[feature_columns].select_dtypes(include=[np.number])

            # ç›¸é–¢åˆ†æ
            correlations = {}
            for col in features.columns:
                if col in data.columns and 'target' in data.columns:
                    correlation = data[col].corr(data['target'])
                    if not np.isnan(correlation):
                        correlations[col] = abs(correlation)

            feature_importance[symbol] = correlations

        # å…¨ä½“çš„ãªç‰¹å¾´é‡é‡è¦åº¦
        overall_importance = {}
        for symbol_features in feature_importance.values():
            for feature, importance in symbol_features.items():
                if feature not in overall_importance:
                    overall_importance[feature] = []
                overall_importance[feature].append(importance)

        # å¹³å‡é‡è¦åº¦è¨ˆç®—
        avg_importance = {
            feature: np.mean(importances)
            for feature, importances in overall_importance.items()
        }

        # ä¸Šä½ç‰¹å¾´é‡
        top_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)[:10]

        return {
            'symbol_specific': feature_importance,
            'overall_importance': avg_importance,
            'top_features': top_features
        }

    async def _analyze_accuracy_degradation(self) -> Dict:
        """ç²¾åº¦åŠ£åŒ–åˆ†æ"""
        logger.info("Analyzing accuracy degradation patterns...")

        degradation_analysis = {}

        # æ™‚ç³»åˆ—ç²¾åº¦æ¨ç§»åˆ†æ
        for symbol in self.validation_config['test_symbols'][:3]:
            if symbol not in self.market_data_cache:
                continue

            data = self.market_data_cache[symbol]

            # æœˆåˆ¥ç²¾åº¦æ¨ç§»
            monthly_accuracy = []
            data['month'] = data.index.to_period('M')

            for month in data['month'].unique():
                month_data = data[data['month'] == month]

                if len(month_data) > 20:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                    predictions, actuals = await self._run_ensemble_predictions(month_data, symbol)

                    if len(predictions) > 0:
                        accuracy = accuracy_score(actuals, predictions)
                        monthly_accuracy.append({
                            'month': str(month),
                            'accuracy': accuracy,
                            'samples': len(predictions)
                        })

            degradation_analysis[symbol] = {
                'monthly_accuracy': monthly_accuracy,
                'accuracy_trend': self._calculate_trend(monthly_accuracy) if monthly_accuracy else None
            }

        return degradation_analysis

    def _extract_period_data(self, data: pd.DataFrame, period: str) -> pd.DataFrame:
        """æœŸé–“ãƒ‡ãƒ¼ã‚¿æŠ½å‡º"""
        if period == '1mo':
            return data.tail(30)
        elif period == '3mo':
            return data.tail(90)
        elif period == '6mo':
            return data.tail(180)
        elif period == '1y':
            return data.tail(365)
        else:
            return data

    async def _run_ensemble_predictions(self, data: pd.DataFrame, symbol: str) -> Tuple[List[int], List[int]]:
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬å®Ÿè¡Œ"""
        # å®Ÿéš›ã®EnsembleSystemã‚’å‘¼ã³å‡ºã™ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        predictions = []
        actuals = []

        feature_columns = [col for col in data.columns if col not in ['target', 'future_return']]

        for i in range(len(data)):
            if i < 20:  # ååˆ†ãªå±¥æ­´ãŒå¿…è¦
                continue

            # äºˆæ¸¬å®Ÿè¡Œï¼ˆç°¡æ˜“ç‰ˆ - å®Ÿéš›ã¯EnsembleSystemã‚’ä½¿ç”¨ï¼‰
            features = data.iloc[i][feature_columns].values

            # ã‚·ãƒ³ãƒ—ãƒ«ãªäºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿéš›ã®MLãƒ¢ãƒ‡ãƒ«ã«ç½®ãæ›ãˆï¼‰
            prediction = await self._simple_ensemble_prediction(features)
            actual = int(data.iloc[i]['target'])

            predictions.append(prediction)
            actuals.append(actual)

        return predictions, actuals

    async def _single_prediction(self, historical_data: pd.DataFrame, symbol: str) -> Optional[int]:
        """å˜ç™ºäºˆæ¸¬"""
        if len(historical_data) < 20:
            return None

        feature_columns = [col for col in historical_data.columns if col not in ['target', 'future_return']]
        latest_features = historical_data.iloc[-1][feature_columns].values

        return await self._simple_ensemble_prediction(latest_features)

    async def _simple_ensemble_prediction(self, features: np.ndarray) -> int:
        """ç°¡æ˜“ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬"""
        # å®Ÿéš›ã®EnsembleSystemã«ç½®ãæ›ãˆã‚‹
        # ã“ã“ã§ã¯ç°¡æ˜“çš„ãªäºˆæ¸¬ãƒ­ã‚¸ãƒƒã‚¯

        # ç‰¹å¾´é‡ã®åŠ é‡å¹³å‡ã§åˆ¤å®š
        if len(features) == 0:
            return np.random.choice([0, 1])

        # æ­£è¦åŒ–
        normalized_features = (features - np.mean(features)) / (np.std(features) + 1e-8)

        # ç°¡æ˜“äºˆæ¸¬ã‚¹ã‚³ã‚¢
        score = np.mean(normalized_features)

        # é–¾å€¤ã§äºŒå€¤åˆ†é¡
        return 1 if score > 0 else 0

    def _calculate_confusion_matrix(self, actuals: List[int], predictions: List[int]) -> List[List[int]]:
        """æ··åŒè¡Œåˆ—è¨ˆç®—"""
        from sklearn.metrics import confusion_matrix

        cm = confusion_matrix(actuals, predictions, labels=[0, 1])
        return cm.tolist()

    def _calculate_trend(self, monthly_data: List[Dict]) -> Optional[float]:
        """ç²¾åº¦ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—"""
        if len(monthly_data) < 3:
            return None

        accuracies = [data['accuracy'] for data in monthly_data]
        x = np.arange(len(accuracies))

        # ç·šå½¢å›å¸°ã®å‚¾ã
        slope = np.polyfit(x, accuracies, 1)[0]
        return float(slope)

    def _generate_accuracy_summary(self, results: List[AccuracyTestResult]) -> Dict:
        """ç²¾åº¦ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"""
        if not results:
            return {'overall_accuracy': 0.0}

        accuracies = [result.accuracy for result in results]
        precisions = [result.precision for result in results]
        recalls = [result.recall for result in results]
        f1_scores = [result.f1_score for result in results]

        # éŠ˜æŸ„åˆ¥çµ±è¨ˆ
        symbol_stats = {}
        for result in results:
            symbol = result.symbol
            if symbol not in symbol_stats:
                symbol_stats[symbol] = []
            symbol_stats[symbol].append(result.accuracy)

        symbol_averages = {
            symbol: np.mean(accuracies)
            for symbol, accuracies in symbol_stats.items()
        }

        # ãƒ†ã‚¹ãƒˆã‚¿ã‚¤ãƒ—åˆ¥çµ±è¨ˆ
        test_type_stats = {}
        for result in results:
            test_type = result.test_name
            if test_type not in test_type_stats:
                test_type_stats[test_type] = []
            test_type_stats[test_type].append(result.accuracy)

        test_type_averages = {
            test_type: np.mean(accuracies)
            for test_type, accuracies in test_type_stats.items()
        }

        return {
            'overall_accuracy': np.mean(accuracies),
            'accuracy_std': np.std(accuracies),
            'min_accuracy': min(accuracies),
            'max_accuracy': max(accuracies),
            'avg_precision': np.mean(precisions),
            'avg_recall': np.mean(recalls),
            'avg_f1_score': np.mean(f1_scores),
            'target_achievement': np.mean(accuracies) >= self.validation_config['target_accuracy'],
            'passing_tests': sum(1 for acc in accuracies if acc >= self.validation_config['target_accuracy']),
            'total_tests': len(results),
            'symbol_performance': symbol_averages,
            'test_type_performance': test_type_averages
        }

    def _generate_accuracy_recommendations(self, summary: Dict) -> List[str]:
        """ç²¾åº¦æ”¹å–„ææ¡ˆ"""
        recommendations = []

        overall_accuracy = summary.get('overall_accuracy', 0.0)
        target_accuracy = self.validation_config['target_accuracy']

        if overall_accuracy < target_accuracy:
            gap = target_accuracy - overall_accuracy
            recommendations.append(f"ç²¾åº¦ç›®æ¨™æœªé”æˆ: {overall_accuracy:.4f} < {target_accuracy:.4f} (å·®åˆ†: {gap:.4f})")

            if gap > 0.05:
                recommendations.append("å¤§å¹…ãªç²¾åº¦æ”¹å–„ãŒå¿…è¦: ãƒ¢ãƒ‡ãƒ«å†è¨­è¨ˆã‚’æ¨å¥¨")
            elif gap > 0.02:
                recommendations.append("ä¸­ç¨‹åº¦ã®ç²¾åº¦æ”¹å–„ãŒå¿…è¦: ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãƒ»ç‰¹å¾´é‡è¿½åŠ ã‚’æ¨å¥¨")
            else:
                recommendations.append("è»½å¾®ãªç²¾åº¦æ”¹å–„ãŒå¿…è¦: ãƒ‡ãƒ¼ã‚¿å“è³ªå‘ä¸Šãƒ»å‰å‡¦ç†æ”¹å–„ã‚’æ¨å¥¨")
        else:
            recommendations.append(f"ç²¾åº¦ç›®æ¨™é”æˆ: {overall_accuracy:.4f} >= {target_accuracy:.4f}")

        # éŠ˜æŸ„åˆ¥æ¨å¥¨
        symbol_performance = summary.get('symbol_performance', {})
        poor_performers = [symbol for symbol, acc in symbol_performance.items() if acc < target_accuracy]

        if poor_performers:
            recommendations.append(f"ç²¾åº¦æ”¹å–„ãŒå¿…è¦ãªéŠ˜æŸ„: {', '.join(poor_performers)}")

        # åˆ†æ•£ç¢ºèª
        accuracy_std = summary.get('accuracy_std', 0)
        if accuracy_std > 0.1:
            recommendations.append("ç²¾åº¦ã®ã°ã‚‰ã¤ããŒå¤§ãã„ãŸã‚ã€ãƒ¢ãƒ‡ãƒ«ã®å®‰å®šæ€§æ”¹å–„ã‚’æ¨å¥¨")

        return recommendations

    def save_accuracy_report(self, validation_report: Dict, filename: str = None):
        """ç²¾åº¦æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜"""
        if filename is None:
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            filename = f'accuracy_validation_{timestamp}.json'

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(validation_report, f, ensure_ascii=False, indent=2, default=str)

        logger.info(f"Accuracy validation report saved to: {filename}")

    def generate_accuracy_charts(self, validation_report: Dict, output_dir: str = "accuracy_charts"):
        """ç²¾åº¦ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
        os.makedirs(output_dir, exist_ok=True)

        # 1. éŠ˜æŸ„åˆ¥ç²¾åº¦ãƒãƒ£ãƒ¼ãƒˆ
        self._create_symbol_accuracy_chart(validation_report, output_dir)

        # 2. æ™‚ç³»åˆ—ç²¾åº¦æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆ
        self._create_time_series_accuracy_chart(validation_report, output_dir)

        # 3. æ··åŒè¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
        self._create_confusion_matrix_heatmap(validation_report, output_dir)

    def _create_symbol_accuracy_chart(self, report: Dict, output_dir: str):
        """éŠ˜æŸ„åˆ¥ç²¾åº¦ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        # å®Ÿè£…çœç•¥ï¼ˆmatplotlibä½¿ç”¨ï¼‰
        pass

    def _create_time_series_accuracy_chart(self, report: Dict, output_dir: str):
        """æ™‚ç³»åˆ—ç²¾åº¦æ¨ç§»ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
        # å®Ÿè£…çœç•¥
        pass

    def _create_confusion_matrix_heatmap(self, report: Dict, output_dir: str):
        """æ··åŒè¡Œåˆ—ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä½œæˆ"""
        # å®Ÿè£…çœç•¥
        pass

async def main():
    """93%ç²¾åº¦æ¤œè¨¼å®Ÿè¡Œ"""
    validator = AccuracyValidator()

    print("ğŸ¯ Day Trade ML System - 93%ç²¾åº¦ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰æ¤œè¨¼é–‹å§‹")
    print("=" * 60)

    # ç²¾åº¦æ¤œè¨¼å®Ÿè¡Œ
    report = await validator.run_comprehensive_accuracy_validation()

    # çµæœå‡ºåŠ›
    print(f"\nğŸ“Š 93%ç²¾åº¦æ¤œè¨¼çµæœ")
    print(f"ç›®æ¨™ç²¾åº¦: {report['target_accuracy']:.1%}")
    print(f"é”æˆç²¾åº¦: {report['summary']['overall_accuracy']:.4f} ({report['summary']['overall_accuracy']:.1%})")
    print(f"ç›®æ¨™é”æˆ: {'âœ…' if report['accuracy_achievement'] else 'âŒ'}")
    print(f"ç·ãƒ†ã‚¹ãƒˆæ•°: {report['total_tests']}")
    print(f"åˆæ ¼ãƒ†ã‚¹ãƒˆæ•°: {report['summary']['passing_tests']}")

    print(f"\nğŸ“ˆ è©³ç´°çµ±è¨ˆ:")
    print(f"ç²¾åº¦ç¯„å›²: {report['summary']['min_accuracy']:.4f} - {report['summary']['max_accuracy']:.4f}")
    print(f"ç²¾åº¦æ¨™æº–åå·®: {report['summary']['accuracy_std']:.4f}")
    print(f"å¹³å‡é©åˆç‡: {report['summary']['avg_precision']:.4f}")
    print(f"å¹³å‡å†ç¾ç‡: {report['summary']['avg_recall']:.4f}")
    print(f"å¹³å‡F1ã‚¹ã‚³ã‚¢: {report['summary']['avg_f1_score']:.4f}")

    print(f"\nğŸ“‹ éŠ˜æŸ„åˆ¥æ€§èƒ½:")
    for symbol, accuracy in report['summary']['symbol_performance'].items():
        status = "âœ…" if accuracy >= report['target_accuracy'] else "âŒ"
        print(f"{status} {symbol}: {accuracy:.4f}")

    print(f"\nğŸ’¡ æ”¹å–„ææ¡ˆ:")
    for rec in report['recommendations']:
        print(f"â€¢ {rec}")

    # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    validator.save_accuracy_report(report)

    print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸ")

if __name__ == '__main__':
    asyncio.run(main())