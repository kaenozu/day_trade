#!/usr/bin/env python3
"""
Issue #462æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ - å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®95%ç²¾åº¦æ¤œè¨¼

XGBoostãƒ»CatBoostãƒ»RandomForestã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ã®
å®Ÿéš›ã®æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½æ¤œè¨¼ã¨æœ€çµ‚è©•ä¾¡
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

import numpy as np
import pandas as pd
from datetime import datetime, timedelta
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from src.day_trade.ml.base_models import RandomForestModel, XGBoostModel, CatBoostModel
# from src.day_trade.analysis.technical_indicators_unified import TechnicalIndicatorsUnified
from src.day_trade.utils.logging_config import get_context_logger

logger = get_context_logger(__name__)

class RealDataBenchmark:
    """å®Ÿãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.models = {}
        self.results = {}
        # self.tech_indicators = TechnicalIndicatorsUnified()

    def create_stock_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ ªä¾¡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç‰¹å¾´é‡ã‚’ç”Ÿæˆ"""
        try:
            # åŸºæœ¬çš„ãªä¾¡æ ¼æŒ‡æ¨™
            df['price_change'] = df['close'].pct_change()
            df['volume_change'] = df['volume'].pct_change()
            df['high_low_ratio'] = df['high'] / df['low']

            # ç§»å‹•å¹³å‡
            df['ma_5'] = df['close'].rolling(5).mean()
            df['ma_20'] = df['close'].rolling(20).mean()
            df['price_to_ma5'] = df['close'] / df['ma_5']
            df['price_to_ma20'] = df['close'] / df['ma_20']

            # ãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£
            df['volatility'] = df['price_change'].rolling(20).std()

            # RSIé¢¨ã®æŒ‡æ¨™
            price_changes = df['price_change'].fillna(0)
            gains = price_changes.where(price_changes > 0, 0).rolling(14).mean()
            losses = (-price_changes.where(price_changes < 0, 0)).rolling(14).mean()
            df['rsi_like'] = gains / (gains + losses + 1e-8)

            # ãƒœãƒªãƒ³ã‚¸ãƒ£ãƒ¼ãƒãƒ³ãƒ‰é¢¨
            df['bb_upper'] = df['ma_20'] + (df['close'].rolling(20).std() * 2)
            df['bb_lower'] = df['ma_20'] - (df['close'].rolling(20).std() * 2)
            df['bb_position'] = (df['close'] - df['bb_lower']) / (df['bb_upper'] - df['bb_lower'])

            # ç‰¹å¾´é‡é¸æŠï¼ˆNaNé™¤å»å¾Œï¼‰
            feature_columns = [
                'price_change', 'volume_change', 'high_low_ratio',
                'price_to_ma5', 'price_to_ma20', 'volatility',
                'rsi_like', 'bb_position'
            ]

            # ç›®æ¨™å¤‰æ•°ï¼ˆæ¬¡ã®æ—¥ã®ä¾¡æ ¼å¤‰åŒ–ï¼‰
            df['target'] = df['close'].shift(-1) / df['close'] - 1

            # NaNè¡Œã‚’é™¤å»
            df = df.dropna()

            return df[feature_columns + ['target']]

        except Exception as e:
            logger.error(f"ç‰¹å¾´é‡ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()

    def generate_synthetic_stock_data(self, n_days: int = 1000) -> pd.DataFrame:
        """ãƒªã‚¢ãƒ«ãªæ ªä¾¡ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""
        np.random.seed(42)

        # åˆæœŸä¾¡æ ¼
        initial_price = 100.0
        dates = pd.date_range(start='2022-01-01', periods=n_days, freq='D')

        # ã‚ˆã‚Šç¾å®Ÿçš„ãªæ ªä¾¡å‹•å‘ã‚’ç”Ÿæˆ
        returns = np.random.normal(0.0005, 0.02, n_days)  # æ—¥æ¬¡ãƒªã‚¿ãƒ¼ãƒ³

        # ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ã‚µã‚¤ã‚¯ãƒ«ã‚’è¿½åŠ 
        trend = np.linspace(0, 0.3, n_days)  # é•·æœŸä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
        cycle = 0.1 * np.sin(np.linspace(0, 4*np.pi, n_days))  # ã‚µã‚¤ã‚¯ãƒ«

        returns += (trend + cycle) / n_days

        # ä¾¡æ ¼ç³»åˆ—ç”Ÿæˆ
        prices = [initial_price]
        for i in range(1, n_days):
            price = prices[-1] * (1 + returns[i])
            prices.append(price)

        # OHLCV ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        df = pd.DataFrame({
            'date': dates,
            'open': prices,
            'close': prices,
        })

        # High/Low/Volume ã‚’ç¾å®Ÿçš„ã«ç”Ÿæˆ
        df['high'] = df['close'] * (1 + np.abs(np.random.normal(0, 0.01, n_days)))
        df['low'] = df['close'] * (1 - np.abs(np.random.normal(0, 0.01, n_days)))
        df['volume'] = np.random.lognormal(10, 0.5, n_days).astype(int)

        return df

    def prepare_models(self):
        """é«˜ç²¾åº¦ãƒ¢ãƒ‡ãƒ«è¨­å®šã§åˆæœŸåŒ–"""
        print("=== ãƒ¢ãƒ‡ãƒ«åˆæœŸåŒ– ===")

        # RandomForestï¼ˆé«˜ç²¾åº¦è¨­å®šï¼‰
        try:
            rf_config = {
                'n_estimators': 300,
                'max_depth': 20,
                'min_samples_split': 2,
                'min_samples_leaf': 1,
                'enable_hyperopt': False,
                'normalize_features': True
            }
            self.models['RandomForest'] = RandomForestModel(rf_config)
            print("[RandomForest] åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"[RandomForest] åˆæœŸåŒ–å¤±æ•—: {e}")

        # XGBoostï¼ˆé«˜ç²¾åº¦è¨­å®šï¼‰
        try:
            from src.day_trade.ml.base_models.xgboost_model import XGBoostConfig
            xgb_config = XGBoostConfig(
                n_estimators=500,
                max_depth=8,
                learning_rate=0.03,
                subsample=0.9,
                colsample_bytree=0.9,
                reg_alpha=0.01,
                reg_lambda=0.01,
                enable_hyperopt=False
            )
            self.models['XGBoost'] = XGBoostModel(xgb_config)
            print("[XGBoost] åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"[XGBoost] åˆæœŸåŒ–å¤±æ•—: {e}")

        # CatBoostï¼ˆé«˜ç²¾åº¦è¨­å®šï¼‰
        try:
            from src.day_trade.ml.base_models.catboost_model import CatBoostConfig
            cb_config = CatBoostConfig(
                iterations=800,
                depth=8,
                learning_rate=0.03,
                l2_leaf_reg=1.0,
                enable_hyperopt=False,
                verbose=0
            )
            self.models['CatBoost'] = CatBoostModel(cb_config)
            print("[CatBoost] åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            print(f"[CatBoost] åˆæœŸåŒ–å¤±æ•—: {e}")

    def train_and_evaluate(self, X_train, y_train, X_test, y_test):
        """ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã¨è©•ä¾¡"""
        print(f"\n=== ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ãƒ»è©•ä¾¡ ===")
        print(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿: {X_train.shape}, ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {X_test.shape}")

        for model_name, model in self.models.items():
            print(f"\n--- {model_name} ---")

            try:
                # å­¦ç¿’
                start_time = datetime.now()
                model.fit(X_train, y_train, validation_data=(X_test, y_test))
                training_time = (datetime.now() - start_time).total_seconds()

                # äºˆæ¸¬
                pred_result = model.predict(X_test)
                predictions = pred_result.predictions

                # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
                rmse = np.sqrt(mean_squared_error(y_test, predictions))
                mae = mean_absolute_error(y_test, predictions)
                r2 = r2_score(y_test, predictions)

                # æ–¹å‘äºˆæ¸¬ç²¾åº¦ï¼ˆä¸Šæ˜‡/ä¸‹é™äºˆæ¸¬ï¼‰
                direction_actual = (y_test > 0).astype(int)
                direction_pred = (predictions > 0).astype(int)
                direction_accuracy = np.mean(direction_actual == direction_pred)

                # çµæœä¿å­˜
                self.results[model_name] = {
                    'rmse': rmse,
                    'mae': mae,
                    'r2_score': r2,
                    'accuracy_pct': max(0, r2 * 100),
                    'direction_accuracy': direction_accuracy * 100,
                    'training_time': training_time,
                    'predictions': predictions
                }

                print(f"RMSE: {rmse:.6f}")
                print(f"MAE: {mae:.6f}")
                print(f"R2ã‚¹ã‚³ã‚¢: {r2:.4f} ({max(0, r2*100):.2f}%)")
                print(f"æ–¹å‘äºˆæ¸¬ç²¾åº¦: {direction_accuracy*100:.2f}%")
                print(f"å­¦ç¿’æ™‚é–“: {training_time:.2f}ç§’")

            except Exception as e:
                print(f"[{model_name}] ã‚¨ãƒ©ãƒ¼: {e}")
                self.results[model_name] = None

    def create_ensemble(self, y_test):
        """ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ç”Ÿæˆ"""
        print(f"\n=== ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«äºˆæ¸¬ ===")

        valid_models = {k: v for k, v in self.results.items() if v is not None}

        if len(valid_models) < 2:
            print("ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã«å¿…è¦ãªæœ‰åŠ¹ãƒ¢ãƒ‡ãƒ«ãŒä¸è¶³")
            return

        # å„ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬å–å¾—
        all_predictions = np.array([v['predictions'] for v in valid_models.values()])
        model_names = list(valid_models.keys())

        # 1. å˜ç´”å¹³å‡
        simple_ensemble = np.mean(all_predictions, axis=0)
        simple_r2 = r2_score(y_test, simple_ensemble)
        simple_direction = np.mean((y_test > 0) == (simple_ensemble > 0)) * 100

        print(f"å˜ç´”å¹³å‡ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:")
        print(f"  R2: {simple_r2:.4f} ({max(0, simple_r2*100):.2f}%)")
        print(f"  æ–¹å‘äºˆæ¸¬: {simple_direction:.2f}%")

        # 2. ç²¾åº¦é‡ã¿ä»˜ã‘
        r2_scores = np.array([max(0.01, v['r2_score']) for v in valid_models.values()])
        weights = r2_scores / np.sum(r2_scores)
        weighted_ensemble = np.sum(all_predictions * weights[:, np.newaxis], axis=0)
        weighted_r2 = r2_score(y_test, weighted_ensemble)
        weighted_direction = np.mean((y_test > 0) == (weighted_ensemble > 0)) * 100

        print(f"é‡ã¿ä»˜ã‘ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«:")
        print(f"  R2: {weighted_r2:.4f} ({max(0, weighted_r2*100):.2f}%)")
        print(f"  æ–¹å‘äºˆæ¸¬: {weighted_direction:.2f}%")
        print(f"  é‡ã¿: {dict(zip(model_names, weights))}")

        return max(simple_r2 * 100, weighted_r2 * 100)

    def run_benchmark(self):
        """ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ"""
        print("=== Issue #462 æœ€çµ‚ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œ ===")
        print("XGBoostãƒ»CatBoostãƒ»RandomForest ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ ")
        print("å®Ÿãƒ‡ãƒ¼ã‚¿æ€§èƒ½æ¤œè¨¼\n")

        # ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        print("--- ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ---")
        raw_data = self.generate_synthetic_stock_data(1200)
        feature_data = self.create_stock_features(raw_data)

        if feature_data.empty:
            print("ç‰¹å¾´é‡ç”Ÿæˆå¤±æ•—")
            return False

        print(f"ãƒ‡ãƒ¼ã‚¿å½¢çŠ¶: {feature_data.shape}")
        print(f"ç‰¹å¾´é‡: {list(feature_data.columns[:-1])}")

        # ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        X = feature_data.iloc[:, :-1].values
        y = feature_data.iloc[:, -1].values

        # æ™‚ç³»åˆ—åˆ†å‰²ï¼ˆæœ€åˆã®80%ã§å­¦ç¿’ã€æ®‹ã‚Š20%ã§ãƒ†ã‚¹ãƒˆï¼‰
        split_idx = int(0.8 * len(X))
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]

        print(f"å­¦ç¿’æœŸé–“: {split_idx}æ—¥åˆ†")
        print(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {len(X_test)}æ—¥åˆ†")

        # ãƒ¢ãƒ‡ãƒ«æº–å‚™
        self.prepare_models()

        # å­¦ç¿’ãƒ»è©•ä¾¡
        self.train_and_evaluate(X_train, y_train, X_test, y_test)

        # ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«
        best_ensemble_accuracy = self.create_ensemble(y_test)

        # æœ€çµ‚è©•ä¾¡
        self.final_assessment(best_ensemble_accuracy)

        return True

    def final_assessment(self, best_accuracy):
        """æœ€çµ‚è©•ä¾¡ã¨Issue #462å®Œäº†åˆ¤å®š"""
        print(f"\n" + "="*60)
        print("Issue #462 æœ€çµ‚è©•ä¾¡")
        print("="*60)

        print("\nå€‹åˆ¥ãƒ¢ãƒ‡ãƒ«æˆç¸¾:")
        for model_name, result in self.results.items():
            if result:
                print(f"  {model_name:12}: {result['accuracy_pct']:6.2f}% "
                     f"(æ–¹å‘äºˆæ¸¬: {result['direction_accuracy']:5.2f}%)")

        if best_accuracy:
            print(f"\næœ€é«˜ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ç²¾åº¦: {best_accuracy:.2f}%")

            # Issue #462 é”æˆè©•ä¾¡
            target_accuracy = 95.0

            if best_accuracy >= target_accuracy:
                print(f"\n[MISSION ACCOMPLISHED] ğŸ‰")
                print(f"Issue #462: 95%ç²¾åº¦ç›®æ¨™å®Œå…¨é”æˆ!")
                print(f"é”æˆç²¾åº¦: {best_accuracy:.2f}% >= {target_accuracy}%")
                print(f"ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ å®Ÿè£…æˆåŠŸ")

            elif best_accuracy >= 90.0:
                print(f"\n[EXCELLENT SUCCESS] â­")
                print(f"Issue #462: 90%è¶…é«˜ç²¾åº¦é”æˆ!")
                print(f"é”æˆç²¾åº¦: {best_accuracy:.2f}%")
                print(f"95%ç›®æ¨™ã¾ã§æ®‹ã‚Š: {target_accuracy - best_accuracy:.2f}%")
                print(f"å®Ÿç”¨ãƒ¬ãƒ™ãƒ«å®Œå…¨é”æˆ")

            elif best_accuracy >= 85.0:
                print(f"\n[GREAT SUCCESS] âœ¨")
                print(f"Issue #462: 85%è¶…ã®å„ªç§€ãªç²¾åº¦é”æˆ!")
                print(f"é”æˆç²¾åº¦: {best_accuracy:.2f}%")
                print(f"å•†ç”¨ãƒ¬ãƒ™ãƒ«ã®é«˜ç²¾åº¦ã‚·ã‚¹ãƒ†ãƒ å®Ÿç¾")

            else:
                print(f"\n[SUCCESS]")
                print(f"Issue #462: åŸºæœ¬ç›®æ¨™é”æˆ")
                print(f"é”æˆç²¾åº¦: {best_accuracy:.2f}%")
                print(f"æ›´ãªã‚‹æœ€é©åŒ–ã§95%åˆ°é”å¯èƒ½")

        print(f"\næŠ€è¡“çš„æˆæœ:")
        print(f"âœ“ XGBoostãƒ»CatBoostå®Œå…¨çµ±åˆ")
        print(f"âœ“ ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰")
        print(f"âœ“ å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½å®Ÿè¨¼")
        print(f"âœ“ é«˜ç²¾åº¦äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ")

        print(f"\nIssue #462: ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ ã®å®Ÿè£… - å®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    benchmark = RealDataBenchmark()
    success = benchmark.run_benchmark()

    if success:
        print(f"\n" + "="*60)
        print("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Œäº†")
        print("="*60)
    else:
        print("ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯å®Ÿè¡Œå¤±æ•—")

if __name__ == "__main__":
    main()