#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Realtime Monitoring & Auto Tuning System - ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ»è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 

Issue #805å®Ÿè£…ï¼šå®Ÿæ™‚é–“ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–ãƒ»è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ 
ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½ã®å®Ÿæ™‚é–“ç›£è¦–ã¨è‡ªå‹•èª¿æ•´ã«ã‚ˆã‚‹æœ€é©åŒ–
"""

import asyncio
import pandas as pd
import numpy as np
import logging
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Union, Callable
from dataclasses import dataclass, field
from enum import Enum
import json
import sqlite3
from pathlib import Path
import time
import threading
from concurrent.futures import ThreadPoolExecutor
from collections import deque
import psutil
import gc
import os

# Windowsç’°å¢ƒã§ã®æ–‡å­—åŒ–ã‘å¯¾ç­–
import sys
os.environ['PYTHONIOENCODING'] = 'utf-8'

if sys.platform == 'win32':
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except:
        import codecs
        sys.stdout = codecs.getwriter('utf-8')(sys.stdout.buffer)
        sys.stderr = codecs.getwriter('utf-8')(sys.stderr.buffer)

class PerformanceLevel(Enum):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«"""
    EXCELLENT = "excellent"  # 90-100%
    GOOD = "good"           # 70-89%
    FAIR = "fair"           # 50-69%
    POOR = "poor"           # 30-49%
    CRITICAL = "critical"   # 0-29%

class OptimizationAction(Enum):
    """æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³"""
    INCREASE_CACHE_SIZE = "increase_cache_size"
    DECREASE_CACHE_SIZE = "decrease_cache_size"
    INCREASE_WORKERS = "increase_workers"
    DECREASE_WORKERS = "decrease_workers"
    CLEAR_MEMORY = "clear_memory"
    OPTIMIZE_QUERIES = "optimize_queries"
    REDUCE_POLLING = "reduce_polling"
    INCREASE_POLLING = "increase_polling"
    RESTART_COMPONENTS = "restart_components"

@dataclass
class SystemHealth:
    """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹çŠ¶æ…‹"""
    timestamp: datetime
    cpu_usage: float
    memory_usage: float
    memory_available: float
    disk_usage: float
    network_latency: float
    cache_hit_rate: float
    response_time_avg: float
    error_rate: float
    active_connections: int
    performance_level: PerformanceLevel

@dataclass
class OptimizationRule:
    """æœ€é©åŒ–ãƒ«ãƒ¼ãƒ«"""
    rule_id: str
    name: str
    condition: str  # Pythonå¼
    action: OptimizationAction
    priority: int  # 1-10 (é«˜ã„ã»ã©å„ªå…ˆ)
    cooldown_seconds: int
    last_executed: Optional[datetime] = None
    execution_count: int = 0
    success_count: int = 0

@dataclass
class TuningHistory:
    """èª¿æ•´å±¥æ­´"""
    timestamp: datetime
    action: OptimizationAction
    parameter: str
    old_value: Any
    new_value: Any
    reason: str
    impact_score: float = 0.0
    success: bool = True

class PerformanceProfiler:
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ©ãƒ¼"""

    def __init__(self):
        self.logger = logging.getLogger(__name__)
        self.metrics_history = deque(maxlen=1440)  # 24æ™‚é–“åˆ†
        self.response_times = deque(maxlen=1000)
        self.error_counts = deque(maxlen=100)

    def profile_function(self, func: Callable, *args, **kwargs) -> Tuple[Any, Dict[str, Any]]:
        """é–¢æ•°ã®æ€§èƒ½ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°"""

        start_time = time.perf_counter()
        memory_before = self._get_memory_usage()
        cpu_before = psutil.cpu_percent()

        try:
            result = func(*args, **kwargs)
            success = True
            error = None
        except Exception as e:
            result = None
            success = False
            error = str(e)

        end_time = time.perf_counter()
        memory_after = self._get_memory_usage()
        cpu_after = psutil.cpu_percent()

        profile = {
            'execution_time': end_time - start_time,
            'memory_delta': memory_after - memory_before,
            'cpu_usage': (cpu_before + cpu_after) / 2,
            'success': success,
            'error': error,
            'function_name': func.__name__ if hasattr(func, '__name__') else 'unknown'
        }

        return result, profile

    def _get_memory_usage(self) -> float:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—ï¼ˆMBï¼‰"""
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024

class AutoTuner:
    """è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # èª¿æ•´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.tunable_params = {
            'cache_size': {'min': 100, 'max': 5000, 'current': 1000},
            'worker_count': {'min': 1, 'max': 8, 'current': 4},
            'polling_interval': {'min': 30, 'max': 300, 'current': 60},
            'batch_size': {'min': 10, 'max': 1000, 'current': 100},
            'timeout': {'min': 5, 'max': 60, 'current': 30}
        }

        # æœ€é©åŒ–ãƒ«ãƒ¼ãƒ«
        self.optimization_rules = []
        self._setup_default_rules()

        # èª¿æ•´å±¥æ­´
        self.tuning_history = deque(maxlen=500)

    def _setup_default_rules(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆæœ€é©åŒ–ãƒ«ãƒ¼ãƒ«è¨­å®š"""

        # CPUä½¿ç”¨ç‡ãŒé«˜ã„å ´åˆ
        self.optimization_rules.append(OptimizationRule(
            rule_id="high_cpu",
            name="é«˜CPUä½¿ç”¨ç‡å¯¾å¿œ",
            condition="cpu_usage > 85",
            action=OptimizationAction.DECREASE_WORKERS,
            priority=8,
            cooldown_seconds=300
        ))

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ãŒé«˜ã„å ´åˆ
        self.optimization_rules.append(OptimizationRule(
            rule_id="high_memory",
            name="é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡å¯¾å¿œ",
            condition="memory_usage > 80",
            action=OptimizationAction.CLEAR_MEMORY,
            priority=9,
            cooldown_seconds=120
        ))

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ãŒä½ã„å ´åˆ
        self.optimization_rules.append(OptimizationRule(
            rule_id="low_cache_hit",
            name="ä½ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡å¯¾å¿œ",
            condition="cache_hit_rate < 0.6",
            action=OptimizationAction.INCREASE_CACHE_SIZE,
            priority=6,
            cooldown_seconds=600
        ))

        # å¿œç­”æ™‚é–“ãŒé…ã„å ´åˆ
        self.optimization_rules.append(OptimizationRule(
            rule_id="slow_response",
            name="é…ã„å¿œç­”æ™‚é–“å¯¾å¿œ",
            condition="response_time_avg > 5.0",
            action=OptimizationAction.OPTIMIZE_QUERIES,
            priority=7,
            cooldown_seconds=300
        ))

        # ã‚¨ãƒ©ãƒ¼ç‡ãŒé«˜ã„å ´åˆ
        self.optimization_rules.append(OptimizationRule(
            rule_id="high_error_rate",
            name="é«˜ã‚¨ãƒ©ãƒ¼ç‡å¯¾å¿œ",
            condition="error_rate > 0.05",
            action=OptimizationAction.RESTART_COMPONENTS,
            priority=10,
            cooldown_seconds=900
        ))

    def evaluate_and_apply_optimizations(self, health: SystemHealth) -> List[TuningHistory]:
        """æœ€é©åŒ–ã®è©•ä¾¡ã¨é©ç”¨"""

        applied_actions = []

        # æ¡ä»¶è©•ä¾¡ç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        context = {
            'cpu_usage': health.cpu_usage,
            'memory_usage': health.memory_usage,
            'cache_hit_rate': health.cache_hit_rate,
            'response_time_avg': health.response_time_avg,
            'error_rate': health.error_rate
        }

        # å„ªå…ˆåº¦ã§ã‚½ãƒ¼ãƒˆ
        sorted_rules = sorted(self.optimization_rules, key=lambda r: r.priority, reverse=True)

        for rule in sorted_rules:
            # ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ãƒã‚§ãƒƒã‚¯
            if rule.last_executed:
                time_since_last = (datetime.now() - rule.last_executed).total_seconds()
                if time_since_last < rule.cooldown_seconds:
                    continue

            # æ¡ä»¶è©•ä¾¡
            try:
                if eval(rule.condition, {"__builtins__": {}}, context):
                    action_result = self._apply_optimization_action(rule.action, context)

                    if action_result:
                        history = TuningHistory(
                            timestamp=datetime.now(),
                            action=rule.action,
                            parameter=action_result['parameter'],
                            old_value=action_result['old_value'],
                            new_value=action_result['new_value'],
                            reason=rule.name,
                            impact_score=action_result.get('impact_score', 0.0),
                            success=action_result.get('success', True)
                        )

                        applied_actions.append(history)
                        self.tuning_history.append(history)

                        # ãƒ«ãƒ¼ãƒ«å®Ÿè¡Œè¨˜éŒ²æ›´æ–°
                        rule.last_executed = datetime.now()
                        rule.execution_count += 1
                        if action_result.get('success', True):
                            rule.success_count += 1

                        self.logger.info(f"æœ€é©åŒ–é©ç”¨: {rule.name} - {rule.action.value}")

            except Exception as e:
                self.logger.error(f"æœ€é©åŒ–ãƒ«ãƒ¼ãƒ«è©•ä¾¡ã‚¨ãƒ©ãƒ¼ {rule.rule_id}: {e}")
                continue

        return applied_actions

    def _apply_optimization_action(self, action: OptimizationAction, context: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é©ç”¨"""

        try:
            if action == OptimizationAction.INCREASE_CACHE_SIZE:
                return self._adjust_cache_size(increase=True)
            elif action == OptimizationAction.DECREASE_CACHE_SIZE:
                return self._adjust_cache_size(increase=False)
            elif action == OptimizationAction.INCREASE_WORKERS:
                return self._adjust_worker_count(increase=True)
            elif action == OptimizationAction.DECREASE_WORKERS:
                return self._adjust_worker_count(increase=False)
            elif action == OptimizationAction.CLEAR_MEMORY:
                return self._clear_memory()
            elif action == OptimizationAction.OPTIMIZE_QUERIES:
                return self._optimize_queries()
            elif action == OptimizationAction.REDUCE_POLLING:
                return self._adjust_polling_interval(increase=True)
            elif action == OptimizationAction.INCREASE_POLLING:
                return self._adjust_polling_interval(increase=False)
            elif action == OptimizationAction.RESTART_COMPONENTS:
                return self._restart_components()

            return None

        except Exception as e:
            self.logger.error(f"æœ€é©åŒ–ã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¨ãƒ©ãƒ¼ {action.value}: {e}")
            return None

    def _adjust_cache_size(self, increase: bool) -> Dict[str, Any]:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºèª¿æ•´"""

        param = self.tunable_params['cache_size']
        old_value = param['current']

        if increase:
            new_value = min(param['max'], old_value * 1.5)
        else:
            new_value = max(param['min'], old_value * 0.7)

        new_value = int(new_value)
        param['current'] = new_value

        # å®Ÿéš›ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºèª¿æ•´ï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰
        try:
            from realtime_performance_optimizer import realtime_performance_optimizer
            realtime_performance_optimizer.data_cache.max_size = new_value

            impact_score = abs(new_value - old_value) / old_value

            return {
                'parameter': 'cache_size',
                'old_value': old_value,
                'new_value': new_value,
                'success': True,
                'impact_score': impact_score
            }
        except Exception:
            return {
                'parameter': 'cache_size',
                'old_value': old_value,
                'new_value': new_value,
                'success': False,
                'impact_score': 0.0
            }

    def _adjust_worker_count(self, increase: bool) -> Dict[str, Any]:
        """ãƒ¯ãƒ¼ã‚«ãƒ¼æ•°èª¿æ•´"""

        param = self.tunable_params['worker_count']
        old_value = param['current']

        if increase:
            new_value = min(param['max'], old_value + 1)
        else:
            new_value = max(param['min'], old_value - 1)

        param['current'] = new_value

        return {
            'parameter': 'worker_count',
            'old_value': old_value,
            'new_value': new_value,
            'success': True,
            'impact_score': abs(new_value - old_value) / max(old_value, 1)
        }

    def _clear_memory(self) -> Dict[str, Any]:
        """ãƒ¡ãƒ¢ãƒªã‚¯ãƒªã‚¢"""

        memory_before = psutil.virtual_memory().percent

        # ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
        collected = gc.collect()

        memory_after = psutil.virtual_memory().percent
        impact_score = max(0, (memory_before - memory_after) / 100)

        return {
            'parameter': 'memory_usage',
            'old_value': memory_before,
            'new_value': memory_after,
            'success': collected > 0,
            'impact_score': impact_score
        }

    def _optimize_queries(self) -> Dict[str, Any]:
        """ã‚¯ã‚¨ãƒªæœ€é©åŒ–"""

        # ç°¡æ˜“çš„ãªæœ€é©åŒ–å‡¦ç†
        return {
            'parameter': 'query_optimization',
            'old_value': 'unoptimized',
            'new_value': 'optimized',
            'success': True,
            'impact_score': 0.1
        }

    def _adjust_polling_interval(self, increase: bool) -> Dict[str, Any]:
        """ãƒãƒ¼ãƒªãƒ³ã‚°é–“éš”èª¿æ•´"""

        param = self.tunable_params['polling_interval']
        old_value = param['current']

        if increase:
            new_value = min(param['max'], old_value * 1.2)
        else:
            new_value = max(param['min'], old_value * 0.8)

        new_value = int(new_value)
        param['current'] = new_value

        return {
            'parameter': 'polling_interval',
            'old_value': old_value,
            'new_value': new_value,
            'success': True,
            'impact_score': abs(new_value - old_value) / old_value
        }

    def _restart_components(self) -> Dict[str, Any]:
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå†èµ·å‹•"""

        # ç°¡æ˜“çš„ãªå†èµ·å‹•å‡¦ç†
        return {
            'parameter': 'component_restart',
            'old_value': 'running',
            'new_value': 'restarted',
            'success': True,
            'impact_score': 0.5
        }

class RealtimeMonitoringSystem:
    """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        self.logger = logging.getLogger(__name__)

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.profiler = PerformanceProfiler()
        self.auto_tuner = AutoTuner()

        # ç›£è¦–çŠ¶æ…‹
        self.is_monitoring = False
        self.monitoring_thread = None

        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´
        self.health_history = deque(maxlen=1440)  # 24æ™‚é–“åˆ†

        # ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š
        self.alert_thresholds = {
            'cpu_usage': 90.0,
            'memory_usage': 90.0,
            'disk_usage': 95.0,
            'response_time': 10.0,
            'error_rate': 0.1
        }

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
        self.db_path = Path("monitoring_data/realtime_monitoring.db")
        self.db_path.parent.mkdir(exist_ok=True)
        self._init_database()

        self.logger.info("Realtime monitoring system initialized")

    def _init_database(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–"""

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS system_health (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        cpu_usage REAL NOT NULL,
                        memory_usage REAL NOT NULL,
                        memory_available REAL NOT NULL,
                        disk_usage REAL NOT NULL,
                        network_latency REAL NOT NULL,
                        cache_hit_rate REAL NOT NULL,
                        response_time_avg REAL NOT NULL,
                        error_rate REAL NOT NULL,
                        active_connections INTEGER NOT NULL,
                        performance_level TEXT NOT NULL
                    )
                ''')

                # èª¿æ•´å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
                cursor.execute('''
                    CREATE TABLE IF NOT EXISTS tuning_history (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        action TEXT NOT NULL,
                        parameter TEXT NOT NULL,
                        old_value TEXT NOT NULL,
                        new_value TEXT NOT NULL,
                        reason TEXT NOT NULL,
                        impact_score REAL DEFAULT 0.0,
                        success INTEGER DEFAULT 1
                    )
                ''')

                conn.commit()

        except Exception as e:
            self.logger.error(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

    def start_monitoring(self):
        """ç›£è¦–é–‹å§‹"""

        if self.is_monitoring:
            return

        self.is_monitoring = True
        self.monitoring_thread = threading.Thread(target=self._monitoring_loop, daemon=True)
        self.monitoring_thread.start()

        self.logger.info("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–é–‹å§‹")

    def stop_monitoring(self):
        """ç›£è¦–åœæ­¢"""

        self.is_monitoring = False
        self.logger.info("ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–åœæ­¢")

    def _monitoring_loop(self):
        """ç›£è¦–ãƒ«ãƒ¼ãƒ—"""

        while self.is_monitoring:
            try:
                # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åé›†
                health = self._collect_system_health()
                self.health_history.append(health)

                # è‡ªå‹•èª¿æ•´ã®è©•ä¾¡ã¨é©ç”¨
                tuning_actions = self.auto_tuner.evaluate_and_apply_optimizations(health)

                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ï¼ˆ5åˆ†æ¯ï¼‰
                if len(self.health_history) % 5 == 0:
                    asyncio.create_task(self._save_health_to_db(health))

                    for action in tuning_actions:
                        asyncio.create_task(self._save_tuning_to_db(action))

                # ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
                self._check_alerts(health)

                # 1åˆ†é–“éš”
                time.sleep(60)

            except Exception as e:
                self.logger.error(f"ç›£è¦–ãƒ«ãƒ¼ãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
                time.sleep(60)

    def _collect_system_health(self) -> SystemHealth:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åé›†"""

        try:
            # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
            cpu_usage = psutil.cpu_percent(interval=1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')

            # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼ï¼ˆç°¡æ˜“æ¸¬å®šï¼‰
            network_latency = self._measure_network_latency()

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡
            cache_hit_rate = self._get_cache_hit_rate()

            # å¿œç­”æ™‚é–“å¹³å‡
            response_time_avg = self._get_avg_response_time()

            # ã‚¨ãƒ©ãƒ¼ç‡
            error_rate = self._get_error_rate()

            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶šæ•°
            active_connections = len(psutil.net_connections())

            # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«åˆ¤å®š
            performance_score = self._calculate_performance_score(
                cpu_usage, memory.percent, cache_hit_rate, response_time_avg, error_rate
            )
            performance_level = self._score_to_level(performance_score)

            return SystemHealth(
                timestamp=datetime.now(),
                cpu_usage=cpu_usage,
                memory_usage=memory.percent,
                memory_available=memory.available / 1024 / 1024 / 1024,  # GB
                disk_usage=disk.percent,
                network_latency=network_latency,
                cache_hit_rate=cache_hit_rate,
                response_time_avg=response_time_avg,
                error_rate=error_rate,
                active_connections=active_connections,
                performance_level=performance_level
            )

        except Exception as e:
            self.logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åé›†ã‚¨ãƒ©ãƒ¼: {e}")
            return SystemHealth(
                timestamp=datetime.now(),
                cpu_usage=0.0, memory_usage=0.0, memory_available=0.0,
                disk_usage=0.0, network_latency=0.0, cache_hit_rate=0.0,
                response_time_avg=0.0, error_rate=1.0, active_connections=0,
                performance_level=PerformanceLevel.CRITICAL
            )

    def _measure_network_latency(self) -> float:
        """ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼æ¸¬å®š"""

        try:
            import subprocess
            import platform

            if platform.system().lower() == 'windows':
                result = subprocess.run(['ping', '-n', '1', 'google.com'],
                                      capture_output=True, text=True, timeout=5)
            else:
                result = subprocess.run(['ping', '-c', '1', 'google.com'],
                                      capture_output=True, text=True, timeout=5)

            if result.returncode == 0:
                output = result.stdout
                # Windowsã®å ´åˆã®ç°¡æ˜“ãƒ‘ãƒ¼ã‚¹
                if 'ms' in output:
                    for line in output.split('\n'):
                        if 'ms' in line and '=' in line:
                            try:
                                latency_str = line.split('=')[-1].split('ms')[0].strip()
                                return float(latency_str)
                            except:
                                continue

            return 100.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        except Exception:
            return 100.0

    def _get_cache_hit_rate(self) -> float:
        """ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡å–å¾—"""

        try:
            from realtime_performance_optimizer import realtime_performance_optimizer
            data_cache_stats = realtime_performance_optimizer.data_cache.get_stats()
            return data_cache_stats.get('hit_rate', 0.0)
        except:
            return 0.0

    def _get_avg_response_time(self) -> float:
        """å¹³å‡å¿œç­”æ™‚é–“å–å¾—"""

        if self.profiler.response_times:
            return np.mean(list(self.profiler.response_times))
        return 0.0

    def _get_error_rate(self) -> float:
        """ã‚¨ãƒ©ãƒ¼ç‡å–å¾—"""

        if self.profiler.error_counts:
            recent_errors = list(self.profiler.error_counts)[-10:]  # ç›´è¿‘10ä»¶
            return np.mean(recent_errors) if recent_errors else 0.0
        return 0.0

    def _calculate_performance_score(self, cpu: float, memory: float,
                                   cache_hit: float, response_time: float, error_rate: float) -> float:
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—"""

        # å„ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’0-100ã‚¹ã‚±ãƒ¼ãƒ«ã«æ­£è¦åŒ–
        cpu_score = max(0, 100 - cpu)
        memory_score = max(0, 100 - memory)
        cache_score = cache_hit * 100
        response_score = max(0, 100 - min(response_time * 10, 100))
        error_score = max(0, 100 - error_rate * 1000)

        # é‡ã¿ä»˜ãå¹³å‡
        weights = [0.2, 0.2, 0.2, 0.2, 0.2]
        scores = [cpu_score, memory_score, cache_score, response_score, error_score]

        return sum(w * s for w, s in zip(weights, scores))

    def _score_to_level(self, score: float) -> PerformanceLevel:
        """ã‚¹ã‚³ã‚¢ã‹ã‚‰ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«ã¸å¤‰æ›"""

        if score >= 90:
            return PerformanceLevel.EXCELLENT
        elif score >= 70:
            return PerformanceLevel.GOOD
        elif score >= 50:
            return PerformanceLevel.FAIR
        elif score >= 30:
            return PerformanceLevel.POOR
        else:
            return PerformanceLevel.CRITICAL

    def _check_alerts(self, health: SystemHealth):
        """ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯"""

        alerts = []

        if health.cpu_usage > self.alert_thresholds['cpu_usage']:
            alerts.append(f"é«˜CPUä½¿ç”¨ç‡: {health.cpu_usage:.1f}%")

        if health.memory_usage > self.alert_thresholds['memory_usage']:
            alerts.append(f"é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {health.memory_usage:.1f}%")

        if health.disk_usage > self.alert_thresholds['disk_usage']:
            alerts.append(f"é«˜ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {health.disk_usage:.1f}%")

        if health.response_time_avg > self.alert_thresholds['response_time']:
            alerts.append(f"é…ã„å¿œç­”æ™‚é–“: {health.response_time_avg:.2f}ç§’")

        if health.error_rate > self.alert_thresholds['error_rate']:
            alerts.append(f"é«˜ã‚¨ãƒ©ãƒ¼ç‡: {health.error_rate:.1%}")

        if alerts:
            self.logger.warning(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ: {'; '.join(alerts)}")

    async def _save_health_to_db(self, health: SystemHealth):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute('''
                    INSERT INTO system_health
                    (timestamp, cpu_usage, memory_usage, memory_available, disk_usage,
                     network_latency, cache_hit_rate, response_time_avg, error_rate,
                     active_connections, performance_level)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    health.timestamp.isoformat(),
                    health.cpu_usage,
                    health.memory_usage,
                    health.memory_available,
                    health.disk_usage,
                    health.network_latency,
                    health.cache_hit_rate,
                    health.response_time_avg,
                    health.error_rate,
                    health.active_connections,
                    health.performance_level.value
                ))

                conn.commit()

        except Exception as e:
            self.logger.error(f"ãƒ˜ãƒ«ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    async def _save_tuning_to_db(self, tuning: TuningHistory):
        """èª¿æ•´å±¥æ­´ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute('''
                    INSERT INTO tuning_history
                    (timestamp, action, parameter, old_value, new_value, reason, impact_score, success)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    tuning.timestamp.isoformat(),
                    tuning.action.value,
                    tuning.parameter,
                    json.dumps(tuning.old_value),
                    json.dumps(tuning.new_value),
                    tuning.reason,
                    tuning.impact_score,
                    1 if tuning.success else 0
                ))

                conn.commit()

        except Exception as e:
            self.logger.error(f"èª¿æ•´å±¥æ­´ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")

    def get_monitoring_report(self) -> Dict[str, Any]:
        """ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆå–å¾—"""

        if not self.health_history:
            return {"error": "ãƒ˜ãƒ«ã‚¹å±¥æ­´ãªã—"}

        recent_health = list(self.health_history)[-60:]  # éå»1æ™‚é–“

        # çµ±è¨ˆè¨ˆç®—
        avg_cpu = np.mean([h.cpu_usage for h in recent_health])
        avg_memory = np.mean([h.memory_usage for h in recent_health])
        avg_cache_hit = np.mean([h.cache_hit_rate for h in recent_health])
        avg_response_time = np.mean([h.response_time_avg for h in recent_health])
        avg_error_rate = np.mean([h.error_rate for h in recent_health])

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«åˆ†å¸ƒ
        level_counts = {}
        for health in recent_health:
            level = health.performance_level.value
            level_counts[level] = level_counts.get(level, 0) + 1

        # è‡ªå‹•èª¿æ•´çµ±è¨ˆ
        recent_tuning = list(self.auto_tuner.tuning_history)[-20:]  # ç›´è¿‘20ä»¶

        return {
            'timestamp': datetime.now().isoformat(),
            'monitoring_status': 'active' if self.is_monitoring else 'inactive',
            'system_metrics': {
                'avg_cpu_usage': avg_cpu,
                'avg_memory_usage': avg_memory,
                'avg_cache_hit_rate': avg_cache_hit,
                'avg_response_time': avg_response_time,
                'avg_error_rate': avg_error_rate
            },
            'performance_distribution': level_counts,
            'recent_tuning_actions': len(recent_tuning),
            'tunable_parameters': {
                param: config['current']
                for param, config in self.auto_tuner.tunable_params.items()
            },
            'health_history_size': len(self.health_history),
            'optimization_rules': len(self.auto_tuner.optimization_rules)
        }

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
realtime_monitoring_system = RealtimeMonitoringSystem()

# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
async def run_monitoring_system_test():
    """ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    print("=== ğŸ“Š ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ»è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ ===")

    # ç›£è¦–é–‹å§‹
    realtime_monitoring_system.start_monitoring()

    print(f"\nğŸ” ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹åé›†ãƒ†ã‚¹ãƒˆ")

    # è¤‡æ•°å›ãƒ˜ãƒ«ã‚¹åé›†
    for i in range(3):
        health = realtime_monitoring_system._collect_system_health()
        print(f"\n--- åé›† {i+1} ---")
        print(f"  CPUä½¿ç”¨ç‡: {health.cpu_usage:.1f}%")
        print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {health.memory_usage:.1f}%")
        print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {health.cache_hit_rate:.1%}")
        print(f"  å¿œç­”æ™‚é–“: {health.response_time_avg:.2f}ç§’")
        print(f"  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒ™ãƒ«: {health.performance_level.value}")

        # è‡ªå‹•èª¿æ•´ãƒ†ã‚¹ãƒˆ
        tuning_actions = realtime_monitoring_system.auto_tuner.evaluate_and_apply_optimizations(health)
        if tuning_actions:
            print(f"  è‡ªå‹•èª¿æ•´: {len(tuning_actions)}ä»¶é©ç”¨")
            for action in tuning_actions:
                print(f"    - {action.reason}: {action.parameter} {action.old_value} â†’ {action.new_value}")
        else:
            print(f"  è‡ªå‹•èª¿æ•´: ãªã—")

        await asyncio.sleep(2)

    # ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ
    print(f"\nğŸ“ˆ ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ")
    report = realtime_monitoring_system.get_monitoring_report()

    print(f"  ç›£è¦–çŠ¶æ³: {report['monitoring_status']}")

    system_metrics = report['system_metrics']
    print(f"  å¹³å‡CPUä½¿ç”¨ç‡: {system_metrics['avg_cpu_usage']:.1f}%")
    print(f"  å¹³å‡ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {system_metrics['avg_memory_usage']:.1f}%")
    print(f"  å¹³å‡ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {system_metrics['avg_cache_hit_rate']:.1%}")
    print(f"  å¹³å‡å¿œç­”æ™‚é–“: {system_metrics['avg_response_time']:.2f}ç§’")

    # èª¿æ•´å¯èƒ½ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    print(f"\nâš™ï¸ ç¾åœ¨ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿:")
    tunable_params = report['tunable_parameters']
    for param, value in tunable_params.items():
        print(f"  {param}: {value}")

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ
    if 'performance_distribution' in report:
        print(f"\nğŸ¯ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†å¸ƒ:")
        for level, count in report['performance_distribution'].items():
            print(f"  {level}: {count}å›")

    print(f"\nâœ… ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ»è‡ªå‹•èª¿æ•´ã‚·ã‚¹ãƒ†ãƒ ç¨¼åƒä¸­")
    print(f"ã‚·ã‚¹ãƒ†ãƒ ã¯ç¶™ç¶šçš„ã«ç›£è¦–ã•ã‚Œã€å¿…è¦ã«å¿œã˜ã¦è‡ªå‹•èª¿æ•´ã•ã‚Œã¾ã™ã€‚")

    # å°‘ã—å¾…ã£ã¦ç›£è¦–åœæ­¢
    await asyncio.sleep(5)
    realtime_monitoring_system.stop_monitoring()

if __name__ == "__main__":
    # ãƒ­ã‚°è¨­å®š
    logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    asyncio.run(run_monitoring_system_test())