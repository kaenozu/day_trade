#!/usr/bin/env python3
"""
æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆ
Issue #436: æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ å®Œæˆ

24/7å®‰å®šé‹ç”¨ã®ãŸã‚ã®APMãƒ»ã‚ªãƒ–ã‚¶ãƒ¼ãƒãƒ“ãƒªãƒ†ã‚£çµ±åˆåŸºç›¤ã®ãƒ†ã‚¹ãƒˆ
"""

import asyncio
import sys
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent / "src"))

from day_trade.monitoring.production_monitoring_system import (
    ProductionMonitoringSystem,
    AlertSeverity,
    MonitoringScope,
)


def test_basic_functionality():
    """åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
    print("=== åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ ===")

    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    monitoring = ProductionMonitoringSystem()
    print("âœ“ ProductionMonitoringSystemã®åˆæœŸåŒ–")

    # ç›£è¦–é–‹å§‹
    monitoring.start_monitoring()
    print("âœ“ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    monitoring.record_metric("test.cpu_usage", 65.5, {"host": "server1"})
    monitoring.record_metric("test.memory_usage", 78.2, {"host": "server1"})
    monitoring.record_metric("test.response_time", 25.3, {"endpoint": "/api/test"})
    print("âœ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²")

    # APIå‘¼ã³å‡ºã—è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    monitoring.record_api_call("/api/trades", "GET", 23.5, 200, True)
    monitoring.record_api_call("/api/trades", "POST", 45.2, 201, True)
    monitoring.record_api_call("/api/orders", "GET", 89.1, 500, False)  # ã‚¨ãƒ©ãƒ¼
    print("âœ“ APIå‘¼ã³å‡ºã—è¨˜éŒ²")

    # æ§‹é€ åŒ–ãƒ­ã‚°è¨˜éŒ²ãƒ†ã‚¹ãƒˆ
    monitoring.log_structured("INFO", "ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸ç¨¼åƒ", "SystemMonitor",
                             cpu_usage=65.5, memory_usage=78.2)
    monitoring.log_structured("WARNING", "ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“å¢—åŠ ", "APIGateway",
                             endpoint="/api/orders", response_time=89.1)
    monitoring.log_structured("ERROR", "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼", "DatabaseManager",
                             error_code="DB001", retry_count=3)
    print("âœ“ æ§‹é€ åŒ–ãƒ­ã‚°è¨˜éŒ²")

    # å°‘ã—å¾…æ©Ÿã—ã¦ã‹ã‚‰çµæœç¢ºèª
    time.sleep(2)

    # ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    dashboard = monitoring.get_dashboard_data()
    print("âœ“ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼å–å¾—
    cpu_summary = monitoring.get_metrics_summary("test.cpu_usage")
    response_time_summary = monitoring.get_metrics_summary("test.response_time")
    print("âœ“ ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚µãƒãƒªãƒ¼å–å¾—")

    # æœ€è¿‘ã®ãƒ­ã‚°å–å¾—
    recent_logs = monitoring.get_recent_logs(limit=10)
    error_logs = monitoring.get_recent_logs(level="ERROR", limit=5)
    print("âœ“ ãƒ­ã‚°æ¤œç´¢æ©Ÿèƒ½")

    monitoring.stop_monitoring()
    print("âœ“ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åœæ­¢")

    return {
        'dashboard': dashboard,
        'cpu_summary': cpu_summary,
        'response_time_summary': response_time_summary,
        'recent_logs_count': len(recent_logs),
        'error_logs_count': len(error_logs)
    }


async def test_distributed_tracing():
    """åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    print("\n=== åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ ===")

    monitoring = ProductionMonitoringSystem()

    # åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚¹å®Ÿè¡Œ
    async with monitoring.trace_operation("user_login_flow") as main_span:
        monitoring.tracer.add_span_tag(main_span, "user_id", "user123")
        monitoring.tracer.add_span_tag(main_span, "client_ip", "192.168.1.100")

        # èªè¨¼ãƒ•ã‚§ãƒ¼ã‚º
        async with monitoring.trace_operation("authentication", main_span) as auth_span:
            monitoring.tracer.add_span_log(auth_span, "èªè¨¼å‡¦ç†é–‹å§‹")
            await asyncio.sleep(0.1)  # æ¨¡æ“¬å‡¦ç†æ™‚é–“
            monitoring.tracer.add_span_tag(auth_span, "auth_method", "password")
            monitoring.tracer.add_span_log(auth_span, "èªè¨¼å‡¦ç†å®Œäº†")

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆãƒ•ã‚§ãƒ¼ã‚º
        async with monitoring.trace_operation("session_creation", main_span) as session_span:
            monitoring.tracer.add_span_log(session_span, "ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆé–‹å§‹")
            await asyncio.sleep(0.05)
            monitoring.tracer.add_span_tag(session_span, "session_id", "sess_456")
            monitoring.tracer.add_span_log(session_span, "ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½œæˆå®Œäº†")

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ•ã‚§ãƒ¼ã‚º
        async with monitoring.trace_operation("user_data_fetch", main_span) as data_span:
            monitoring.tracer.add_span_log(data_span, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—é–‹å§‹")
            await asyncio.sleep(0.08)
            monitoring.tracer.add_span_tag(data_span, "database", "user_db")
            monitoring.tracer.add_span_log(data_span, "ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—å®Œäº†")

    print("âœ“ åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚¹å®Ÿè¡Œå®Œäº†")

    # ãƒˆãƒ¬ãƒ¼ã‚¹çµæœç¢ºèª
    dashboard = monitoring.get_dashboard_data()
    trace_info = dashboard['traces']

    print(f"âœ“ ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒˆãƒ¬ãƒ¼ã‚¹: {trace_info['active_traces']}")
    print(f"âœ“ å®Œäº†ãƒˆãƒ¬ãƒ¼ã‚¹: {trace_info['completed_traces']}")

    return trace_info


def test_slo_monitoring():
    """SLOç›£è¦–ãƒ†ã‚¹ãƒˆ"""
    print("\n=== SLOç›£è¦–ãƒ†ã‚¹ãƒˆ ===")

    monitoring = ProductionMonitoringSystem()
    slo_manager = monitoring.slo_manager

    # SLOãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ² - æˆåŠŸã‚±ãƒ¼ã‚¹
    for i in range(50):
        response_time = 20 + (i % 10)  # 20-30ms
        success = response_time < 50  # 50msä»¥ä¸‹ã‚’æˆåŠŸã¨ã™ã‚‹
        slo_manager.add_slo_metric("api_latency", response_time, success)

    # SLOãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ² - ç•°å¸¸ã‚±ãƒ¼ã‚¹
    for i in range(5):
        response_time = 80 + (i * 10)  # 80-120msï¼ˆç•°å¸¸å€¤ï¼‰
        success = False
        slo_manager.add_slo_metric("api_latency", response_time, success)

    print("âœ“ SLOãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨˜éŒ²")

    # SLOçŠ¶æ…‹ç¢ºèª
    api_latency_status = slo_manager.get_slo_status("api_latency")
    system_availability_status = slo_manager.get_slo_status("system_availability")
    all_slo_status = slo_manager.get_all_slo_status()

    print("âœ“ SLOçŠ¶æ…‹å–å¾—")

    if api_latency_status:
        print(f"  - API ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {api_latency_status.current_percentage:.2f}% "
              f"(ç›®æ¨™: {api_latency_status.config.target_percentage:.2f}%) "
              f"çŠ¶æ…‹: {api_latency_status.status}")
        print(f"  - ã‚¨ãƒ©ãƒ¼ãƒã‚¸ã‚§ãƒƒãƒˆæ¶ˆè²»: {api_latency_status.error_budget_consumed:.1f}%")

    return {
        'api_latency_status': api_latency_status,
        'system_availability_status': system_availability_status,
        'total_slos': len(all_slo_status)
    }


def test_anomaly_detection():
    """ç•°å¸¸æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ"""
    print("\n=== ç•°å¸¸æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ ===")

    monitoring = ProductionMonitoringSystem()
    anomaly_detector = monitoring.anomaly_detector

    # æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’å¤§é‡ã«è¿½åŠ ï¼ˆå­¦ç¿’ç”¨ï¼‰
    print("æ­£å¸¸ãƒ‡ãƒ¼ã‚¿å­¦ç¿’ä¸­...")
    for i in range(100):
        # CPUä½¿ç”¨ç‡: 40-60%ã®æ­£å¸¸ç¯„å›²
        normal_cpu = 50 + (i % 20) - 10
        anomaly_detector.add_metric_point("cpu_usage", normal_cpu)

        # ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: 60-80%ã®æ­£å¸¸ç¯„å›²
        normal_memory = 70 + (i % 20) - 10
        anomaly_detector.add_metric_point("memory_usage", normal_memory)

    print("âœ“ æ­£å¸¸ãƒ‡ãƒ¼ã‚¿å­¦ç¿’å®Œäº†")

    # ç•°å¸¸å€¤ãƒ†ã‚¹ãƒˆ
    test_cases = [
        ("cpu_usage", 95.0, "é«˜CPUä½¿ç”¨ç‡"),
        ("cpu_usage", 5.0, "ä½CPUä½¿ç”¨ç‡"),
        ("memory_usage", 98.0, "é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡"),
        ("memory_usage", 25.0, "ä½ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡"),
        ("cpu_usage", 55.0, "æ­£å¸¸CPUä½¿ç”¨ç‡"),
        ("memory_usage", 75.0, "æ­£å¸¸ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡"),
    ]

    anomaly_results = []
    for metric_name, value, description in test_cases:
        is_anomaly, score = anomaly_detector.detect_anomaly(metric_name, value)
        anomaly_results.append({
            'metric': metric_name,
            'value': value,
            'description': description,
            'is_anomaly': is_anomaly,
            'score': score
        })
        print(f"  - {description}: å€¤={value}, ç•°å¸¸={is_anomaly}, ã‚¹ã‚³ã‚¢={score:.3f}")

    print("âœ“ ç•°å¸¸æ¤œçŸ¥ãƒ†ã‚¹ãƒˆå®Œäº†")

    return anomaly_results


def test_comprehensive_monitoring():
    """åŒ…æ‹¬çš„ç›£è¦–ãƒ†ã‚¹ãƒˆ"""
    print("\n=== åŒ…æ‹¬çš„ç›£è¦–ãƒ†ã‚¹ãƒˆ ===")

    monitoring = ProductionMonitoringSystem()
    monitoring.start_monitoring()

    # è¤‡æ•°ã®ç›£è¦–é …ç›®ã‚’åŒæ™‚ã«ãƒ†ã‚¹ãƒˆ
    test_scenarios = [
        # æ­£å¸¸ã‚±ãƒ¼ã‚¹
        {"api": "/api/users", "response_time": 25.0, "status": 200, "success": True},
        {"api": "/api/trades", "response_time": 35.0, "status": 200, "success": True},
        {"api": "/api/orders", "response_time": 42.0, "status": 201, "success": True},

        # è­¦å‘Šã‚±ãƒ¼ã‚¹
        {"api": "/api/analytics", "response_time": 65.0, "status": 200, "success": True},
        {"api": "/api/reports", "response_time": 78.0, "status": 200, "success": True},

        # ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹
        {"api": "/api/trades", "response_time": 120.0, "status": 500, "success": False},
        {"api": "/api/orders", "response_time": 95.0, "status": 503, "success": False},
    ]

    for scenario in test_scenarios:
        monitoring.record_api_call(
            scenario["api"], "GET",
            scenario["response_time"],
            scenario["status"],
            scenario["success"]
        )

        # ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
        monitoring.record_metric("custom.trade_volume", 1000 + (scenario["response_time"] * 100))
        monitoring.record_metric("custom.active_users", 500 + int(scenario["response_time"]))

        # ãƒ­ã‚°è¨˜éŒ²
        log_level = "ERROR" if not scenario["success"] else "WARNING" if scenario["response_time"] > 60 else "INFO"
        monitoring.log_structured(
            log_level,
            f"APIå‡¦ç†: {scenario['api']}",
            "APIGateway",
            response_time=scenario["response_time"],
            status_code=scenario["status"],
            endpoint=scenario["api"]
        )

    # å°‘ã—å¾…æ©Ÿã—ã¦å‡¦ç†å®Œäº†ã‚’å¾…ã¤
    time.sleep(3)

    # çµæœç¢ºèª
    dashboard = monitoring.get_dashboard_data()

    print("âœ“ åŒ…æ‹¬çš„ç›£è¦–ãƒ†ã‚¹ãƒˆå®Œäº†")
    print(f"  - ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹: {dashboard['system_health']['status']}")
    print(f"  - ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {dashboard['statistics']['total_requests']}")
    print(f"  - æˆåŠŸç‡: {dashboard['statistics']['successful_requests'] / max(1, dashboard['statistics']['total_requests']):.1%}")
    print(f"  - å¹³å‡å¿œç­”æ™‚é–“: {dashboard['statistics']['avg_response_time']:.2f}ms")
    print(f"  - ã‚¢ãƒ©ãƒ¼ãƒˆæ•°: {dashboard['alerts']['total']}")
    print(f"  - ç•°å¸¸æ¤œçŸ¥: {dashboard['statistics']['anomalies_detected']}")

    monitoring.stop_monitoring()

    return dashboard


async def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("æœ¬ç•ªé‹ç”¨ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ  çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)

    try:
        # åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
        basic_results = test_basic_functionality()

        # åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°ãƒ†ã‚¹ãƒˆ
        trace_results = await test_distributed_tracing()

        # SLOç›£è¦–ãƒ†ã‚¹ãƒˆ
        slo_results = test_slo_monitoring()

        # ç•°å¸¸æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ
        anomaly_results = test_anomaly_detection()

        # åŒ…æ‹¬çš„ç›£è¦–ãƒ†ã‚¹ãƒˆ
        comprehensive_results = test_comprehensive_monitoring()

        # çµæœã‚µãƒãƒªãƒ¼
        print("\n" + "=" * 60)
        print("ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)

        print("âœ… åŸºæœ¬æ©Ÿèƒ½:")
        print(f"   - ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰: {basic_results['dashboard']['system_health']['status']}")
        print(f"   - CPUç›£è¦–: {len(basic_results.get('cpu_summary', {}))}é …ç›®")
        print(f"   - ãƒ­ã‚°åé›†: {basic_results['recent_logs_count']}ä»¶")

        print("âœ… åˆ†æ•£ãƒˆãƒ¬ãƒ¼ã‚·ãƒ³ã‚°:")
        print(f"   - ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒˆãƒ¬ãƒ¼ã‚¹: {trace_results['active_traces']}")
        print(f"   - å®Œäº†ãƒˆãƒ¬ãƒ¼ã‚¹: {trace_results['completed_traces']}")

        print("âœ… SLOç›£è¦–:")
        if slo_results['api_latency_status']:
            print(f"   - APIãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ãƒ¼: {slo_results['api_latency_status'].current_percentage:.1f}%")
            print(f"   - SLOçŠ¶æ…‹: {slo_results['api_latency_status'].status}")
        print(f"   - ç›£è¦–SLOæ•°: {slo_results['total_slos']}")

        print("âœ… ç•°å¸¸æ¤œçŸ¥:")
        anomaly_detected = sum(1 for r in anomaly_results if r['is_anomaly'])
        print(f"   - ç•°å¸¸æ¤œçŸ¥æ•°: {anomaly_detected}/{len(anomaly_results)}")

        print("âœ… åŒ…æ‹¬çš„ç›£è¦–:")
        print(f"   - ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹: {comprehensive_results['system_health']['status']}")
        print(f"   - ç·å‡¦ç†ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {comprehensive_results['statistics']['total_requests']}")
        print(f"   - ç™ºç”Ÿã‚¢ãƒ©ãƒ¼ãƒˆ: {comprehensive_results['alerts']['total']}")

        print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ!")
        return True

    except Exception as e:
        print(f"\nâŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = asyncio.run(main())
    sys.exit(0 if success else 1)