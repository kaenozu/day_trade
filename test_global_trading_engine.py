#!/usr/bin/env python3
"""
Global Trading Engine - 24æ™‚é–“é€£ç¶šå–å¼•ã‚·ã‚¹ãƒ†ãƒ çµ±åˆãƒ‡ãƒ¢
Forexãƒ»Cryptoãƒ»Stockå¸‚å ´ã®åŒ…æ‹¬çš„åˆ†æãƒ»å–å¼•ã‚·ã‚¹ãƒ†ãƒ 

ä¸–ç•Œ3å¤§å¸‚å ´ã§ã®24æ™‚é–“ãƒãƒ³ã‚¹ãƒˆãƒƒãƒ—å–å¼•ã‚’å®Ÿç¾
"""

import asyncio
import json
import logging
import time
from datetime import datetime, timedelta, timezone
from typing import Any, Dict, List, Optional

import numpy as np

from src.day_trade.analysis.cross_market_correlation import create_correlation_engine
from src.day_trade.data.crypto_data_collector import create_crypto_collector
from src.day_trade.data.forex_data_collector import create_forex_collector
from src.day_trade.models.database import init_global_database
from src.day_trade.models.global_ai_models import (
    GlobalModelConfig,
    create_global_ai_models,
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå†…ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from src.day_trade.utils.logging_config import get_context_logger

logger = get_context_logger(__name__)

class GlobalTradingSession:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«å–å¼•ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†"""

    def __init__(self):
        # å–å¼•ã‚»ãƒƒã‚·ãƒ§ãƒ³å®šç¾©
        self.sessions = {
            'tokyo': {
                'name': 'Tokyo Session',
                'timezone': 'Asia/Tokyo',
                'start_hour': 9,
                'end_hour': 17,
                'markets': ['forex', 'stock']
            },
            'london': {
                'name': 'London Session',
                'timezone': 'Europe/London',
                'start_hour': 8,
                'end_hour': 16,
                'markets': ['forex', 'stock']
            },
            'new_york': {
                'name': 'New York Session',
                'timezone': 'America/New_York',
                'start_hour': 9,
                'end_hour': 17,
                'markets': ['forex', 'stock']
            },
            'crypto': {
                'name': '24/7 Crypto Session',
                'timezone': 'UTC',
                'start_hour': 0,
                'end_hour': 24,
                'markets': ['crypto']
            }
        }

    def get_active_sessions(self) -> List[str]:
        """ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—"""
        current_utc = datetime.now(timezone.utc)
        active = []

        # Cryptoã¯å¸¸æ™‚ã‚¢ã‚¯ãƒ†ã‚£ãƒ–
        active.append('crypto')

        # å„å¸‚å ´ã‚»ãƒƒã‚·ãƒ§ãƒ³æ™‚é–“ã‚’UTCã§è¿‘ä¼¼ãƒã‚§ãƒƒã‚¯
        utc_hour = current_utc.hour

        # Tokyo: UTC 0:00-8:00 (JST 9:00-17:00)
        if 0 <= utc_hour <= 8:
            active.append('tokyo')

        # London: UTC 8:00-16:00 (GMT 8:00-16:00)
        if 8 <= utc_hour <= 16:
            active.append('london')

        # New York: UTC 13:00-21:00 (EST 9:00-17:00)
        if 13 <= utc_hour <= 21:
            active.append('new_york')

        return active

    def get_primary_session(self) -> str:
        """ä¸»è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¤å®š"""
        active_sessions = self.get_active_sessions()

        # å„ªå…ˆé †ä½: New York > London > Tokyo > Crypto only
        if 'new_york' in active_sessions:
            return 'new_york'
        elif 'london' in active_sessions:
            return 'london'
        elif 'tokyo' in active_sessions:
            return 'tokyo'
        else:
            return 'crypto'

class GlobalTradingEngine:
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«å–å¼•ã‚¨ãƒ³ã‚¸ãƒ³çµ±åˆã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self):
        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.forex_collector = create_forex_collector()
        self.crypto_collector = create_crypto_collector()
        self.correlation_engine = create_correlation_engine(
            self.forex_collector, self.crypto_collector
        )

        # AI ãƒ¢ãƒ‡ãƒ«
        model_config = GlobalModelConfig(
            sequence_length=60,
            forex_features=24,
            crypto_features=32,
            hidden_size=128,
            num_layers=2,
            prediction_horizons=[1, 5, 15, 60]  # 1åˆ†ã€5åˆ†ã€15åˆ†ã€1æ™‚é–“
        )
        self.ai_models = create_global_ai_models(model_config)

        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†
        self.session_manager = GlobalTradingSession()

        # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹
        self.is_running = False
        self.system_stats = {
            'start_time': None,
            'total_predictions': 0,
            'total_correlations': 0,
            'active_markets': [],
            'current_session': None,
            'uptime_hours': 0.0
        }

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹çµ±è¨ˆ
        self.performance_metrics = {
            'prediction_latency': [],
            'correlation_calc_time': [],
            'data_collection_rate': 0,
            'system_health_score': 1.0
        }

        logger.info("Global Trading Engine initialized")

    async def start_24h_operation(self, duration_hours: float = 1.0):
        """24æ™‚é–“é€£ç¶šé‹ç”¨é–‹å§‹"""

        print("=" * 70)
        print("ğŸŒ GLOBAL TRADING ENGINE - 24æ™‚é–“é€£ç¶šå–å¼•ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 70)
        print(f"é‹ç”¨é–‹å§‹æ™‚åˆ»: {datetime.now()}")
        print(f"ãƒ†ã‚¹ãƒˆæœŸé–“: {duration_hours} æ™‚é–“")
        print("=" * 70)

        self.is_running = True
        self.system_stats['start_time'] = datetime.now()

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        try:
            init_global_database()
            print("âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–å®Œäº†")
        except Exception as e:
            logger.warning(f"Database initialization warning: {e}")

        # ä¸¦è¡Œå‡¦ç†ã‚¿ã‚¹ã‚¯
        tasks = [
            self._continuous_data_collection(),
            self._continuous_ai_analysis(),
            self._continuous_correlation_analysis(),
            self._continuous_performance_monitoring(),
            self._session_management_loop(),
            self._system_health_monitoring()
        ]

        try:
            # æŒ‡å®šæ™‚é–“å¾Œã«åœæ­¢
            duration_seconds = duration_hours * 3600

            print("ğŸš€ 24æ™‚é–“é€£ç¶šã‚·ã‚¹ãƒ†ãƒ é–‹å§‹...")
            print(f"â° {duration_seconds:.0f} ç§’é–“ã®é‹ç”¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")

            # ã‚¿ã‚¹ã‚¯å®Ÿè¡Œã¨ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            await asyncio.wait_for(
                asyncio.gather(*tasks, return_exceptions=True),
                timeout=duration_seconds
            )

        except asyncio.TimeoutError:
            print(f"\nâœ… {duration_hours} æ™‚é–“ã®ãƒ†ã‚¹ãƒˆé‹ç”¨ãŒæ­£å¸¸å®Œäº†ã—ã¾ã—ãŸ")

        finally:
            await self._shutdown_system()

    async def _continuous_data_collection(self):
        """ç¶™ç¶šçš„ãƒ‡ãƒ¼ã‚¿åé›†"""
        logger.info("Starting continuous data collection...")

        while self.is_running:
            try:
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¤å®š
                current_session = self.session_manager.get_primary_session()

                # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¸‚å ´ã§ã®ãƒ‡ãƒ¼ã‚¿åé›†
                if current_session in ['tokyo', 'london', 'new_york']:
                    # Forex ãƒ‡ãƒ¼ã‚¿åé›†
                    forex_data = self.forex_collector.get_all_latest_ticks()
                    if forex_data:
                        logger.debug(f"Forex data: {len(forex_data)} pairs")

                # æš—å·é€šè²¨ãƒ‡ãƒ¼ã‚¿ï¼ˆ24æ™‚é–“ï¼‰
                crypto_data = self.crypto_collector.get_all_market_data()
                if crypto_data:
                    logger.debug(f"Crypto data: {len(crypto_data)} symbols")

                # çµ±è¨ˆæ›´æ–°
                self.performance_metrics['data_collection_rate'] = len(forex_data) + len(crypto_data) if forex_data and crypto_data else 0

                await asyncio.sleep(5)  # 5ç§’é–“éš”

            except Exception as e:
                logger.error(f"Data collection error: {e}")
                await asyncio.sleep(10)

    async def _continuous_ai_analysis(self):
        """ç¶™ç¶šçš„AIåˆ†æ"""
        logger.info("Starting continuous AI analysis...")

        while self.is_running:
            try:
                # æ¨¡æ“¬AIåˆ†æï¼ˆå®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼‰
                start_time = time.time()

                # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§AIäºˆæ¸¬å®Ÿè¡Œ
                batch_size = 2
                sequence_length = 60

                forex_data = np.random.randn(batch_size, sequence_length, 24).astype(np.float32)
                crypto_data = np.random.randn(batch_size, sequence_length, 32).astype(np.float32)

                # Tensorå¤‰æ›
                import torch
                forex_tensor = torch.tensor(forex_data)
                crypto_tensor = torch.tensor(crypto_data)
                forex_ids = torch.randint(0, 10, (batch_size,))
                crypto_ids = torch.randint(0, 20, (batch_size,))

                # AIäºˆæ¸¬å®Ÿè¡Œ
                with torch.no_grad():
                    predictions = self.ai_models(forex_tensor, crypto_tensor, forex_ids, crypto_ids)

                # ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·è¨˜éŒ²
                prediction_time = (time.time() - start_time) * 1000
                self.performance_metrics['prediction_latency'].append(prediction_time)

                # çµ±è¨ˆæ›´æ–°
                self.system_stats['total_predictions'] += len(predictions['forex_predictions']) + len(predictions['crypto_predictions'])

                logger.debug(f"AI analysis completed in {prediction_time:.2f}ms")

                await asyncio.sleep(15)  # 15ç§’é–“éš”

            except Exception as e:
                logger.error(f"AI analysis error: {e}")
                await asyncio.sleep(30)

    async def _continuous_correlation_analysis(self):
        """ç¶™ç¶šçš„ç›¸é–¢åˆ†æ"""
        logger.info("Starting continuous correlation analysis...")

        while self.is_running:
            try:
                start_time = time.time()

                # ç›¸é–¢åˆ†æå®Ÿè¡Œï¼ˆç¸®å°ç‰ˆï¼‰
                asset_pairs = [
                    ("EUR/USD", "BTCUSDT"),
                    ("USD/JPY", "ETHUSDT"),
                    ("BTCUSDT", "ETHUSDT")
                ]

                correlation_count = 0
                for asset1, asset2 in asset_pairs:
                    # æ¨¡æ“¬ç›¸é–¢è¨ˆç®—
                    correlation = np.random.uniform(-0.5, 0.5)
                    correlation_count += 1

                # æ™‚é–“è¨˜éŒ²
                correlation_time = (time.time() - start_time) * 1000
                self.performance_metrics['correlation_calc_time'].append(correlation_time)

                # çµ±è¨ˆæ›´æ–°
                self.system_stats['total_correlations'] += correlation_count

                logger.debug(f"Correlation analysis: {correlation_count} pairs in {correlation_time:.2f}ms")

                await asyncio.sleep(30)  # 30ç§’é–“éš”

            except Exception as e:
                logger.error(f"Correlation analysis error: {e}")
                await asyncio.sleep(60)

    async def _session_management_loop(self):
        """ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç†ãƒ«ãƒ¼ãƒ—"""
        logger.info("Starting session management...")

        while self.is_running:
            try:
                # ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³åˆ¤å®š
                active_sessions = self.session_manager.get_active_sessions()
                primary_session = self.session_manager.get_primary_session()

                # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹æ›´æ–°
                self.system_stats['active_markets'] = active_sessions
                self.system_stats['current_session'] = primary_session

                # ã‚»ãƒƒã‚·ãƒ§ãƒ³å¤‰æ›´æ™‚ã®ãƒ­ã‚°
                current_time = datetime.now()
                logger.info(f"Active sessions: {active_sessions}, Primary: {primary_session}")

                await asyncio.sleep(60)  # 1åˆ†é–“éš”

            except Exception as e:
                logger.error(f"Session management error: {e}")
                await asyncio.sleep(120)

    async def _continuous_performance_monitoring(self):
        """ç¶™ç¶šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–"""
        logger.info("Starting performance monitoring...")

        while self.is_running:
            try:
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™è¨ˆç®—
                if self.performance_metrics['prediction_latency']:
                    avg_latency = np.mean(self.performance_metrics['prediction_latency'][-100:])  # æœ€æ–°100ä»¶
                else:
                    avg_latency = 0

                if self.performance_metrics['correlation_calc_time']:
                    avg_correlation_time = np.mean(self.performance_metrics['correlation_calc_time'][-50:])  # æœ€æ–°50ä»¶
                else:
                    avg_correlation_time = 0

                # ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ã‚¹ã‚³ã‚¢è¨ˆç®—
                health_score = 1.0
                if avg_latency > 1000:  # 1ç§’ä»¥ä¸Š
                    health_score -= 0.2
                if avg_correlation_time > 2000:  # 2ç§’ä»¥ä¸Š
                    health_score -= 0.1

                self.performance_metrics['system_health_score'] = max(0.0, health_score)

                logger.debug(f"Performance: Latency={avg_latency:.1f}ms, Health={health_score:.2f}")

                await asyncio.sleep(30)  # 30ç§’é–“éš”

            except Exception as e:
                logger.error(f"Performance monitoring error: {e}")
                await asyncio.sleep(60)

    async def _system_health_monitoring(self):
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ç›£è¦–"""
        logger.info("Starting system health monitoring...")

        while self.is_running:
            try:
                # ç¨¼åƒæ™‚é–“è¨ˆç®—
                if self.system_stats['start_time']:
                    uptime = datetime.now() - self.system_stats['start_time']
                    self.system_stats['uptime_hours'] = uptime.total_seconds() / 3600

                # ãƒ˜ãƒ«ã‚¹çŠ¶æ³è¡¨ç¤ºï¼ˆ10åˆ†ã”ã¨ï¼‰
                if int(self.system_stats['uptime_hours'] * 6) % 1 == 0:  # 10åˆ†ã”ã¨
                    self._display_system_status()

                await asyncio.sleep(60)  # 1åˆ†é–“éš”

            except Exception as e:
                logger.error(f"Health monitoring error: {e}")
                await asyncio.sleep(120)

    def _display_system_status(self):
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³è¡¨ç¤º"""
        stats = self.system_stats
        metrics = self.performance_metrics

        print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ³ [{datetime.now().strftime('%H:%M:%S')}]")
        print(f"   ç¨¼åƒæ™‚é–“: {stats['uptime_hours']:.2f} æ™‚é–“")
        print(f"   ç¾åœ¨ã‚»ãƒƒã‚·ãƒ§ãƒ³: {stats['current_session']}")
        print(f"   ã‚¢ã‚¯ãƒ†ã‚£ãƒ–å¸‚å ´: {', '.join(stats['active_markets'])}")
        print(f"   ç·äºˆæ¸¬å›æ•°: {stats['total_predictions']}")
        print(f"   ç·ç›¸é–¢åˆ†æ: {stats['total_correlations']}")
        print(f"   ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹: {metrics['system_health_score']:.1%}")

        if metrics['prediction_latency']:
            avg_latency = np.mean(metrics['prediction_latency'][-10:])
            print(f"   å¹³å‡äºˆæ¸¬æ™‚é–“: {avg_latency:.1f}ms")

    async def _shutdown_system(self):
        """ã‚·ã‚¹ãƒ†ãƒ åœæ­¢å‡¦ç†"""

        print("\nğŸ”„ ã‚·ã‚¹ãƒ†ãƒ åœæ­¢å‡¦ç†ä¸­...")
        self.is_running = False

        try:
            # ãƒ‡ãƒ¼ã‚¿åé›†åœæ­¢
            if hasattr(self.forex_collector, 'cleanup'):
                await self.forex_collector.cleanup()
            if hasattr(self.crypto_collector, 'cleanup'):
                await self.crypto_collector.cleanup()

            print("âœ… ãƒ‡ãƒ¼ã‚¿åé›†ã‚·ã‚¹ãƒ†ãƒ åœæ­¢å®Œäº†")

        except Exception as e:
            logger.error(f"Shutdown error: {e}")

        # æœ€çµ‚çµ±è¨ˆè¡¨ç¤º
        self._display_final_report()

    def _display_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º"""

        stats = self.system_stats
        metrics = self.performance_metrics

        print("\n" + "=" * 70)
        print("ğŸŒ GLOBAL TRADING ENGINE - æœ€çµ‚é‹ç”¨ãƒ¬ãƒãƒ¼ãƒˆ")
        print("=" * 70)

        print(f"é‹ç”¨æœŸé–“: {stats['start_time']} ï½ {datetime.now()}")
        print(f"ç·ç¨¼åƒæ™‚é–“: {stats['uptime_hours']:.2f} æ™‚é–“")

        print("\nğŸ“ˆ å‡¦ç†çµ±è¨ˆ:")
        print(f"  âœ… ç·AIäºˆæ¸¬å›æ•°: {stats['total_predictions']:,}")
        print(f"  âœ… ç·ç›¸é–¢åˆ†æå›æ•°: {stats['total_correlations']:,}")
        print(f"  âœ… ãƒ‡ãƒ¼ã‚¿åé›†ãƒ¬ãƒ¼ãƒˆ: {metrics['data_collection_rate']}/cycle")

        print("\nâš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™:")
        if metrics['prediction_latency']:
            avg_latency = np.mean(metrics['prediction_latency'])
            min_latency = np.min(metrics['prediction_latency'])
            max_latency = np.max(metrics['prediction_latency'])
            print(f"  AIäºˆæ¸¬ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·: å¹³å‡ {avg_latency:.1f}ms (ç¯„å›²: {min_latency:.1f}-{max_latency:.1f}ms)")

        if metrics['correlation_calc_time']:
            avg_corr_time = np.mean(metrics['correlation_calc_time'])
            print(f"  ç›¸é–¢åˆ†ææ™‚é–“: å¹³å‡ {avg_corr_time:.1f}ms")

        print(f"  æœ€çµ‚ãƒ˜ãƒ«ã‚¹ã‚¹ã‚³ã‚¢: {metrics['system_health_score']:.1%}")

        print("\nğŸ† é‹ç”¨åˆ¤å®š:")
        if stats['uptime_hours'] >= 0.95 and metrics['system_health_score'] >= 0.8:
            grade = "EXCELLENT - 24æ™‚é–“é‹ç”¨å¯¾å¿œ"
            emoji = "ğŸŒŸ"
        elif stats['uptime_hours'] >= 0.8 and metrics['system_health_score'] >= 0.7:
            grade = "GOOD - å®Ÿç”¨ãƒ¬ãƒ™ãƒ«é”æˆ"
            emoji = "âœ…"
        elif stats['uptime_hours'] >= 0.5:
            grade = "ACCEPTABLE - åŸºæœ¬æ©Ÿèƒ½ç¢ºèª"
            emoji = "âš ï¸"
        else:
            grade = "NEEDS IMPROVEMENT - è¦æ”¹å–„"
            emoji = "âŒ"

        print(f"  {emoji} ç·åˆè©•ä¾¡: {grade}")

        print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
        print("  â€¢ æœ¬æ ¼é‹ç”¨ã«ã¯ãƒªã‚¢ãƒ«APIæ¥ç¶šãŒå¿…è¦")
        print("  â€¢ é«˜é »åº¦å–å¼•ã«ã¯å°‚ç”¨ã‚¤ãƒ³ãƒ•ãƒ©æ¨å¥¨")
        print("  â€¢ 24æ™‚é–“ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆä½“åˆ¶æ§‹ç¯‰")
        print("  â€¢ å„å¸‚å ´æ³•è¦åˆ¶ã¸ã®å¯¾å¿œç¢ºèª")

        print("\n" + "=" * 70)
        print("ğŸš€ Global Trading Engine ãƒ†ã‚¹ãƒˆå®Œäº†ï¼")
        print("=" * 70)

async def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""

    # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«è¨­å®š
    logging.getLogger().setLevel(logging.INFO)

    try:
        # Global Trading Engine èµ·å‹•
        engine = GlobalTradingEngine()

        # 1æ™‚é–“ï¼ˆå®Ÿéš›ã¯çŸ­ç¸®ç‰ˆã§5åˆ†ï¼‰ã®24æ™‚é–“ã‚·ã‚¹ãƒ†ãƒ ãƒ‡ãƒ¢
        demo_duration = 5.0 / 60  # 5åˆ† = 0.083æ™‚é–“

        await engine.start_24h_operation(duration_hours=demo_duration)

        return 0

    except KeyboardInterrupt:
        print("\n\nã‚·ã‚¹ãƒ†ãƒ é‹ç”¨ãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 2
    except Exception as e:
        print(f"\nâŒ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()
        return 3

if __name__ == "__main__":
    exit_code = asyncio.run(main())
    exit(exit_code)
