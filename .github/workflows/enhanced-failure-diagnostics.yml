#==============================================================================
# Enhanced Failure Diagnostics - Issue #440
# Advanced error analysis and debugging information collection
#==============================================================================

name: ðŸ” Enhanced Failure Diagnostics

on:
  workflow_call:
    inputs:
      failure-context:
        description: 'Context of the failure'
        required: true
        type: string
      collect-logs:
        description: 'Collect detailed logs'
        required: false
        default: true
        type: boolean
      analyze-performance:
        description: 'Include performance analysis'
        required: false
        default: false
        type: boolean

  # Trigger on workflow failure
  workflow_run:
    workflows: ["ðŸš€ Optimized Main CI", "Main CI (Simplified)"]
    types: [completed]

jobs:
  #------------------------------------------------------------------------------
  # Failure Detection and Context Analysis
  #------------------------------------------------------------------------------
  failure-detection:
    name: ðŸš¨ Failure Detection
    runs-on: ubuntu-latest
    if: github.event.workflow_run.conclusion == 'failure' || always()
    timeout-minutes: 5
    outputs:
      has-failures: ${{ steps.analyze.outputs.has-failures }}
      failure-summary: ${{ steps.analyze.outputs.summary }}
      critical-failures: ${{ steps.analyze.outputs.critical }}
    steps:
      - name: Analyze workflow failure
        id: analyze
        uses: actions/github-script@v7
        with:
          script: |
            let hasFailures = false;
            let failureSummary = '';
            let criticalFailures = false;

            if (context.eventName === 'workflow_run') {
              const workflowRun = context.payload.workflow_run;

              if (workflowRun.conclusion === 'failure') {
                hasFailures = true;

                // Get job details
                const jobs = await github.rest.actions.listJobsForWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: workflowRun.id
                });

                const failedJobs = jobs.data.jobs.filter(job => job.conclusion === 'failure');

                failureSummary = `Workflow "${workflowRun.name}" failed with ${failedJobs.length} failed jobs:\n`;

                for (const job of failedJobs) {
                  failureSummary += `- ${job.name}: ${job.conclusion}\n`;

                  // Check for critical failures
                  if (job.name.includes('security') || job.name.includes('test')) {
                    criticalFailures = true;
                  }
                }

                console.log('Failure detected:', failureSummary);
              }
            }

            core.setOutput('has-failures', hasFailures);
            core.setOutput('summary', failureSummary);
            core.setOutput('critical', criticalFailures);

            return {
              hasFailures,
              failureSummary,
              criticalFailures
            };

  #------------------------------------------------------------------------------
  # Comprehensive Log Collection
  #------------------------------------------------------------------------------
  log-collection:
    name: ðŸ“‹ Log Collection
    runs-on: ubuntu-latest
    needs: failure-detection
    if: needs.failure-detection.outputs.has-failures == 'true' && inputs.collect-logs
    timeout-minutes: 8
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Collect system information
        run: |
          mkdir -p diagnostic-logs

          echo "## System Information" > diagnostic-logs/system-info.md
          echo "- **OS**: $(uname -a)" >> diagnostic-logs/system-info.md
          echo "- **Date**: $(date -u)" >> diagnostic-logs/system-info.md
          echo "- **GitHub Event**: ${{ github.event_name }}" >> diagnostic-logs/system-info.md
          echo "- **Repository**: ${{ github.repository }}" >> diagnostic-logs/system-info.md
          echo "- **Branch**: ${{ github.ref }}" >> diagnostic-logs/system-info.md
          echo "- **Commit**: ${{ github.sha }}" >> diagnostic-logs/system-info.md
          echo "- **Runner**: ${{ runner.os }}" >> diagnostic-logs/system-info.md

          # Memory and disk usage
          echo "" >> diagnostic-logs/system-info.md
          echo "### Resource Usage" >> diagnostic-logs/system-info.md
          echo '```' >> diagnostic-logs/system-info.md
          free -h >> diagnostic-logs/system-info.md || echo "free command not available"
          echo "" >> diagnostic-logs/system-info.md
          df -h >> diagnostic-logs/system-info.md || echo "df command not available"
          echo '```' >> diagnostic-logs/system-info.md

      - name: Collect GitHub Actions logs
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            if (context.eventName === 'workflow_run') {
              const workflowRun = context.payload.workflow_run;

              try {
                // Get workflow jobs
                const jobs = await github.rest.actions.listJobsForWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: workflowRun.id
                });

                let logSummary = `# GitHub Actions Logs Summary\n\n`;
                logSummary += `**Workflow**: ${workflowRun.name}\n`;
                logSummary += `**Run ID**: ${workflowRun.id}\n`;
                logSummary += `**Trigger**: ${workflowRun.event}\n\n`;

                for (const job of jobs.data.jobs) {
                  logSummary += `## Job: ${job.name}\n`;
                  logSummary += `- **Status**: ${job.conclusion || 'in_progress'}\n`;
                  logSummary += `- **Started**: ${job.started_at}\n`;
                  logSummary += `- **Duration**: ${job.started_at && job.completed_at ?
                    Math.round((new Date(job.completed_at) - new Date(job.started_at)) / 1000) : 'N/A'} seconds\n`;

                  if (job.conclusion === 'failure') {
                    logSummary += `- **âš ï¸ FAILED**: This job failed\n`;

                    try {
                      // Get job logs
                      const logs = await github.rest.actions.downloadJobLogsForWorkflowRun({
                        owner: context.repo.owner,
                        repo: context.repo.repo,
                        job_id: job.id
                      });

                      // Note: logs.data is a compressed stream - we'll note this for manual inspection
                      logSummary += `- **Logs**: Available for download (job_id: ${job.id})\n`;
                    } catch (error) {
                      logSummary += `- **Logs**: Failed to retrieve (${error.message})\n`;
                    }
                  }
                  logSummary += `\n`;
                }

                fs.writeFileSync('diagnostic-logs/github-actions-logs.md', logSummary);

              } catch (error) {
                console.error('Error collecting GitHub Actions logs:', error);
                fs.writeFileSync('diagnostic-logs/github-actions-error.txt',
                  `Error collecting logs: ${error.message}\n${error.stack}`);
              }
            }

      - name: Environment diagnostics
        run: |
          echo "## Environment Diagnostics" > diagnostic-logs/environment.md

          # Python environment
          if command -v python3 &> /dev/null; then
            echo "### Python Environment" >> diagnostic-logs/environment.md
            echo '```' >> diagnostic-logs/environment.md
            python3 --version >> diagnostic-logs/environment.md
            pip --version >> diagnostic-logs/environment.md || echo "pip not available"
            pip list --format=freeze | head -20 >> diagnostic-logs/environment.md 2>/dev/null || echo "pip list failed"
            echo '```' >> diagnostic-logs/environment.md
          fi

          # Docker environment
          if command -v docker &> /dev/null; then
            echo "### Docker Environment" >> diagnostic-logs/environment.md
            echo '```' >> diagnostic-logs/environment.md
            docker --version >> diagnostic-logs/environment.md
            docker images --format "table {{.Repository}}\t{{.Tag}}\t{{.Size}}" | head -10 >> diagnostic-logs/environment.md 2>/dev/null || echo "docker images failed"
            echo '```' >> diagnostic-logs/environment.md
          fi

          # Git environment
          echo "### Git Environment" >> diagnostic-logs/environment.md
          echo '```' >> diagnostic-logs/environment.md
          git --version >> diagnostic-logs/environment.md
          git log --oneline -5 >> diagnostic-logs/environment.md || echo "git log failed"
          echo '```' >> diagnostic-logs/environment.md

      - name: Collect test artifacts
        if: always()
        run: |
          # Look for common test artifacts
          find . -name "*.xml" -o -name "*.json" -o -name "*.log" | grep -E "(test|coverage|report)" | head -20 > diagnostic-logs/test-artifacts-list.txt || echo "No test artifacts found"

          # Collect pytest cache info
          if [ -d ".pytest_cache" ]; then
            echo "## Pytest Cache Information" > diagnostic-logs/pytest-info.md
            echo "Cache directory exists: .pytest_cache" >> diagnostic-logs/pytest-info.md
            find .pytest_cache -type f | head -10 >> diagnostic-logs/pytest-info.md || echo "Failed to list pytest cache"
          fi

          # Look for coverage files
          if compgen -G "coverage*.xml" > /dev/null || compgen -G ".coverage*" > /dev/null; then
            echo "Coverage files found:" > diagnostic-logs/coverage-info.txt
            ls -la coverage* .coverage* >> diagnostic-logs/coverage-info.txt 2>/dev/null || echo "Failed to list coverage files"
          fi

      - name: Upload diagnostic logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: failure-diagnostic-logs-${{ github.run_id }}
          path: diagnostic-logs/
          retention-days: 14

  #------------------------------------------------------------------------------
  # Performance Analysis
  #------------------------------------------------------------------------------
  performance-analysis:
    name: ðŸ“ˆ Performance Analysis
    runs-on: ubuntu-latest
    needs: failure-detection
    if: needs.failure-detection.outputs.has-failures == 'true' && inputs.analyze-performance
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Analyze workflow performance
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            if (context.eventName === 'workflow_run') {
              const workflowRun = context.payload.workflow_run;

              try {
                const jobs = await github.rest.actions.listJobsForWorkflowRun({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  run_id: workflowRun.id
                });

                let perfAnalysis = `# Performance Analysis Report\n\n`;
                perfAnalysis += `**Workflow**: ${workflowRun.name}\n`;
                perfAnalysis += `**Total Duration**: ${workflowRun.updated_at && workflowRun.created_at ?
                  Math.round((new Date(workflowRun.updated_at) - new Date(workflowRun.created_at)) / 1000 / 60) : 'N/A'} minutes\n\n`;

                // Analyze job performance
                const jobPerformance = [];
                for (const job of jobs.data.jobs) {
                  if (job.started_at && job.completed_at) {
                    const duration = Math.round((new Date(job.completed_at) - new Date(job.started_at)) / 1000);
                    jobPerformance.push({ name: job.name, duration, status: job.conclusion });
                  }
                }

                // Sort by duration (slowest first)
                jobPerformance.sort((a, b) => b.duration - a.duration);

                perfAnalysis += `## Job Performance (sorted by duration)\n\n`;
                perfAnalysis += `| Job | Duration (s) | Status |\n`;
                perfAnalysis += `|-----|-------------|--------|\n`;

                for (const job of jobPerformance) {
                  const statusIcon = job.status === 'success' ? 'âœ…' : job.status === 'failure' ? 'âŒ' : 'âš ï¸';
                  perfAnalysis += `| ${job.name} | ${job.duration} | ${statusIcon} ${job.status} |\n`;
                }

                // Performance recommendations
                perfAnalysis += `\n## Performance Recommendations\n\n`;

                const slowJobs = jobPerformance.filter(job => job.duration > 300); // > 5 minutes
                if (slowJobs.length > 0) {
                  perfAnalysis += `### ðŸŒ Slow Jobs (>5 minutes)\n`;
                  for (const job of slowJobs) {
                    perfAnalysis += `- **${job.name}**: ${Math.round(job.duration / 60)} minutes\n`;
                    perfAnalysis += `  - Consider parallelization or caching improvements\n`;
                  }
                }

                const failedJobs = jobPerformance.filter(job => job.status === 'failure');
                if (failedJobs.length > 0) {
                  perfAnalysis += `\n### âŒ Failed Jobs\n`;
                  for (const job of failedJobs) {
                    perfAnalysis += `- **${job.name}**: Failed after ${job.duration} seconds\n`;
                  }
                }

                // CI time analysis
                const totalDuration = Math.max(...jobPerformance.map(j => j.duration));
                perfAnalysis += `\n### â±ï¸ CI Time Analysis\n`;
                perfAnalysis += `- **Longest job**: ${Math.round(totalDuration / 60)} minutes\n`;
                perfAnalysis += `- **Target CI time**: 2-3 minutes\n`;

                if (totalDuration > 180) { // > 3 minutes
                  perfAnalysis += `- **âš ï¸ Exceeds target**: Consider optimization\n`;
                  perfAnalysis += `  - Enable aggressive caching\n`;
                  perfAnalysis += `  - Increase parallelization\n`;
                  perfAnalysis += `  - Reduce test scope for non-critical changes\n`;
                } else {
                  perfAnalysis += `- **âœ… Within target range**\n`;
                }

                fs.writeFileSync('performance-analysis.md', perfAnalysis);

              } catch (error) {
                console.error('Performance analysis failed:', error);
                fs.writeFileSync('performance-analysis-error.txt',
                  `Performance analysis failed: ${error.message}`);
              }
            }

      - name: Upload performance analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-analysis-${{ github.run_id }}
          path: |
            performance-analysis.md
            performance-analysis-error.txt
          retention-days: 7

  #------------------------------------------------------------------------------
  # Error Analysis and Reporting
  #------------------------------------------------------------------------------
  error-analysis:
    name: ðŸ”¬ Error Analysis
    runs-on: ubuntu-latest
    needs: [failure-detection, log-collection]
    if: always() && needs.failure-detection.outputs.has-failures == 'true'
    timeout-minutes: 7
    steps:
      - name: Download diagnostic logs
        uses: actions/download-artifact@v4
        with:
          name: failure-diagnostic-logs-${{ github.run_id }}
          path: diagnostic-logs/

      - name: Analyze common failure patterns
        run: |
          mkdir -p analysis-results

          echo "# Error Analysis Report" > analysis-results/error-analysis.md
          echo "Generated: $(date -u)" >> analysis-results/error-analysis.md
          echo "" >> analysis-results/error-analysis.md

          # Common error patterns
          echo "## Common Error Patterns" >> analysis-results/error-analysis.md

          # Check for import errors
          if grep -r "ImportError\|ModuleNotFoundError" diagnostic-logs/ 2>/dev/null; then
            echo "### ðŸ Import/Module Errors Found" >> analysis-results/error-analysis.md
            echo '```' >> analysis-results/error-analysis.md
            grep -r "ImportError\|ModuleNotFoundError" diagnostic-logs/ | head -5 >> analysis-results/error-analysis.md 2>/dev/null
            echo '```' >> analysis-results/error-analysis.md
            echo "**Recommendation**: Check dependencies and Python path configuration" >> analysis-results/error-analysis.md
            echo "" >> analysis-results/error-analysis.md
          fi

          # Check for permission errors
          if grep -r "Permission denied\|PermissionError" diagnostic-logs/ 2>/dev/null; then
            echo "### ðŸ”’ Permission Errors Found" >> analysis-results/error-analysis.md
            echo "**Recommendation**: Check file permissions and user context" >> analysis-results/error-analysis.md
            echo "" >> analysis-results/error-analysis.md
          fi

          # Check for timeout errors
          if grep -r "timeout\|TimeoutError" diagnostic-logs/ 2>/dev/null; then
            echo "### â° Timeout Errors Found" >> analysis-results/error-analysis.md
            echo "**Recommendation**: Increase timeout values or optimize slow operations" >> analysis-results/error-analysis.md
            echo "" >> analysis-results/error-analysis.md
          fi

          # Check for memory errors
          if grep -r "MemoryError\|Out of memory" diagnostic-logs/ 2>/dev/null; then
            echo "### ðŸ’¾ Memory Errors Found" >> analysis-results/error-analysis.md
            echo "**Recommendation**: Optimize memory usage or increase available memory" >> analysis-results/error-analysis.md
            echo "" >> analysis-results/error-analysis.md
          fi

          echo "## Diagnostic Summary" >> analysis-results/error-analysis.md
          echo "- **System Info**: $([ -f diagnostic-logs/system-info.md ] && echo 'Available' || echo 'Not collected')" >> analysis-results/error-analysis.md
          echo "- **Environment**: $([ -f diagnostic-logs/environment.md ] && echo 'Available' || echo 'Not collected')" >> analysis-results/error-analysis.md
          echo "- **GitHub Logs**: $([ -f diagnostic-logs/github-actions-logs.md ] && echo 'Available' || echo 'Not collected')" >> analysis-results/error-analysis.md

      - name: Generate failure report
        run: |
          echo "# Comprehensive Failure Report" > analysis-results/failure-report.md
          echo "**Generated**: $(date -u)" >> analysis-results/failure-report.md
          echo "**Context**: ${{ inputs.failure-context || 'Automated detection' }}" >> analysis-results/failure-report.md
          echo "**Critical**: ${{ needs.failure-detection.outputs.critical-failures }}" >> analysis-results/failure-report.md
          echo "" >> analysis-results/failure-report.md

          echo "## Failure Summary" >> analysis-results/failure-report.md
          echo "${{ needs.failure-detection.outputs.failure-summary }}" >> analysis-results/failure-report.md
          echo "" >> analysis-results/failure-report.md

          echo "## Next Steps" >> analysis-results/failure-report.md
          if [[ "${{ needs.failure-detection.outputs.critical-failures }}" == "true" ]]; then
            echo "ðŸš¨ **CRITICAL**: Immediate attention required" >> analysis-results/failure-report.md
            echo "1. Review security or test failures immediately" >> analysis-results/failure-report.md
            echo "2. Consider reverting recent changes if needed" >> analysis-results/failure-report.md
            echo "3. Run diagnostics locally before retrying" >> analysis-results/failure-report.md
          else
            echo "âš ï¸ **NON-CRITICAL**: Review and fix when convenient" >> analysis-results/failure-report.md
            echo "1. Review diagnostic logs in artifacts" >> analysis-results/failure-report.md
            echo "2. Apply recommended fixes" >> analysis-results/failure-report.md
            echo "3. Consider caching or performance improvements" >> analysis-results/failure-report.md
          fi

          echo "" >> analysis-results/failure-report.md
          echo "## Available Artifacts" >> analysis-results/failure-report.md
          echo "- Diagnostic logs: failure-diagnostic-logs-${{ github.run_id }}" >> analysis-results/failure-report.md
          echo "- Error analysis: failure-error-analysis-${{ github.run_id }}" >> analysis-results/failure-report.md
          if [[ "${{ inputs.analyze-performance }}" == "true" ]]; then
            echo "- Performance analysis: performance-analysis-${{ github.run_id }}" >> analysis-results/failure-report.md
          fi

      - name: Upload error analysis
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: failure-error-analysis-${{ github.run_id }}
          path: analysis-results/
          retention-days: 30

      - name: Create GitHub issue for critical failures
        if: needs.failure-detection.outputs.critical-failures == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');

            let issueBody = `# ðŸš¨ Critical CI Failure Detected\n\n`;
            issueBody += `**Workflow**: ${{ github.workflow }}\n`;
            issueBody += `**Run ID**: ${{ github.run_id }}\n`;
            issueBody += `**Commit**: ${{ github.sha }}\n`;
            issueBody += `**Branch**: ${{ github.ref }}\n\n`;

            issueBody += `## Failure Summary\n`;
            issueBody += `${{ needs.failure-detection.outputs.failure-summary }}\n\n`;

            issueBody += `## Available Diagnostics\n`;
            issueBody += `- [Workflow Run](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})\n`;
            issueBody += `- Diagnostic artifacts available in workflow run\n\n`;

            issueBody += `## Immediate Actions Required\n`;
            issueBody += `- [ ] Review diagnostic logs\n`;
            issueBody += `- [ ] Identify root cause\n`;
            issueBody += `- [ ] Apply fix or revert changes\n`;
            issueBody += `- [ ] Verify fix with test run\n\n`;

            issueBody += `*This issue was created automatically by the Enhanced Failure Diagnostics system.*`;

            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: `ðŸš¨ Critical CI Failure - ${new Date().toISOString().split('T')[0]}`,
              body: issueBody,
              labels: ['bug', 'ci-failure', 'high-priority', 'automated'],
              assignees: ['kaenozu']
            });

#==============================================================================
# Enhanced Failure Diagnostics Features:
#
# 1. ðŸš¨ Automatic Failure Detection:
#    - Monitor workflow conclusions
#    - Identify critical vs non-critical failures
#    - Context-aware analysis
#
# 2. ðŸ“‹ Comprehensive Log Collection:
#    - System information gathering
#    - Environment diagnostics
#    - GitHub Actions logs aggregation
#    - Test artifacts collection
#
# 3. ðŸ”¬ Intelligent Error Analysis:
#    - Common error pattern detection
#    - Failure categorization
#    - Automated recommendations
#
# 4. ðŸ“ˆ Performance Analysis:
#    - Job duration tracking
#    - Bottleneck identification
#    - CI time optimization recommendations
#
# 5. ðŸŽ¯ Automated Issue Creation:
#    - Critical failure alerts
#    - Structured issue templates
#    - Actionable next steps
#
# Expected diagnosis time improvement: 15min â†’ 3-5min
#==============================================================================