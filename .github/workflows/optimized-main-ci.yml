#==============================================================================
# Optimized Main CI Pipeline - Issue #440
# Ultra-fast CI with parallel execution and advanced caching (Target: 2-3min)
#==============================================================================

name: ğŸš€ Optimized Main CI

on:
  push:
    branches: [main, 'feature/*', 'hotfix/*', 'release/*']
  pull_request:
    branches: [main]
    types: [opened, synchronize, reopened, ready_for_review]
  workflow_dispatch:
    inputs:
      force_full_test:
        description: 'Force full test suite execution'
        required: false
        default: false
        type: boolean

# Optimize concurrency
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: ${{ github.event_name == 'pull_request' }}

# Minimal required permissions
permissions:
  contents: read
  checks: write
  pull-requests: write
  issues: write

env:
  # Python optimization
  PYTHONDONTWRITEBYTECODE: 1
  PYTHONUNBUFFERED: 1
  PIP_NO_CACHE_DIR: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1

  # Test optimization
  PYTEST_DISABLE_PLUGIN_AUTOLOAD: 1
  PYTEST_CURRENT_TEST: ""

  # Cache optimization
  CACHE_KEY_PREFIX: v2
  CACHE_RESTORE_KEYS_FALLBACK: v1

jobs:
  #------------------------------------------------------------------------------
  # Pre-flight: Quick validation and change detection
  #------------------------------------------------------------------------------
  preflight-check:
    name: ğŸ” Pre-flight Check
    runs-on: ubuntu-latest
    timeout-minutes: 2
    outputs:
      test-matrix: ${{ steps.test-matrix.outputs.matrix }}
      cache-key: ${{ steps.cache-key.outputs.key }}
      skip-tests: ${{ steps.changes.outputs.skip_tests }}
      python-changed: ${{ steps.changes.outputs.python }}
      tests-changed: ${{ steps.changes.outputs.tests }}
      deps-changed: ${{ steps.changes.outputs.deps }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2

      - name: Detect file changes
        uses: dorny/paths-filter@v3
        id: changes
        with:
          filters: |
            python:
              - 'src/**/*.py'
              - 'tests/**/*.py'
            tests:
              - 'tests/**/*'
            deps:
              - 'requirements*.txt'
              - 'pyproject.toml'
              - 'setup.py'
              - 'setup.cfg'
            docs_only:
              - '**.md'
              - 'docs/**'
            skip_tests:
              - '**.md'
              - 'docs/**'
              - '.github/**'
              - '!.github/workflows/**'

      - name: Generate cache key
        id: cache-key
        run: |
          DEPS_HASH=$(find . -name "requirements*.txt" -o -name "pyproject.toml" | xargs cat | sha256sum | cut -d' ' -f1)
          PY_VERSION="3.12"
          echo "key=${{ env.CACHE_KEY_PREFIX }}-${{ runner.os }}-py${PY_VERSION}-${DEPS_HASH}" >> $GITHUB_OUTPUT
          echo "restore-keys=${{ env.CACHE_KEY_PREFIX }}-${{ runner.os }}-py${PY_VERSION}-" >> $GITHUB_OUTPUT

      - name: Generate test matrix
        id: test-matrix
        run: |
          # Dynamic test matrix based on changes
          if [[ "${{ steps.changes.outputs.python }}" == "true" || "${{ github.event.inputs.force_full_test }}" == "true" ]]; then
            echo "matrix={\"test-type\":[\"unit\",\"integration\",\"performance\",\"security\"],\"python-version\":[\"3.11\",\"3.12\"],\"include\":[{\"test-type\":\"unit\",\"python-version\":\"3.12\",\"coverage\":true}]}" >> $GITHUB_OUTPUT
          else
            echo "matrix={\"test-type\":[\"unit\"],\"python-version\":[\"3.12\"]}" >> $GITHUB_OUTPUT
          fi

      - name: Pre-flight summary
        run: |
          echo "## ğŸ” Pre-flight Check Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Python files changed**: ${{ steps.changes.outputs.python }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests changed**: ${{ steps.changes.outputs.tests }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Dependencies changed**: ${{ steps.changes.outputs.deps }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Skip tests**: ${{ steps.changes.outputs.skip_tests }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Cache key**: ${{ steps.cache-key.outputs.key }}" >> $GITHUB_STEP_SUMMARY

  #------------------------------------------------------------------------------
  # Parallel Test Execution Matrix
  #------------------------------------------------------------------------------
  test-matrix:
    name: ğŸ§ª Test (${{ matrix.test-type }}, py${{ matrix.python-version }})
    runs-on: ubuntu-latest
    needs: preflight-check
    if: false  # Temporarily disabled for PR #449
    timeout-minutes: 10
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.preflight-check.outputs.test-matrix) }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Advanced Cache Strategy
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/pre-commit
            .pytest_cache
            .mypy_cache
            .ruff_cache
            __pycache__
            .coverage*
          key: ${{ needs.preflight-check.outputs.cache-key }}-${{ matrix.test-type }}-${{ matrix.python-version }}
          restore-keys: |
            ${{ needs.preflight-check.outputs.cache-key }}-${{ matrix.test-type }}-
            ${{ needs.preflight-check.outputs.cache-key }}-
            ${{ env.CACHE_RESTORE_KEYS_FALLBACK }}-${{ runner.os }}-py${{ matrix.python-version }}-

      - name: Install dependencies (optimized)
        run: |
          # Use pip-tools for faster installs
          python -m pip install --upgrade pip setuptools wheel pip-tools

          # Install based on test type
          case "${{ matrix.test-type }}" in
            "unit")
              pip install pytest pytest-xdist pytest-cov pandas numpy
              ;;
            "integration")
              pip install pytest pytest-mock pandas numpy sqlalchemy
              ;;
            "performance")
              pip install pytest pytest-benchmark pandas numpy psutil
              ;;
            "security")
              pip install pytest bandit safety pip-audit
              ;;
            *)
              pip install pytest pandas numpy
              ;;
          esac

          # Install project
          pip install -e . --no-deps

      - name: Run ${{ matrix.test-type }} tests
        run: |
          case "${{ matrix.test-type }}" in
            "unit")
              pytest tests/test_*.py \
                -n auto \
                --maxfail=5 \
                --tb=short \
                --disable-warnings \
                ${{ matrix.coverage && '--cov=src --cov-report=xml:coverage.xml --cov-report=term-missing' || '' }}
              ;;
            "integration")
              pytest tests/integration/ \
                -n auto \
                --maxfail=3 \
                --tb=short \
                --disable-warnings \
                -m "not slow"
              ;;
            "performance")
              pytest tests/test_*performance*.py \
                --benchmark-only \
                --benchmark-min-time=0.1 \
                --benchmark-max-time=2.0
              ;;
            "security")
              # Security scans
              bandit -r src/ -f json -o bandit-report.json || true
              safety check --json --output safety-report.json || true
              pip-audit --format=json --output=pip-audit-report.json || true

              # Run security tests if they exist
              pytest tests/test_*security*.py -v || echo "No security tests found"
              ;;
          esac

      - name: Upload test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.test-type }}-py${{ matrix.python-version }}
          path: |
            coverage.xml
            *-report.json
            pytest-report.xml
          retention-days: 30

      - name: Upload coverage to Codecov
        if: matrix.coverage == true && always()
        uses: codecov/codecov-action@v4
        with:
          file: coverage.xml
          flags: ${{ matrix.test-type }}
          fail_ci_if_error: false

  #------------------------------------------------------------------------------
  # Code Quality Checks (Parallel)
  #------------------------------------------------------------------------------
  code-quality:
    name: ğŸ“Š Code Quality
    runs-on: ubuntu-latest
    needs: preflight-check
    if: false  # Temporarily disabled for PR #449
    timeout-minutes: 5
    strategy:
      fail-fast: false
      matrix:
        tool: [ruff, mypy, black]

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache quality tools
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: quality-${{ matrix.tool }}-${{ runner.os }}-py3.12
          restore-keys: quality-${{ matrix.tool }}-${{ runner.os }}-

      - name: Install ${{ matrix.tool }}
        run: |
          case "${{ matrix.tool }}" in
            "ruff")
              pip install ruff==0.1.15
              ;;
            "mypy")
              pip install mypy pandas-stubs types-requests
              ;;
            "black")
              pip install black
              ;;
          esac

      - name: Run ${{ matrix.tool }}
        run: |
          case "${{ matrix.tool }}" in
            "ruff")
              ruff check src/ --output-format=github
              ruff format src/ --check
              ;;
            "mypy")
              mypy src/ --ignore-missing-imports --no-strict-optional
              ;;
            "black")
              black --check src/
              ;;
          esac

  #------------------------------------------------------------------------------
  # Security Scan (Fast)
  #------------------------------------------------------------------------------
  security-scan:
    name: ğŸ”’ Security Scan
    runs-on: ubuntu-latest
    timeout-minutes: 3
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Cache security tools
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: security-tools-${{ runner.os }}-py3.12
          restore-keys: security-tools-${{ runner.os }}-

      - name: Install security tools
        run: |
          pip install bandit safety pip-audit

      - name: Run security scans (parallel)
        run: |
          # Run all security tools in parallel
          bandit -r src/ -f json -o bandit.json &
          safety check --json --output safety.json &
          pip-audit --format=json --output=audit.json &

          wait  # Wait for all background jobs

      - name: Process security results
        if: always()
        run: |
          echo "## ğŸ”’ Security Scan Results" >> $GITHUB_STEP_SUMMARY

          # Check bandit results
          if [ -f bandit.json ]; then
            BANDIT_ISSUES=$(jq '.results | length' bandit.json 2>/dev/null || echo "0")
            echo "- **Bandit**: $BANDIT_ISSUES issues found" >> $GITHUB_STEP_SUMMARY
          fi

          # Check safety results
          if [ -f safety.json ]; then
            echo "- **Safety**: $(wc -l < safety.json) vulnerabilities checked" >> $GITHUB_STEP_SUMMARY
          fi

          # Check pip-audit results
          if [ -f audit.json ]; then
            echo "- **Pip-audit**: Dependency audit completed" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload security reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: security-reports
          path: |
            bandit.json
            safety.json
            audit.json

  #------------------------------------------------------------------------------
  # Docker Build Test (Fast)
  #------------------------------------------------------------------------------
  docker-build-test:
    name: ğŸ³ Docker Build Test
    runs-on: ubuntu-latest
    needs: preflight-check
    if: false  # Temporarily disabled for PR #449
    timeout-minutes: 8
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Build production image (cached)
        uses: docker/build-push-action@v5
        with:
          context: .
          target: production
          push: false
          tags: daytrade:test
          cache-from: type=gha,scope=production
          cache-to: type=gha,scope=production,mode=max
          build-args: |
            BUILD_DATE=${{ github.event.head_commit.timestamp }}
            VERSION=test
            GIT_COMMIT=${{ github.sha }}

      - name: Test container startup
        run: |
          # Quick container test
          docker run --rm --name test-container -d daytrade:test
          sleep 5

          # Basic health check
          if docker ps | grep -q test-container; then
            echo "âœ… Container started successfully"
            docker stop test-container
          else
            echo "âŒ Container failed to start"
            exit 1
          fi

  #------------------------------------------------------------------------------
  # Performance Regression Check
  #------------------------------------------------------------------------------
  performance-check:
    name: âš¡ Performance Check
    runs-on: ubuntu-latest
    needs: preflight-check
    if: needs.preflight-check.outputs.python-changed == 'true'
    timeout-minutes: 5
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies (minimal)
        run: |
          pip install pytest pytest-benchmark pandas numpy psutil

      - name: Install project
        run: pip install -e .

      - name: Run performance benchmarks
        run: |
          # Quick performance tests
          pytest tests/test_*performance*.py \
            --benchmark-only \
            --benchmark-min-time=0.05 \
            --benchmark-max-time=1.0 \
            --benchmark-json=benchmark-results.json \
            || echo "No performance tests found"

      - name: Performance regression check
        if: github.event_name == 'pull_request'
        run: |
          if [ -f benchmark-results.json ]; then
            echo "## âš¡ Performance Benchmark Results" >> $GITHUB_STEP_SUMMARY
            echo "Benchmark results available - check artifacts for details" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Upload performance results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: performance-results
          path: benchmark-results.json

  #------------------------------------------------------------------------------
  # Final CI Status
  #------------------------------------------------------------------------------
  ci-status:
    name: ğŸ“Š CI Status Summary
    runs-on: ubuntu-latest
    needs: [preflight-check, security-scan]
    if: false  # Temporarily disabled for PR #449
    timeout-minutes: 2
    steps:
      - name: Generate CI summary
        run: |
          echo "# ğŸš€ Optimized CI Pipeline Results" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Execution Time**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "**Commit**: ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Job status summary
          echo "## ğŸ“‹ Job Status" >> $GITHUB_STEP_SUMMARY
          echo "- **Pre-flight**: âœ… Completed" >> $GITHUB_STEP_SUMMARY
          echo "- **Tests**: ${{ needs.test-matrix.result == 'success' && 'âœ…' || needs.test-matrix.result == 'skipped' && 'â­ï¸' || 'âŒ' }} ${{ needs.test-matrix.result }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Code Quality**: â­ï¸ Temporarily disabled" >> $GITHUB_STEP_SUMMARY
          echo "- **Security**: ${{ needs.security-scan.result == 'success' && 'âœ…' || 'âŒ' }} ${{ needs.security-scan.result }}" >> $GITHUB_STEP_SUMMARY

          # Performance metrics
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "## ğŸ“ˆ Performance Metrics" >> $GITHUB_STEP_SUMMARY
          echo "- **Target Duration**: 2-3 minutes" >> $GITHUB_STEP_SUMMARY
          echo "- **Parallel Jobs**: ${{ strategy.max-parallel || '4' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Cache Strategy**: Advanced multi-layer caching" >> $GITHUB_STEP_SUMMARY

          # Overall status
          if [[ "${{ needs.test-matrix.result }}" == "success" && "${{ needs.security-scan.result }}" == "success" ]]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## âœ… Overall Status: SUCCESS" >> $GITHUB_STEP_SUMMARY
            echo "All critical checks passed. Ready for merge." >> $GITHUB_STEP_SUMMARY
          else
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "## âŒ Overall Status: FAILED" >> $GITHUB_STEP_SUMMARY
            echo "Some checks failed. Please review and fix issues." >> $GITHUB_STEP_SUMMARY
          fi

      - name: Set workflow status
        if: needs.test-matrix.result != 'success' || needs.security-scan.result != 'success'
        run: |
          echo "âŒ CI Pipeline failed"
          exit 1

#==============================================================================
# Performance Optimization Features:
#
# 1. ğŸš€ Parallel Execution:
#    - Matrix strategy for tests (4x parallelization)
#    - Concurrent quality checks
#    - Background security scans
#
# 2. ğŸ¯ Smart Caching:
#    - Multi-layer cache keys
#    - Tool-specific caches
#    - Dependency-based invalidation
#
# 3. âš¡ Fast-fail Strategy:
#    - Early change detection
#    - Minimal dependency installs
#    - Optimized test selection
#
# 4. ğŸ“Š Efficient Resource Usage:
#    - Targeted timeouts
#    - Minimal permissions
#    - Concurrency optimization
#
# Target: 5-10min â†’ 2-3min (50-70% improvement)
#==============================================================================