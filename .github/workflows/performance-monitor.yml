name: üìä Performance Monitor

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  schedule:
    # ÊØéÊó• 06:00 UTC „Å´ÂÆüË°å
    - cron: '0 6 * * *'
  workflow_dispatch:

env:
  # Performance monitoring configuration
  PERFORMANCE_REGRESSION_THRESHOLD: '20'  # Percentage threshold for regression detection
  PERFORMANCE_HISTORY_DAYS: '30'          # Days of history to analyze
  LARGE_FILE_THRESHOLD: '1M'              # Threshold for large file detection
  REPORT_RETENTION_DAYS: '90'             # Artifact retention days

permissions:
  contents: read
  pull-requests: write
  issues: write

jobs:
  ci-performance:
    runs-on: ubuntu-latest
    name: Monitor CI Performance

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Analyze workflow performance
        id: performance
        run: |
          echo "üìä Analyzing CI performance..."

          # ÁèæÂú®„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂêç„ÇíÂãïÁöÑ„Å´ÂèñÂæó
          current_workflow="${{ github.workflow }}"
          echo "Current workflow: $current_workflow"

          # „Çà„ÇäÂ†ÖÁâ¢„Å™„ÉØ„Éº„ÇØ„Éï„É≠„ÉºÂÆüË°å„Éá„Éº„Çø„ÅÆÂèñÂæó
          echo "Fetching workflow performance data..."
          cutoff_date=$(date -d "${{ env.PERFORMANCE_HISTORY_DAYS }} days ago" --iso-8601)

          # „É°„Ç§„É≥CI/CD„Éë„Ç§„Éó„É©„Ç§„É≥Èñ¢ÈÄ£„ÅÆ„ÉØ„Éº„ÇØ„Éï„É≠„Éº„ÇíÂØæË±°„Å®„Åô„Çã
          gh run list --limit 50 --created ">=$cutoff_date" \
            --json databaseId,status,conclusion,createdAt,updatedAt,workflowName \
            --jq '[
              .[] |
              select(
                .workflowName == "üöÄ Main CI/CD Pipeline" or
                .workflowName == "CI/CD Pipeline" or
                .workflowName == "Optimized CI/CD Pipeline" or
                .workflowName == "main-ci" or
                (.workflowName | test("CI|ci"))
              ) |
              select(.status == "completed" and .conclusion == "success") |
              {
                id: .databaseId,
                status: .status,
                conclusion: .conclusion,
                duration: ((.updatedAt | fromdateiso8601) - (.createdAt | fromdateiso8601)),
                workflow: .workflowName,
                created: .createdAt
              }
            ]' > performance-data.json

          echo "üìã Performance data collected:"
          cat performance-data.json | jq 'length' | xargs echo "Total successful runs:"

          # „Çà„ÇäÂ†ÖÁâ¢„Å™Âπ≥ÂùáÂÆüË°åÊôÇÈñìË®àÁÆó
          if [ -s performance-data.json ] && [ "$(jq 'length' performance-data.json)" -gt 0 ]; then
            # Áµ±Ë®àÊÉÖÂ†±„ÅÆË®àÁÆó
            avg_duration=$(jq '[.[].duration] | add / length' performance-data.json)
            min_duration=$(jq '[.[].duration] | min' performance-data.json)
            max_duration=$(jq '[.[].duration] | max' performance-data.json)
            latest_duration=$(jq '.[0].duration // 0' performance-data.json)

            echo "average_duration=$avg_duration" >> $GITHUB_OUTPUT
            echo "min_duration=$min_duration" >> $GITHUB_OUTPUT
            echo "max_duration=$max_duration" >> $GITHUB_OUTPUT
            echo "latest_duration=$latest_duration" >> $GITHUB_OUTPUT
            echo "data_available=true" >> $GITHUB_OUTPUT

            echo "üìà Performance Statistics:"
            echo "  Average CI duration: ${avg_duration}s"
            echo "  Minimum CI duration: ${min_duration}s"
            echo "  Maximum CI duration: ${max_duration}s"
            echo "  Latest CI duration: ${latest_duration}s"
          else
            echo "‚ö†Ô∏è No performance data available"
            echo "average_duration=0" >> $GITHUB_OUTPUT
            echo "min_duration=0" >> $GITHUB_OUTPUT
            echo "max_duration=0" >> $GITHUB_OUTPUT
            echo "latest_duration=0" >> $GITHUB_OUTPUT
            echo "data_available=false" >> $GITHUB_OUTPUT
          fi
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Performance regression check
        if: github.event_name == 'pull_request' && steps.performance.outputs.data_available == 'true'
        id: regression-check
        run: |
          avg_duration=${{ steps.performance.outputs.average_duration }}
          latest_duration=${{ steps.performance.outputs.latest_duration }}
          regression_threshold=${{ env.PERFORMANCE_REGRESSION_THRESHOLD }}

          echo "üìä Performance Regression Analysis:"
          echo "  Average duration: ${avg_duration}s"
          echo "  Latest duration: ${latest_duration}s"
          echo "  Regression threshold: ${regression_threshold}%"

          # „Çà„ÇäÂ†ÖÁâ¢„Å™ÈñæÂÄ§Ë®àÁÆóÔºà„Çº„É≠Èô§ÁÆóÂØæÁ≠ñÂê´„ÇÄÔºâ
          if [ "$(echo "$avg_duration > 0" | bc -l)" = "1" ]; then
            threshold_multiplier=$(echo "1 + $regression_threshold / 100" | bc -l)
            threshold=$(echo "$avg_duration * $threshold_multiplier" | bc -l)
            regression_percentage=$(echo "scale=1; ($latest_duration - $avg_duration) / $avg_duration * 100" | bc -l)

            echo "  Calculated threshold: ${threshold}s"
            echo "  Performance change: ${regression_percentage}%"

            if (( $(echo "$latest_duration > $threshold" | bc -l) )); then
              echo "‚ö†Ô∏è Performance regression detected!"
              echo "regression=true" >> $GITHUB_ENV
              echo "regression_percentage=$regression_percentage" >> $GITHUB_ENV
            else
              echo "‚úÖ No performance regression detected"
              echo "regression=false" >> $GITHUB_ENV
              echo "regression_percentage=$regression_percentage" >> $GITHUB_ENV
            fi
          else
            echo "‚ö†Ô∏è Cannot calculate regression - insufficient baseline data"
            echo "regression=false" >> $GITHUB_ENV
            echo "regression_percentage=0" >> $GITHUB_ENV
          fi

      - name: Comment performance regression
        if: env.regression == 'true' && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const commentMarker = '<!-- PERFORMANCE_MONITOR_COMMENT -->';
            const body = `${commentMarker}
            ## ‚ö†Ô∏è CI Performance Regression Detected

            This PR may have introduced a performance regression in the CI pipeline.

            **Performance Metrics:**
            - Average CI duration: ${{ steps.performance.outputs.average_duration }}s
            - This PR's CI duration: ${{ steps.performance.outputs.latest_duration }}s
            - Performance change: ${{ env.regression_percentage }}%
            - Regression threshold: ${{ env.PERFORMANCE_REGRESSION_THRESHOLD }}%
            - Analysis period: Last ${{ env.PERFORMANCE_HISTORY_DAYS }} days

            **Additional Statistics:**
            - Minimum CI duration: ${{ steps.performance.outputs.min_duration }}s
            - Maximum CI duration: ${{ steps.performance.outputs.max_duration }}s

            **Possible causes:**
            - New dependencies added
            - Increased test complexity or coverage
            - Additional CI steps or security scans
            - Resource contention or infrastructure issues
            - Changes to build/packaging process

            **Recommended actions:**
            1. Review new dependencies and their impact on build time
            2. Consider optimizing test execution (parallel tests, selective testing)
            3. Check for unnecessary CI steps or redundant operations
            4. Optimize caching strategies for dependencies and build artifacts
            5. Review resource-intensive operations in the CI pipeline

            **Note:** This analysis is automated and may have false positives. Please review the actual CI logs for detailed performance insights.

            <details>
            <summary>üìä Performance Analysis Details</summary>

            - Analysis Date: ${new Date().toISOString()}
            - Workflow: ${{ github.workflow }}
            - Run ID: ${{ github.run_id }}
            - Commit: ${{ github.sha }}

            </details>
            `;

            // Check for existing performance monitor comments
            const comments = await github.rest.issues.listComments({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            });

            const existingComment = comments.data.find(comment =>
              comment.body.includes(commentMarker)
            );

            if (existingComment) {
              // Update existing comment
              await github.rest.issues.updateComment({
                comment_id: existingComment.id,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
              console.log('Updated existing performance regression comment');
            } else {
              // Create new comment
              await github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: body
              });
              console.log('Created new performance regression comment');
            }

  resource-usage:
    runs-on: ubuntu-latest
    name: Monitor Resource Usage

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Analyze repository size
        run: |
          echo "üìÅ Repository size analysis:"
          du -sh . | tail -1
          echo "Largest directories:"
          du -sh */ 2>/dev/null | sort -hr | head -10 || true

          echo "üìä File count by type:"
          find . -type f -name "*.py" | wc -l | xargs echo "Python files:"
          find . -type f -name "*.yml" -o -name "*.yaml" | wc -l | xargs echo "YAML files:"
          find . -type f -name "*.json" | wc -l | xargs echo "JSON files:"
          find . -type f -name "*.md" | wc -l | xargs echo "Markdown files:"

      - name: Check for large files
        run: |
          echo "üîç Checking for large files (>${{ env.LARGE_FILE_THRESHOLD }}):"
          large_files=$(find . -type f -size +${{ env.LARGE_FILE_THRESHOLD }} -exec ls -lh {} \; 2>/dev/null | head -10)
          if [ -n "$large_files" ]; then
            echo "Large files found:"
            echo "$large_files"
          else
            echo "No large files found"
          fi

          # Repository size warnings
          repo_size=$(du -sh . | cut -f1)
          echo "üìä Current repository size: $repo_size"

          # Check for binary files that might bloat the repository
          echo "üîç Checking for potentially problematic file types:"
          find . \( -name "*.exe" -o -name "*.dll" -o -name "*.so" -o -name "*.dylib" \) -exec ls -lh {} \; 2>/dev/null | head -5 || true
          find . \( -name "*.zip" -o -name "*.tar" -o -name "*.gz" -o -name "*.bz2" \) -exec ls -lh {} \; 2>/dev/null | head -5 || true

      - name: Generate comprehensive performance report
        if: github.event_name == 'schedule'
        run: |
          echo "üìä Comprehensive Performance Report" > performance-report.md
          echo "Generated: $(date -u '+%Y-%m-%d %H:%M:%S UTC')" >> performance-report.md
          echo "Repository: ${{ github.repository }}" >> performance-report.md
          echo "Analysis Period: Last ${{ env.PERFORMANCE_HISTORY_DAYS }} days" >> performance-report.md
          echo "" >> performance-report.md

          echo "## Executive Summary" >> performance-report.md
          if [ "${{ steps.performance.outputs.data_available }}" = "true" ]; then
            echo "- CI Performance: ‚úÖ Data Available" >> performance-report.md
            echo "- Average CI Duration: ${{ steps.performance.outputs.average_duration }}s" >> performance-report.md
            echo "- Performance Range: ${{ steps.performance.outputs.min_duration }}s - ${{ steps.performance.outputs.max_duration }}s" >> performance-report.md
          else
            echo "- CI Performance: ‚ö†Ô∏è Insufficient Data" >> performance-report.md
          fi
          echo "- Repository Size: $(du -sh . | cut -f1)" >> performance-report.md
          echo "- Total Files: $(find . -type f | wc -l)" >> performance-report.md
          echo "" >> performance-report.md

          echo "## Repository Statistics" >> performance-report.md
          echo "### File Count by Type" >> performance-report.md
          echo "- Python files: $(find . -name '*.py' | wc -l)" >> performance-report.md
          echo "- YAML files: $(find . -name '*.yml' -o -name '*.yaml' | wc -l)" >> performance-report.md
          echo "- JSON files: $(find . -name '*.json' | wc -l)" >> performance-report.md
          echo "- Markdown files: $(find . -name '*.md' | wc -l)" >> performance-report.md
          echo "- Test files: $(find . -name '*test*.py' | wc -l)" >> performance-report.md
          echo "" >> performance-report.md

          echo "### Directory Analysis" >> performance-report.md
          echo "Top 5 largest directories:" >> performance-report.md
          du -sh */ 2>/dev/null | sort -hr | head -5 | sed 's/^/- /' >> performance-report.md || echo "- No subdirectories found" >> performance-report.md
          echo "" >> performance-report.md

          echo "### Large Files (>${{ env.LARGE_FILE_THRESHOLD }})" >> performance-report.md
          large_files_count=$(find . -type f -size +${{ env.LARGE_FILE_THRESHOLD }} 2>/dev/null | wc -l)
          if [ "$large_files_count" -gt 0 ]; then
            echo "Found $large_files_count large files:" >> performance-report.md
            find . -type f -size +${{ env.LARGE_FILE_THRESHOLD }} -exec ls -lh {} \; 2>/dev/null | head -10 | sed 's/^/- /' >> performance-report.md
          else
            echo "No large files found" >> performance-report.md
          fi
          echo "" >> performance-report.md

          echo "## CI/CD Performance Analysis" >> performance-report.md
          if [ "${{ steps.performance.outputs.data_available }}" = "true" ]; then
            echo "### Performance Metrics (Last ${{ env.PERFORMANCE_HISTORY_DAYS }} days)" >> performance-report.md
            echo "- Average Duration: ${{ steps.performance.outputs.average_duration }}s" >> performance-report.md
            echo "- Minimum Duration: ${{ steps.performance.outputs.min_duration }}s" >> performance-report.md
            echo "- Maximum Duration: ${{ steps.performance.outputs.max_duration }}s" >> performance-report.md
            echo "- Latest Duration: ${{ steps.performance.outputs.latest_duration }}s" >> performance-report.md

            # Calculate performance variance
            variance=$(echo "scale=2; (${{ steps.performance.outputs.max_duration }} - ${{ steps.performance.outputs.min_duration }}) / ${{ steps.performance.outputs.average_duration }} * 100" | bc -l 2>/dev/null || echo "N/A")
            echo "- Performance Variance: ${variance}%" >> performance-report.md
            echo "" >> performance-report.md

            echo "### Performance Recommendations" >> performance-report.md
            avg_duration=${{ steps.performance.outputs.average_duration }}
            if (( $(echo "$avg_duration > 600" | bc -l) )); then
              echo "‚ö†Ô∏è **CI Duration Concern**: Average CI time exceeds 10 minutes" >> performance-report.md
              echo "- Consider optimizing test execution" >> performance-report.md
              echo "- Review caching strategies" >> performance-report.md
              echo "- Consider parallelizing build steps" >> performance-report.md
            elif (( $(echo "$avg_duration > 300" | bc -l) )); then
              echo "üìä **CI Duration Acceptable**: Average CI time is within reasonable limits" >> performance-report.md
              echo "- Continue monitoring for trends" >> performance-report.md
            else
              echo "‚úÖ **CI Performance Good**: Fast CI execution times" >> performance-report.md
            fi
          else
            echo "‚ö†Ô∏è Insufficient CI performance data available for analysis" >> performance-report.md
            echo "- Ensure CI workflows are running successfully" >> performance-report.md
            echo "- Check GitHub Actions permissions" >> performance-report.md
          fi
          echo "" >> performance-report.md

          echo "## Security and Quality Metrics" >> performance-report.md
          echo "### Workflow Files" >> performance-report.md
          workflow_count=$(find .github/workflows -name '*.yml' -o -name '*.yaml' 2>/dev/null | wc -l)
          action_count=$(find .github/actions -type f 2>/dev/null | wc -l)
          echo "- GitHub Workflows: $workflow_count" >> performance-report.md
          echo "- Custom Actions: $action_count" >> performance-report.md
          echo "" >> performance-report.md

          echo "### Configuration Files" >> performance-report.md
          config_files="pyproject.toml setup.py requirements.txt .pre-commit-config.yaml"
          for config in $config_files; do
            if [ -f "$config" ]; then
              echo "- $config: ‚úÖ" >> performance-report.md
            else
              echo "- $config: ‚ùå" >> performance-report.md
            fi
          done
          echo "" >> performance-report.md

          echo "## Report Metadata" >> performance-report.md
          echo "- Generated by: Performance Monitor Workflow" >> performance-report.md
          echo "- Workflow Run: ${{ github.run_id }}" >> performance-report.md
          echo "- Commit: ${{ github.sha }}" >> performance-report.md
          echo "- Branch: ${{ github.ref_name }}" >> performance-report.md

          echo "üìä Performance report generated successfully"
          echo "Report size: $(wc -l performance-report.md | cut -d' ' -f1) lines"

      - name: Upload performance report
        if: github.event_name == 'schedule'
        uses: actions/upload-artifact@v4
        with:
          name: performance-report-${{ github.run_number }}
          path: |
            performance-report.md
            performance-data.json
          retention-days: ${{ env.REPORT_RETENTION_DAYS }}

      - name: Create performance issue for critical metrics
        if: github.event_name == 'schedule' && steps.performance.outputs.data_available == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const avgDuration = parseFloat('${{ steps.performance.outputs.average_duration }}');
            const maxDuration = parseFloat('${{ steps.performance.outputs.max_duration }}');

            // Create issue if CI performance is concerning (>10 minutes average or >20 minutes max)
            if (avgDuration > 600 || maxDuration > 1200) {
              const title = `üö® CI Performance Alert - $(new Date().toISOString().split('T')[0])`;
              const body = `## CI Performance Alert

              Automated monitoring has detected concerning CI performance metrics:

              **Performance Metrics:**
              - Average Duration: ${avgDuration}s (${(avgDuration/60).toFixed(1)} minutes)
              - Maximum Duration: ${maxDuration}s (${(maxDuration/60).toFixed(1)} minutes)
              - Analysis Period: Last ${{ env.PERFORMANCE_HISTORY_DAYS }} days

              **Recommended Actions:**
              - Review recent changes that may have impacted CI performance
              - Analyze build logs for bottlenecks
              - Consider optimizing test execution and dependency management
              - Review CI workflow configuration

              **Links:**
              - [Performance Report Artifact](https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }})
              - [CI Workflow History](https://github.com/${{ github.repository }}/actions)

              This issue was automatically created by the Performance Monitor workflow.
              `;

              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['performance', 'ci-cd', 'automated']
              });

              console.log('Created performance alert issue due to concerning metrics');
            } else {
              console.log('CI performance metrics are within acceptable ranges');
            }
