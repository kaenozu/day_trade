# Day Trading System API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

**çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œç‰ˆ** - 2025å¹´8æœˆç‰ˆ

---

## ğŸ“‹ æ¦‚è¦

ã“ã®APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã§ã¯ã€Day Trading Systemã®çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒæä¾›ã™ã‚‹å…¨ã¦ã®APIã€ãƒ¡ã‚½ãƒƒãƒ‰ã€ã‚¯ãƒ©ã‚¹ã®è©³ç´°ãªä½¿ç”¨æ–¹æ³•ã‚’èª¬æ˜ã—ã¾ã™ã€‚

### ğŸ¯ å¯¾è±¡èª­è€…
- **é–‹ç™ºè€…**: ã‚·ã‚¹ãƒ†ãƒ æ‹¡å¼µãƒ»ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ‹…å½“è€…
- **çµ±åˆæ‹…å½“è€…**: å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ é€£æºæ‹…å½“è€…
- **é‹ç”¨ãƒãƒ¼ãƒ **: APIçµŒç”±ã§ã®ç›£è¦–ãƒ»ç®¡ç†æ‹…å½“è€…
- **ãƒ†ã‚¹ã‚¿ãƒ¼**: ã‚·ã‚¹ãƒ†ãƒ ãƒ†ã‚¹ãƒˆãƒ»æ¤œè¨¼æ‹…å½“è€…

---

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹

```python
# çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
from src.day_trade.infrastructure.database.unified_database_manager import (
    initialize_unified_database_manager
)

# ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
manager = initialize_unified_database_manager(
    config_path="config/production/database.yaml",
    auto_start=True
)

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
status = manager.get_system_status()
print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {status['overall_health']}")

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
backup_result = manager.create_backup("manual")
print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_result['status']}")

# ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
metrics = manager.get_current_metrics()
if metrics:
    print(f"CPUä½¿ç”¨ç‡: {metrics['cpu_usage']}%")
```

---

## ğŸ“š Core APIs

### çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 

#### UnifiedDatabaseManager

**ä¸»è¦ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ**: çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã®ä¸­å¿ƒçš„ãªã‚¯ãƒ©ã‚¹

```python
class UnifiedDatabaseManager:
    """çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""
```

##### åˆæœŸåŒ–

```python
def __init__(self, config_path: Optional[str] = None, auto_start: bool = False):
    """
    çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–

    Args:
        config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "config/database_production.yaml")
        auto_start: è‡ªå‹•é–‹å§‹ãƒ•ãƒ©ã‚° (ç›£è¦–ãƒ»ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®è‡ªå‹•é–‹å§‹)

    Raises:
        ApplicationError: åˆæœŸåŒ–å¤±æ•—æ™‚
    """
```

**ä½¿ç”¨ä¾‹**:
```python
# åŸºæœ¬åˆæœŸåŒ–
manager = UnifiedDatabaseManager()

# ã‚«ã‚¹ã‚¿ãƒ è¨­å®šã§ã®åˆæœŸåŒ–
manager = UnifiedDatabaseManager(
    config_path="config/custom_database.yaml",
    auto_start=True
)
```

##### ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†

###### `get_system_status() -> Dict[str, Any]`

ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“ã®çŠ¶æ…‹ã‚’å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "overall_health": "healthy",  # healthy | degraded | unhealthy
    "initialized": True,
    "components": {
        "production_db": "healthy",
        "backup_system": "healthy",
        "monitoring_system": "healthy",
        "dashboard": "healthy"
    },
    "uptime_seconds": 3600,
    "last_health_check": "2025-08-18T10:30:00Z"
}
```

**ä½¿ç”¨ä¾‹**:
```python
status = manager.get_system_status()
if status["overall_health"] != "healthy":
    print("ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
    for component, state in status["components"].items():
        if state != "healthy":
            print(f"å•é¡Œã®ã‚ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ: {component}")
```

###### `run_health_check() -> Dict[str, Any]`

åŒ…æ‹¬çš„ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ

**æˆ»ã‚Šå€¤**:
```python
{
    "overall_status": "healthy",  # healthy | degraded | critical
    "timestamp": "2025-08-18T10:30:00Z",
    "components": [
        {
            "name": "database_connection",
            "status": "healthy",
            "response_time_ms": 15.2,
            "details": {...}
        },
        {
            "name": "backup_system",
            "status": "healthy",
            "last_backup": "2025-08-18T02:00:00Z"
        }
    ],
    "issues": [],  # å•é¡ŒãŒã‚ã‚‹å ´åˆã®ãƒªã‚¹ãƒˆ
    "recommendations": []  # æ¨å¥¨äº‹é …
}
```

**ä½¿ç”¨ä¾‹**:
```python
health = manager.run_health_check()
if health["overall_status"] == "critical":
    print("ç·Šæ€¥å¯¾å¿œãŒå¿…è¦:")
    for issue in health["issues"]:
        print(f"- {issue}")
```

###### `shutdown() -> Dict[str, Any]`

ã‚·ã‚¹ãƒ†ãƒ å®‰å…¨åœæ­¢

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",  # success | partial | failed
    "stopped_components": ["monitoring", "backup_scheduler"],
    "duration_seconds": 5.2,
    "timestamp": "2025-08-18T10:30:00Z"
}
```

##### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†

###### `create_backup(backup_type: str = "manual") -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `backup_type`: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã®ç¨®é¡ ("manual", "scheduled", "emergency")

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",  # success | failed
    "backup_path": "/opt/daytrading/backups/backup_20250818_103000.sql.gz",
    "backup_id": "backup_20250818_103000",
    "size_mb": 15.7,
    "duration_seconds": 12.3,
    "timestamp": "2025-08-18T10:30:00Z",
    "verification_status": "verified",
    "metadata": {
        "compression": "gzip",
        "database_size_mb": 45.2,
        "table_count": 12
    }
}
```

**ä½¿ç”¨ä¾‹**:
```python
# æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
backup = manager.create_backup("manual")
if backup["status"] == "success":
    print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup['backup_path']}")
    print(f"ã‚µã‚¤ã‚º: {backup['size_mb']}MB")

# ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
emergency_backup = manager.create_backup("emergency")
```

###### `list_backups(limit: int = 50) -> List[Dict[str, Any]]`

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§å–å¾—

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `limit`: å–å¾—ã™ã‚‹æœ€å¤§ä»¶æ•°

**æˆ»ã‚Šå€¤**:
```python
[
    {
        "filename": "backup_20250818_103000.sql.gz",
        "backup_id": "backup_20250818_103000",
        "size_mb": 15.7,
        "created_at": "2025-08-18T10:30:00Z",
        "backup_type": "manual",
        "status": "verified",
        "retention_until": "2025-09-17T10:30:00Z"
    },
    # ... ä»–ã®ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
]
```

**ä½¿ç”¨ä¾‹**:
```python
backups = manager.list_backups(limit=10)
print(f"åˆ©ç”¨å¯èƒ½ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {len(backups)}ä»¶")

for backup in backups:
    print(f"- {backup['filename']}: {backup['size_mb']}MB ({backup['status']})")
```

###### `restore_database(backup_filename: str, dry_run: bool = False) -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å¾©å…ƒ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `backup_filename`: å¾©å…ƒã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å
- `dry_run`: ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œãƒ•ãƒ©ã‚°ï¼ˆå®Ÿéš›ã«ã¯å¾©å…ƒã›ãšã€æ¤œè¨¼ã®ã¿ï¼‰

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",  # success | failed
    "backup_filename": "backup_20250818_103000.sql.gz",
    "duration_seconds": 25.7,
    "restored_tables": 12,
    "restored_records": 15420,
    "pre_restore_backup": "backup_pre_restore_20250818_104500.sql.gz",
    "verification_passed": True,
    "dry_run": False
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³å®Ÿè¡Œ
dry_result = manager.restore_database("backup_20250818_103000.sql.gz", dry_run=True)
if dry_result["status"] == "success":
    print("å¾©å…ƒå¯èƒ½ãªãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã§ã™")

    # å®Ÿéš›ã®å¾©å…ƒå®Ÿè¡Œ
    restore_result = manager.restore_database("backup_20250818_103000.sql.gz")
    if restore_result["status"] == "success":
        print(f"å¾©å…ƒå®Œäº†: {restore_result['restored_records']}ãƒ¬ã‚³ãƒ¼ãƒ‰")
```

##### ç›£è¦–ãƒ»ãƒ¡ãƒˆãƒªã‚¯ã‚¹

###### `get_current_metrics() -> Optional[Dict[str, Any]]`

ç¾åœ¨ã®ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "timestamp": "2025-08-18T10:30:00Z",
    "active_connections": 5,
    "max_connections": 20,
    "connection_pool_usage": 0.25,
    "queries_per_second": 12.5,
    "average_query_time": 0.015,
    "slow_queries_count": 0,
    "cpu_usage": 25.3,
    "memory_usage_mb": 512.7,
    "disk_usage_percent": 45.2,
    "disk_io_read_mb": 15.2,
    "disk_io_write_mb": 8.7,
    "connection_errors": 0,
    "query_errors": 0,
    "deadlocks": 0,
    "database_size_mb": 45.2,
    "table_count": 12,
    "index_count": 18
}
```

**ä½¿ç”¨ä¾‹**:
```python
metrics = manager.get_current_metrics()
if metrics:
    # CPUä½¿ç”¨ç‡ç›£è¦–
    if metrics["cpu_usage"] > 80:
        print(f"é«˜CPUä½¿ç”¨ç‡: {metrics['cpu_usage']}%")

    # æ¥ç¶šãƒ—ãƒ¼ãƒ«ç›£è¦–
    if metrics["connection_pool_usage"] > 0.8:
        print("æ¥ç¶šãƒ—ãƒ¼ãƒ«ä½¿ç”¨ç‡ãŒé«˜ã„")

    # ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªç›£è¦–
    if metrics["slow_queries_count"] > 0:
        print(f"ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªæ¤œå‡º: {metrics['slow_queries_count']}ä»¶")
```

###### `get_active_alerts() -> List[Dict[str, Any]]`

ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆå–å¾—

**æˆ»ã‚Šå€¤**:
```python
[
    {
        "id": "high_cpu_usage_cpu_usage",
        "rule_name": "high_cpu_usage",
        "metric_name": "cpu_usage",
        "current_value": 85.2,
        "threshold": 80.0,
        "severity": "warning",
        "message": "CPUä½¿ç”¨ç‡ãŒé«˜ã„: ç¾åœ¨å€¤=85.20, é–¾å€¤=80.0",
        "timestamp": "2025-08-18T10:25:00Z",
        "resolved": False
    }
]
```

**ä½¿ç”¨ä¾‹**:
```python
alerts = manager.get_active_alerts()
if alerts:
    print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {len(alerts)}ä»¶")

    for alert in alerts:
        print(f"[{alert['severity']}] {alert['message']}")

        # Critical ã‚¢ãƒ©ãƒ¼ãƒˆã®å ´åˆã¯ç·Šæ€¥å¯¾å¿œ
        if alert["severity"] == "critical":
            print("ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ã§ã™")
```

##### ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ»ãƒ¬ãƒãƒ¼ãƒˆ

###### `get_dashboard_data() -> Dict[str, Any]`

ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "system_overview": {
        "status": "healthy",
        "uptime_hours": 24.5,
        "total_transactions": 1542,
        "success_rate": 99.2
    },
    "performance_metrics": {
        "avg_response_time_ms": 15.2,
        "peak_cpu_usage": 65.3,
        "peak_memory_usage_mb": 892.1
    },
    "database_stats": {
        "size_mb": 45.2,
        "backup_count": 12,
        "last_backup": "2025-08-18T02:00:00Z"
    },
    "alerts_summary": {
        "active_count": 0,
        "resolved_today": 2,
        "critical_count": 0
    },
    "generated_at": "2025-08-18T10:30:00Z"
}
```

**ä½¿ç”¨ä¾‹**:
```python
dashboard = manager.get_dashboard_data()
print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {dashboard['system_overview']['status']}")
print(f"ç¨¼åƒæ™‚é–“: {dashboard['system_overview']['uptime_hours']}æ™‚é–“")
print(f"æˆåŠŸç‡: {dashboard['system_overview']['success_rate']}%")
```

###### `generate_report(report_type: str = "daily") -> Dict[str, Any]`

ã‚·ã‚¹ãƒ†ãƒ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `report_type`: ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ— ("daily", "weekly", "monthly", "custom")

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",
    "report_type": "daily",
    "file_path": "/opt/daytrading/reports/daily_report_20250818.pdf",
    "period": {
        "start": "2025-08-17T00:00:00Z",
        "end": "2025-08-18T00:00:00Z"
    },
    "summary": {
        "total_transactions": 1542,
        "average_response_time": 15.2,
        "system_availability": 99.8,
        "backup_count": 1,
        "alert_count": 3
    },
    "generated_at": "2025-08-18T10:30:00Z"
}
```

**ä½¿ç”¨ä¾‹**:
```python
# æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
daily_report = manager.generate_report("daily")
if daily_report["status"] == "success":
    print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {daily_report['file_path']}")
    print(f"å–å¼•æ•°: {daily_report['summary']['total_transactions']}")

# é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
weekly_report = manager.generate_report("weekly")
```

---

## ğŸ—„ï¸ Database APIs

### ProductionDatabaseManager

**ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å›ºæœ‰æ“ä½œ**: PostgreSQL/SQLiteæœ¬ç•ªç’°å¢ƒç®¡ç†

```python
class ProductionDatabaseManager:
    """æœ¬ç•ªç’°å¢ƒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚¯ãƒ©ã‚¹"""
```

##### åˆæœŸåŒ–ãƒ»æ¥ç¶š

###### `__init__(config_path: Optional[str] = None)`

```python
def __init__(self, config_path: Optional[str] = None):
    """
    æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–

    Args:
        config_path: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
    """
```

###### `initialize() -> None`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–å®Ÿè¡Œ

```python
def initialize() -> None:
    """
    ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ—ãƒ¼ãƒ«ãƒ»ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç®¡ç†åˆæœŸåŒ–

    Raises:
        ProductionDatabaseError: åˆæœŸåŒ–å¤±æ•—æ™‚
    """
```

###### `get_session()`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—ï¼ˆã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼‰

```python
@contextmanager
def get_session():
    """
    SQLAlchemyã‚»ãƒƒã‚·ãƒ§ãƒ³å–å¾—

    Yields:
        Session: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚»ãƒƒã‚·ãƒ§ãƒ³

    Usage:
        with manager.get_session() as session:
            result = session.execute(text("SELECT 1"))
    """
```

**ä½¿ç”¨ä¾‹**:
```python
db_manager = ProductionDatabaseManager()
db_manager.initialize()

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ä½¿ç”¨ä¾‹
with db_manager.get_session() as session:
    # ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
    result = session.execute(text("SELECT COUNT(*) FROM trades"))
    count = result.scalar()
    print(f"å–å¼•æ•°: {count}")

    # ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥
    session.execute(text("""
        INSERT INTO trades (symbol, quantity, price, timestamp)
        VALUES (:symbol, :quantity, :price, :timestamp)
    """), {
        "symbol": "AAPL",
        "quantity": 100,
        "price": 150.25,
        "timestamp": datetime.now()
    })
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ‚äº†æ™‚ã«è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ
```

##### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±

###### `get_database_info() -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è©³ç´°æƒ…å ±å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "database_type": "PostgreSQL",
    "version": "PostgreSQL 13.7 on x86_64-pc-linux-gnu",
    "database_size": "15 MB",
    "active_connections": 5,
    "environment": "production",
    "pool_status": {
        "size": 20,
        "checked_out": 3,
        "overflow": 0,
        "utilization": 0.15
    }
}
```

###### `health_check() -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "healthy",  # healthy | unhealthy
    "response_time_ms": 15.2,
    "pool_status": {
        "size": 20,
        "checked_out": 3,
        "overflow": 0,
        "utilization": 0.15
    },
    "slow_queries_count": 0,
    "last_check": "2025-08-18T10:30:00Z"
}
```

##### ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

###### `run_migrations() -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ

**æˆ»ã‚Šå€¤**:
```python
{
    "success": True,
    "duration_seconds": 5.2,
    "from_revision": "abc123",
    "to_revision": "def456",
    "applied_revisions": ["def456"]
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
migration_result = db_manager.run_migrations()
if migration_result["success"]:
    print(f"ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œäº†: {migration_result['duration_seconds']}ç§’")
    print(f"é©ç”¨ãƒªãƒ“ã‚¸ãƒ§ãƒ³: {migration_result['applied_revisions']}")
```

---

## ğŸ“Š Monitoring APIs

### DatabaseMonitoringSystem

**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†

```python
class DatabaseMonitoringSystem:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
```

##### åˆæœŸåŒ–ãƒ»åˆ¶å¾¡

###### `__init__(engine: Engine, config: Dict[str, Any])`

```python
def __init__(self, engine: Engine, config: Dict[str, Any]):
    """
    ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–

    Args:
        engine: SQLAlchemyã‚¨ãƒ³ã‚¸ãƒ³
        config: ç›£è¦–è¨­å®š
    """
```

###### `start_monitoring() -> None`

ç›£è¦–é–‹å§‹

```python
def start_monitoring() -> None:
    """
    ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹
    è¨­å®šã•ã‚ŒãŸé–“éš”ã§ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
    """
```

###### `stop_monitoring() -> None`

ç›£è¦–åœæ­¢

```python
def stop_monitoring() -> None:
    """
    ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰å®‰å…¨åœæ­¢
    """
```

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.infrastructure.database.monitoring_system import (
    initialize_monitoring_system
)

# ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
monitoring = initialize_monitoring_system(engine, config)

# ç›£è¦–é–‹å§‹
monitoring.start_monitoring()
print("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

# ã—ã°ã‚‰ãç¨¼åƒ...
time.sleep(60)

# ç›£è¦–åœæ­¢
monitoring.stop_monitoring()
print("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ åœæ­¢")
```

##### ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

###### `collect_metrics() -> Optional[DatabaseMetrics]`

ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹åé›†

**æˆ»ã‚Šå€¤**:
```python
DatabaseMetrics(
    timestamp=datetime(2025, 8, 18, 10, 30, 0),
    active_connections=5,
    max_connections=20,
    connection_pool_usage=0.25,
    queries_per_second=12.5,
    average_query_time=0.015,
    slow_queries_count=0,
    cpu_usage=25.3,
    memory_usage_mb=512.7,
    disk_usage_percent=45.2,
    disk_io_read_mb=15.2,
    disk_io_write_mb=8.7,
    connection_errors=0,
    query_errors=0,
    deadlocks=0,
    database_size_mb=45.2,
    table_count=12,
    index_count=18
)
```

###### `get_metrics_history(hours: int = 1) -> List[Dict[str, Any]]`

ãƒ¡ãƒˆãƒªã‚¯ã‚¹å±¥æ­´å–å¾—

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `hours`: å–å¾—ã™ã‚‹éå»æ™‚é–“æ•°

**æˆ»ã‚Šå€¤**: ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸ã®ãƒªã‚¹ãƒˆ

**ä½¿ç”¨ä¾‹**:
```python
# éå»1æ™‚é–“ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
recent_metrics = monitoring.get_metrics_history(hours=1)
print(f"éå»1æ™‚é–“ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ: {len(recent_metrics)}ä»¶")

# CPUä½¿ç”¨ç‡ã®æ¨ç§»åˆ†æ
cpu_usage_values = [m["cpu_usage"] for m in recent_metrics]
avg_cpu = sum(cpu_usage_values) / len(cpu_usage_values)
max_cpu = max(cpu_usage_values)
print(f"å¹³å‡CPUä½¿ç”¨ç‡: {avg_cpu:.1f}%")
print(f"æœ€å¤§CPUä½¿ç”¨ç‡: {max_cpu:.1f}%")
```

##### ã‚¢ãƒ©ãƒ¼ãƒˆç®¡ç†

###### `check_alerts(metrics: DatabaseMetrics) -> List[Alert]`

ã‚¢ãƒ©ãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `metrics`: ãƒã‚§ãƒƒã‚¯å¯¾è±¡ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹

**æˆ»ã‚Šå€¤**: æ–°è¦ç™ºç”Ÿã‚¢ãƒ©ãƒ¼ãƒˆã®ãƒªã‚¹ãƒˆ

###### `get_active_alerts() -> List[Dict[str, Any]]`

ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆå–å¾—

**æˆ»ã‚Šå€¤**:
```python
[
    {
        "id": "high_cpu_usage_cpu_usage",
        "rule_name": "high_cpu_usage",
        "metric_name": "cpu_usage",
        "current_value": 85.2,
        "threshold": 80.0,
        "severity": "warning",
        "message": "CPUä½¿ç”¨ç‡ãŒé«˜ã„: ç¾åœ¨å€¤=85.20, é–¾å€¤=80.0",
        "timestamp": "2025-08-18T10:25:00Z",
        "resolved": False
    }
]
```

###### `get_alert_statistics() -> Dict[str, Any]`

ã‚¢ãƒ©ãƒ¼ãƒˆçµ±è¨ˆæƒ…å ±å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "total_alerts": 15,
    "active_alerts": 2,
    "resolved_alerts": 13,
    "critical_count": 1,
    "warning_count": 12,
    "info_count": 2
}
```

###### `add_alert_callback(callback: Callable[[Alert], None]) -> None`

ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ 

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `callback`: ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç”Ÿæ™‚ã«å‘¼ã³å‡ºã•ã‚Œã‚‹é–¢æ•°

**ä½¿ç”¨ä¾‹**:
```python
def email_alert_handler(alert):
    """ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    if alert.severity in ["critical", "high"]:
        send_email(
            to="admin@company.com",
            subject=f"[ALERT] {alert.rule_name}",
            body=alert.message
        )

def slack_alert_handler(alert):
    """Slacké€šçŸ¥ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    slack_client.send_message(
        channel="#alerts",
        text=f"ğŸš¨ {alert.message}"
    )

# ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ 
monitoring.add_alert_callback(email_alert_handler)
monitoring.add_alert_callback(slack_alert_handler)
```

##### ç›£è¦–çŠ¶æ…‹

###### `get_monitoring_status() -> Dict[str, Any]`

ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "enabled": True,
    "running": True,
    "interval_seconds": 30,
    "metrics_count": 120,
    "active_alerts_count": 2,
    "alert_history_count": 15,
    "alert_rules_count": 8,
    "last_collection": "2025-08-18T10:30:00Z"
}
```

---

## ğŸ’¾ Backup APIs

### BackupManager

**ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†**: è‡ªå‹•ãƒ»æ‰‹å‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½

```python
class BackupManager:
    """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ """
```

##### åˆæœŸåŒ–ãƒ»è¨­å®š

###### `__init__(engine: Engine, config: Dict[str, Any])`

```python
def __init__(self, engine: Engine, config: Dict[str, Any]):
    """
    ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–

    Args:
        engine: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ³ã‚¸ãƒ³
        config: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—è¨­å®š
    """
```

###### `start_scheduler() -> None`

è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼é–‹å§‹

```python
def start_scheduler() -> None:
    """
    è¨­å®šã•ã‚ŒãŸé–“éš”ã§è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
    """
```

###### `stop_scheduler() -> None`

è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åœæ­¢

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.infrastructure.database.backup_manager import (
    initialize_backup_manager
)

# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼åˆæœŸåŒ–
backup_manager = initialize_backup_manager(engine, config)

# è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹
backup_manager.start_scheduler()
print("è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—é–‹å§‹")

# å¿…è¦ã«å¿œã˜ã¦åœæ­¢
backup_manager.stop_scheduler()
```

##### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ

###### `create_backup(backup_type: str = "manual") -> Dict[str, Any]`

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `backup_type`: ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¿ã‚¤ãƒ— ("manual", "scheduled", "emergency")

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",
    "backup_id": "backup_20250818_103000",
    "backup_path": "/opt/daytrading/backups/backup_20250818_103000.sql.gz",
    "size_mb": 15.7,
    "duration_seconds": 12.3,
    "compression_ratio": 0.35,
    "verification_status": "verified",
    "metadata": {
        "database_type": "postgresql",
        "database_size_mb": 45.2,
        "table_count": 12,
        "record_count": 15420
    }
}
```

###### `verify_backup(backup_filename: str) -> Dict[str, Any]`

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´åˆæ€§ç¢ºèª

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `backup_filename`: ç¢ºèªã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "verified",  # verified | corrupted | not_found
    "backup_filename": "backup_20250818_103000.sql.gz",
    "file_exists": True,
    "file_size_mb": 15.7,
    "checksum_valid": True,
    "compression_valid": True,
    "readable": True,
    "verification_time": "2025-08-18T10:30:00Z"
}
```

**ä½¿ç”¨ä¾‹**:
```python
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
backup_result = backup_manager.create_backup("manual")
if backup_result["status"] == "success":
    backup_file = backup_result["backup_id"] + ".sql.gz"

    # æ•´åˆæ€§ç¢ºèª
    verification = backup_manager.verify_backup(backup_file)
    if verification["status"] == "verified":
        print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ•´åˆæ€§OK")
    else:
        print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã«å•é¡ŒãŒã‚ã‚Šã¾ã™")
```

##### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ç®¡ç†

###### `list_backups(limit: int = 50) -> List[Dict[str, Any]]`

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§å–å¾—

###### `delete_backup(backup_filename: str) -> Dict[str, Any]`

ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `backup_filename`: å‰Šé™¤ã™ã‚‹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«å

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",  # success | failed | not_found
    "backup_filename": "backup_20250818_103000.sql.gz",
    "deleted_size_mb": 15.7,
    "timestamp": "2025-08-18T10:30:00Z"
}
```

###### `cleanup_old_backups(retention_days: int = 30) -> Dict[str, Any]`

å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å‰Šé™¤

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `retention_days`: ä¿æŒæ—¥æ•°

**æˆ»ã‚Šå€¤**:
```python
{
    "status": "success",
    "deleted_count": 5,
    "freed_space_mb": 78.5,
    "retention_days": 30,
    "remaining_backups": 12
}
```

**ä½¿ç”¨ä¾‹**:
```python
# å¤ã„ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆ30æ—¥ä»¥ä¸Šï¼‰
cleanup_result = backup_manager.cleanup_old_backups(retention_days=30)
print(f"å‰Šé™¤ã—ãŸãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—: {cleanup_result['deleted_count']}ä»¶")
print(f"è§£æ”¾ã—ãŸå®¹é‡: {cleanup_result['freed_space_mb']}MB")
```

---

## ğŸ”§ Error Handling APIs

### çµ±åˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

#### ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹éšå±¤

```python
# ãƒ™ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹
class ApplicationError(Exception):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å›ºæœ‰ã‚¨ãƒ©ãƒ¼ã®åŸºåº•ã‚¯ãƒ©ã‚¹"""

class DataAccessError(ApplicationError):
    """ãƒ‡ãƒ¼ã‚¿ã‚¢ã‚¯ã‚»ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼"""

class SystemError(ApplicationError):
    """ã‚·ã‚¹ãƒ†ãƒ é–¢é€£ã‚¨ãƒ©ãƒ¼"""

class SecurityError(ApplicationError):
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é–¢é€£ã‚¨ãƒ©ãƒ¼"""

class ValidationError(ApplicationError):
    """ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³é–¢é€£ã‚¨ãƒ©ãƒ¼"""
```

#### ã‚¨ãƒ©ãƒ¼ãƒã‚¦ãƒ³ãƒ€ãƒªãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼

###### `@error_boundary(component_name: str, operation_name: str, suppress_errors: bool = False)`

é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

**ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿**:
- `component_name`: ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå
- `operation_name`: æ“ä½œå
- `suppress_errors`: ã‚¨ãƒ©ãƒ¼æŠ‘åˆ¶ãƒ•ãƒ©ã‚°

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.core.error_handling.unified_error_system import (
    error_boundary, DataAccessError
)

@error_boundary(
    component_name="trading_service",
    operation_name="execute_trade",
    suppress_errors=False
)
def execute_trade(symbol: str, quantity: int, price: float) -> Dict[str, Any]:
    """å–å¼•å®Ÿè¡Œ"""
    try:
        # å–å¼•ãƒ­ã‚¸ãƒƒã‚¯
        result = trading_api.execute(symbol, quantity, price)
        return {"status": "success", "trade_id": result.id}
    except Exception as e:
        raise DataAccessError(f"å–å¼•å®Ÿè¡Œå¤±æ•—: {e}") from e

# ä½¿ç”¨
try:
    trade_result = execute_trade("AAPL", 100, 150.25)
    print(f"å–å¼•å®Œäº†: {trade_result['trade_id']}")
except DataAccessError as e:
    print(f"å–å¼•ã‚¨ãƒ©ãƒ¼: {e}")
```

#### ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒ©ãƒ¼

###### `global_error_handler.handle_error(error: Exception, context: Dict[str, Any])`

ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¨ãƒ©ãƒ¼å‡¦ç†

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.core.error_handling.unified_error_system import (
    global_error_handler
)

try:
    # å±é™ºãªæ“ä½œ
    risky_operation()
except Exception as e:
    # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã§å‡¦ç†
    global_error_handler.handle_error(e, {
        "operation": "risky_operation",
        "user_id": "user123",
        "timestamp": datetime.now().isoformat()
    })
```

---

## ğŸ”’ Security APIs

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ 

#### SecurityMonitor

```python
class SecurityMonitor:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ """
```

###### `record_failed_login(ip_address: str, user_id: Optional[str] = None)`

ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—è¨˜éŒ²

###### `is_ip_blocked(ip_address: str) -> bool`

IPãƒ–ãƒ­ãƒƒã‚¯çŠ¶æ…‹ç¢ºèª

###### `get_security_summary() -> Dict[str, Any]`

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚µãƒãƒªãƒ¼å–å¾—

**æˆ»ã‚Šå€¤**:
```python
{
    "blocked_ips_count": 3,
    "recent_events_count": 15,
    "event_breakdown": {
        "failed_login": 8,
        "suspicious_request": 4,
        "ip_blocked": 3
    },
    "failed_attempts_count": 12,
    "last_update": "2025-08-18T10:30:00Z"
}
```

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.core.security.security_monitor import get_security_monitor

security = get_security_monitor()

# ãƒ­ã‚°ã‚¤ãƒ³å¤±æ•—è¨˜éŒ²
security.record_failed_login("192.168.1.100", "user123")

# IPãƒ–ãƒ­ãƒƒã‚¯ç¢ºèª
if security.is_ip_blocked("192.168.1.100"):
    print("ã“ã®IPã¯ãƒ–ãƒ­ãƒƒã‚¯ã•ã‚Œã¦ã„ã¾ã™")

# ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚µãƒãƒªãƒ¼
summary = security.get_security_summary()
print(f"ãƒ–ãƒ­ãƒƒã‚¯æ¸ˆã¿IP: {summary['blocked_ips_count']}ä»¶")
```

#### DataEncryption

```python
class DataEncryption:
    """ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–ã‚¯ãƒ©ã‚¹"""
```

###### `encrypt(data: Union[str, bytes]) -> str`

ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–

###### `decrypt(encrypted_data: str) -> str`

ãƒ‡ãƒ¼ã‚¿å¾©å·åŒ–

###### `encrypt_file(file_path: str, output_path: str = None) -> str`

ãƒ•ã‚¡ã‚¤ãƒ«æš—å·åŒ–

###### `decrypt_file(encrypted_file_path: str, output_path: str = None) -> str`

ãƒ•ã‚¡ã‚¤ãƒ«å¾©å·åŒ–

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.core.security.data_encryption import get_data_encryption

encryption = get_data_encryption()

# ãƒ‡ãƒ¼ã‚¿æš—å·åŒ–
sensitive_data = "æ©Ÿå¯†æƒ…å ±"
encrypted = encryption.encrypt(sensitive_data)
print(f"æš—å·åŒ–ãƒ‡ãƒ¼ã‚¿: {encrypted}")

# ãƒ‡ãƒ¼ã‚¿å¾©å·åŒ–
decrypted = encryption.decrypt(encrypted)
print(f"å¾©å·åŒ–ãƒ‡ãƒ¼ã‚¿: {decrypted}")

# ãƒ•ã‚¡ã‚¤ãƒ«æš—å·åŒ–
encrypted_file = encryption.encrypt_file("sensitive_file.txt")
print(f"æš—å·åŒ–ãƒ•ã‚¡ã‚¤ãƒ«: {encrypted_file}")
```

---

## ğŸ§ª Testing APIs

### ãƒ†ã‚¹ãƒˆãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£

#### DatabaseTestUtils

```python
class DatabaseTestUtils:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆç”¨ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
```

###### `create_test_database() -> str`

ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½œæˆ

###### `cleanup_test_database(db_name: str)`

ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å‰Šé™¤

###### `load_test_data(db_session: Session, data_file: str)`

ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ•å…¥

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.testing.database_test_utils import DatabaseTestUtils

def test_trading_operations():
    test_utils = DatabaseTestUtils()

    # ãƒ†ã‚¹ãƒˆDBä½œæˆ
    test_db = test_utils.create_test_database()

    try:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŠ•å…¥
        with get_test_session(test_db) as session:
            test_utils.load_test_data(session, "test_trades.json")

            # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
            result = execute_test_trade(session, "AAPL", 100, 150.25)
            assert result["status"] == "success"

    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        test_utils.cleanup_test_database(test_db)
```

---

## ğŸ“‹ Configuration APIs

### è¨­å®šç®¡ç†

#### EnvironmentConfig

```python
class EnvironmentConfig:
    """ç’°å¢ƒè¨­å®šç®¡ç†"""
```

###### `get_database_config() -> Dict[str, Any]`

ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šå–å¾—

###### `get_monitoring_config() -> Dict[str, Any]`

ç›£è¦–è¨­å®šå–å¾—

###### `get_security_config() -> Dict[str, Any]`

ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¨­å®šå–å¾—

**ä½¿ç”¨ä¾‹**:
```python
from src.day_trade.config.environment_config import get_environment_config

config = get_environment_config()

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š
db_config = config.get_database_config()
print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹URL: {db_config['url']}")

# ç›£è¦–è¨­å®š
monitoring_config = config.get_monitoring_config()
print(f"ç›£è¦–é–“éš”: {monitoring_config['interval_seconds']}ç§’")
```

---

## ğŸ” Utility Functions

### ã‚ˆãä½¿ç”¨ã•ã‚Œã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

#### åˆæœŸåŒ–é–¢æ•°

```python
# çµ±åˆã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
def initialize_unified_database_manager(
    config_path: str = None,
    auto_start: bool = False
) -> UnifiedDatabaseManager:
    """çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–"""

# å„ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
def initialize_production_database(config_path: str = None) -> ProductionDatabaseManager:
def initialize_monitoring_system(engine: Engine, config: Dict) -> DatabaseMonitoringSystem:
def initialize_backup_manager(engine: Engine, config: Dict) -> BackupManager:
```

#### è¨­å®šå–å¾—é–¢æ•°

```python
def get_unified_database_manager() -> Optional[UnifiedDatabaseManager]:
    """çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""

def get_production_database_manager() -> ProductionDatabaseManager:
    """æœ¬ç•ªãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼å–å¾—"""

def get_monitoring_system() -> Optional[DatabaseMonitoringSystem]:
    """ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ å–å¾—"""

def get_security_monitor() -> SecurityMonitor:
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¢ãƒ‹ã‚¿ãƒ¼å–å¾—"""
```

---

## ğŸ“Š Response Formats

### æ¨™æº–ãƒ¬ã‚¹ãƒãƒ³ã‚¹å½¢å¼

#### æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹

```python
{
    "status": "success",
    "data": { /* çµæœãƒ‡ãƒ¼ã‚¿ */ },
    "timestamp": "2025-08-18T10:30:00Z",
    "duration_seconds": 0.123
}
```

#### ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹

```python
{
    "status": "error",
    "error": {
        "type": "DataAccessError",
        "message": "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼",
        "code": "DB_CONNECTION_FAILED",
        "details": { /* ã‚¨ãƒ©ãƒ¼è©³ç´° */ }
    },
    "timestamp": "2025-08-18T10:30:00Z"
}
```

#### éƒ¨åˆ†æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹

```python
{
    "status": "partial",
    "data": { /* æˆåŠŸã—ãŸéƒ¨åˆ†ã®ãƒ‡ãƒ¼ã‚¿ */ },
    "warnings": [
        "ä¸€éƒ¨ã®æ“ä½œãŒå¤±æ•—ã—ã¾ã—ãŸ",
        "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã¾ã—ãŸ"
    ],
    "timestamp": "2025-08-18T10:30:00Z"
}
```

---

## ğŸš€ Advanced Usage Examples

### å®Œå…¨ãªçµ±åˆä¾‹

```python
#!/usr/bin/env python3
"""
Day Trading System çµ±åˆä½¿ç”¨ä¾‹
"""

import time
from datetime import datetime
from src.day_trade.infrastructure.database.unified_database_manager import (
    initialize_unified_database_manager
)

def main():
    # 1. ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    print("çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–...")
    manager = initialize_unified_database_manager(
        config_path="config/production/database.yaml",
        auto_start=True
    )

    # 2. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
    status = manager.get_system_status()
    print(f"ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹: {status['overall_health']}")

    if status["overall_health"] != "healthy":
        print("ã‚·ã‚¹ãƒ†ãƒ ã«å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚çµ‚äº†ã—ã¾ã™ã€‚")
        return

    # 3. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
    health = manager.run_health_check()
    print(f"ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯: {health['overall_status']}")

    # 4. ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
    metrics = manager.get_current_metrics()
    if metrics:
        print(f"CPUä½¿ç”¨ç‡: {metrics['cpu_usage']}%")
        print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: {metrics['memory_usage_mb']}MB")
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ¥ç¶š: {metrics['active_connections']}")

    # 5. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆç¢ºèª
    alerts = manager.get_active_alerts()
    if alerts:
        print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {len(alerts)}ä»¶")
        for alert in alerts:
            print(f"- [{alert['severity']}] {alert['message']}")
    else:
        print("ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆãªã—")

    # 6. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    print("ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­...")
    backup_result = manager.create_backup("api_example")
    if backup_result["status"] == "success":
        print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: {backup_result['backup_path']}")
        print(f"ã‚µã‚¤ã‚º: {backup_result['size_mb']}MB")

    # 7. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¸€è¦§ç¢ºèª
    backups = manager.list_backups(limit=5)
    print(f"æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ— {len(backups)}ä»¶:")
    for backup in backups:
        print(f"- {backup['filename']}: {backup['size_mb']}MB")

    # 8. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ãƒ‡ãƒ¼ã‚¿å–å¾—
    dashboard = manager.get_dashboard_data()
    if dashboard:
        print("ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦:")
        overview = dashboard["system_overview"]
        print(f"- çŠ¶æ…‹: {overview['status']}")
        print(f"- ç¨¼åƒæ™‚é–“: {overview['uptime_hours']}æ™‚é–“")
        print(f"- æˆåŠŸç‡: {overview['success_rate']}%")

    # 9. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    print("æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­...")
    report = manager.generate_report("daily")
    if report["status"] == "success":
        print(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {report['file_path']}")

    # 10. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç›´æ¥æ“ä½œä¾‹
    if manager.production_db_manager:
        with manager.production_db_manager.get_session() as session:
            from sqlalchemy import text

            # ã‚µãƒ³ãƒ—ãƒ«ã‚¯ã‚¨ãƒªå®Ÿè¡Œ
            result = session.execute(text("SELECT 'API Test Success' as message"))
            message = result.scalar()
            print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒ†ã‚¹ãƒˆ: {message}")

    print("çµ±åˆã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨ä¾‹å®Œäº†")

if __name__ == "__main__":
    main()
```

### ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šä¾‹

```python
"""
ã‚«ã‚¹ã‚¿ãƒ ç›£è¦–ãƒ»ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šä¾‹
"""

from src.day_trade.infrastructure.database.unified_database_manager import get_unified_database_manager

def setup_custom_monitoring():
    manager = get_unified_database_manager()
    if not manager or not manager.monitoring_system:
        print("ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
        return

    monitoring = manager.monitoring_system

    # ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆé€šçŸ¥è¨­å®š
    def custom_alert_handler(alert):
        """ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
        print(f"ğŸš¨ ã‚«ã‚¹ã‚¿ãƒ ã‚¢ãƒ©ãƒ¼ãƒˆ: {alert.message}")

        # Critical ã®å ´åˆã¯ç·Šæ€¥å¯¾å¿œ
        if alert.severity == "critical":
            print("ç·Šæ€¥å¯¾å¿œãŒå¿…è¦ã§ã™ï¼")
            # ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            emergency_backup = manager.create_backup("emergency_alert")
            print(f"ç·Šæ€¥ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {emergency_backup['status']}")

        # Slacké€šçŸ¥ï¼ˆå®Ÿè£…ä¾‹ï¼‰
        # send_slack_notification(alert)

        # ãƒ¡ãƒ¼ãƒ«é€šçŸ¥ï¼ˆå®Ÿè£…ä¾‹ï¼‰
        # send_email_notification(alert)

    # ã‚¢ãƒ©ãƒ¼ãƒˆã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯è¿½åŠ 
    monitoring.add_alert_callback(custom_alert_handler)

    # ç›£è¦–é–‹å§‹
    monitoring.start_monitoring()
    print("ã‚«ã‚¹ã‚¿ãƒ ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ é–‹å§‹")

if __name__ == "__main__":
    setup_custom_monitoring()
```

---

## ğŸ“š SDK Integration

### Python SDK çµ±åˆä¾‹

```python
"""
Day Trading System Python SDK
"""

class DayTradingSDK:
    """Day Trading System SDK"""

    def __init__(self, config_path: str = None):
        self.manager = initialize_unified_database_manager(
            config_path=config_path,
            auto_start=True
        )

    def health_check(self) -> bool:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
        health = self.manager.run_health_check()
        return health["overall_status"] == "healthy"

    def backup(self, backup_type: str = "manual") -> str:
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ"""
        result = self.manager.create_backup(backup_type)
        if result["status"] == "success":
            return result["backup_path"]
        else:
            raise Exception(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å¤±æ•—: {result.get('error')}")

    def get_metrics(self) -> dict:
        """ç¾åœ¨ã®ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—"""
        return self.manager.get_current_metrics()

    def get_alerts(self) -> list:
        """ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆå–å¾—"""
        return self.manager.get_active_alerts()

# SDKä½¿ç”¨ä¾‹
sdk = DayTradingSDK("config/production/database.yaml")

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
if sdk.health_check():
    print("ã‚·ã‚¹ãƒ†ãƒ æ­£å¸¸")

    # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
    backup_path = sdk.backup("sdk_test")
    print(f"ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ: {backup_path}")

    # ãƒ¡ãƒˆãƒªã‚¯ã‚¹å–å¾—
    metrics = sdk.get_metrics()
    print(f"CPU: {metrics['cpu_usage']}%")
```

---

**ã“ã®APIãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã‚’å‚è€ƒã«ã€Day Trading Systemã®çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã‚’åŠ¹æœçš„ã«æ´»ç”¨ã—ã¦ãã ã•ã„ã€‚å„APIã®è©³ç´°ãªä½¿ç”¨æ–¹æ³•ã¨å®Ÿç”¨çš„ãªä¾‹ã‚’é€šã˜ã¦ã€ã‚·ã‚¹ãƒ†ãƒ ã®å…¨æ©Ÿèƒ½ã‚’æœ€å¤§é™ã«æ´»ç”¨ã§ãã¾ã™ã€‚**

---

*æœ€çµ‚æ›´æ–°: 2025å¹´8æœˆ18æ—¥*  
*ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0 (çµ±åˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ å¯¾å¿œ)*