# ãƒ‡ã‚¤ãƒˆãƒ¬ãƒ¼ãƒ‰AIã‚·ã‚¹ãƒ†ãƒ  ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã‚¬ã‚¤ãƒ‰

## ğŸš¨ ç·Šæ€¥æ™‚ã‚¯ã‚¤ãƒƒã‚¯å¯¾å¿œãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

### ã‚·ã‚¹ãƒ†ãƒ åœæ­¢æ™‚ã®ç¢ºèªé …ç›®
- [ ] ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šç¢ºèª
- [ ] Pythonãƒ—ãƒ­ã‚»ã‚¹å‹•ä½œç¢ºèª (`ps aux | grep python`)
- [ ] ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª (`top`, `free -h`)
- [ ] ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ç¢ºèª (`df -h`)
- [ ] æœ€æ–°ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ç¢ºèª

### å¿œæ€¥å‡¦ç½®ã‚³ãƒãƒ³ãƒ‰
```bash
# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
python production_readiness_test.py

# ç·Šæ€¥åœæ­¢
pkill -f python

# ç·Šæ€¥å†èµ·å‹•
python comprehensive_live_validation.py
```

---

## ğŸ” å•é¡Œè¨ºæ–­ãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```
ã‚·ã‚¹ãƒ†ãƒ å•é¡Œç™ºç”Ÿ
       â†“
   ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚ã‚Šï¼Ÿ
   â†“YES          â†“NO
ã‚¨ãƒ©ãƒ¼ã‚³ãƒ¼ãƒ‰å‚ç…§  ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œï¼Ÿ
                â†“YES        â†“NO
            ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª    ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œï¼Ÿ
                           â†“YES      â†“NO
                        æ¥ç¶šç¢ºèª   ãƒ­ã‚°è©³ç´°èª¿æŸ»
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸åˆ¥å¯¾å¿œã‚¬ã‚¤ãƒ‰

### ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢é€£ã‚¨ãƒ©ãƒ¼

#### `No data found, symbol may be delisted`
**åŸå› **: éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ãŒç„¡åŠ¹ã¾ãŸã¯å¸‚å ´ä¼‘æ¥­
```python
# è§£æ±ºæ–¹æ³•
symbols_map = {
    "7203": "ãƒˆãƒ¨ã‚¿è‡ªå‹•è»Š",
    "8306": "ä¸‰è±UFJéŠ€è¡Œ",
    "4751": "ã‚µã‚¤ãƒãƒ¼ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ"
}

# æ­£ã—ã„éŠ˜æŸ„ã‚³ãƒ¼ãƒ‰ç¢ºèª
print("åˆ©ç”¨å¯èƒ½éŠ˜æŸ„:")
for code, name in symbols_map.items():
    print(f"  {code}: {name}")
```

#### `All data sources failed for [symbol]`
**åŸå› **: å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ãŒå¤±æ•—
```python
# æ®µéšçš„è§£æ±º
# 1. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šç¢ºèª
import requests
try:
    response = requests.get("https://www.google.com", timeout=5)
    print(f"ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: OK ({response.status_code})")
except:
    print("ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: NG - ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶šã‚’ç¢ºèª")

# 2. Yahoo Finance APIç¢ºèª
import yfinance as yf
try:
    ticker = yf.Ticker("7203.T")
    data = ticker.history(period="1d")
    print(f"Yahoo Finance: OK ({len(data)}ãƒ¬ã‚³ãƒ¼ãƒ‰)")
except Exception as e:
    print(f"Yahoo Finance: NG - {e}")

# 3. ä»£æ›¿ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
from market_data_stability_system import market_data_stability_system
data = await market_data_stability_system.source_manager.fetch_with_fallback("7203", "5d")
if data is not None:
    print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: OK")
else:
    print("ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: NG - æ‰‹å‹•ãƒ‡ãƒ¼ã‚¿å…¥åŠ›ãŒå¿…è¦")
```

#### `DataFrame.fillna with 'method' is deprecated`
**åŸå› **: Pandasãƒãƒ¼ã‚¸ãƒ§ãƒ³äº’æ›æ€§å•é¡Œ
```python
# è§£æ±ºæ–¹æ³•: ã‚³ãƒ¼ãƒ‰ä¿®æ­£
# å¤ã„æ›¸ãæ–¹
# df.fillna(method='ffill')

# æ–°ã—ã„æ›¸ãæ–¹
df.ffill().bfill()
```

### äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼

#### `äºˆæ¸¬å®Ÿè¡Œã‚¨ãƒ©ãƒ¼`
**è¨ºæ–­æ‰‹é †**:
```python
# 1. ãƒ‡ãƒ¼ã‚¿ç¢ºèª
from real_data_provider_v2 import real_data_provider
data = await real_data_provider.get_stock_data("7203", "5d")
print(f"ãƒ‡ãƒ¼ã‚¿ä»¶æ•°: {len(data) if data is not None else 0}")
if data is None or len(data) < 5:
    print("âŒ ãƒ‡ãƒ¼ã‚¿ä¸è¶³ - æœ€ä½5æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦")

# 2. ç‰¹å¾´é‡ç”Ÿæˆç¢ºèª
from optimized_prediction_system import optimized_prediction_system
if data is not None:
    features = optimized_prediction_system.create_optimized_features(data)
    print(f"ç‰¹å¾´é‡æ•°: {len(features.columns)}")
    print(f"ã‚µãƒ³ãƒ—ãƒ«æ•°: {len(features)}")
    if len(features) < 20:
        print("âš ï¸ ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„ - ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§")

# 3. ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹ç¢ºèª
model_info = optimized_prediction_system.get_model_info("7203")
print(f"ãƒ¢ãƒ‡ãƒ«æƒ…å ±: {model_info}")
```

**è§£æ±ºæ–¹æ³•**:
```python
# ãƒ¢ãƒ‡ãƒ«å†å­¦ç¿’
await optimized_prediction_system.train_optimized_models("7203")

# äºˆæ¸¬å†å®Ÿè¡Œ
prediction = await optimized_prediction_system.predict_with_optimized_models("7203")
print(f"äºˆæ¸¬çµæœ: {prediction}")
```

#### `æœ€é©åŒ–ç‰¹å¾´é‡ä½œæˆå®Œäº†: 80ç‰¹å¾´é‡, 22ã‚µãƒ³ãƒ—ãƒ«`
**çŠ¶æ³**: ãƒ‡ãƒ¼ã‚¿ã¯æ­£å¸¸ã€ã‚µãƒ³ãƒ—ãƒ«æ•°ãŒå°‘ãªã„
```python
# ã‚ˆã‚Šé•·æœŸé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
longer_data = await real_data_provider.get_stock_data("7203", "3mo")  # 3ãƒ¶æœˆåˆ†
if longer_data is not None and len(longer_data) > 50:
    print("âœ… ååˆ†ãªãƒ‡ãƒ¼ã‚¿å–å¾—")
    # äºˆæ¸¬å®Ÿè¡Œ
    prediction = await optimized_prediction_system.predict_with_optimized_models("7203")
else:
    print("âš ï¸ é•·æœŸãƒ‡ãƒ¼ã‚¿ã‚‚ä¸è¶³ - äºˆæ¸¬ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§")
```

### ãƒªã‚¹ã‚¯ç®¡ç†ã‚¨ãƒ©ãƒ¼

#### `ãƒªã‚¹ã‚¯è¨ˆç®—ã‚¨ãƒ©ãƒ¼`
**è¨ºæ–­**:
```python
# å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç¢ºèª
from production_risk_management_validator import production_risk_validator
risk_metrics = await production_risk_validator.risk_engine.calculate_comprehensive_risk_metrics("7203")

if risk_metrics is None:
    # è©³ç´°è¨ºæ–­
    data = await production_risk_validator.risk_engine._get_market_data("7203", "3mo")
    print(f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿: {len(data) if data else 0}ãƒ¬ã‚³ãƒ¼ãƒ‰")

    if data is not None and len(data) > 0:
        returns = data['Close'].pct_change().dropna()
        print(f"ãƒªã‚¿ãƒ¼ãƒ³è¨ˆç®—: {len(returns)}ã‚µãƒ³ãƒ—ãƒ«")

        if len(returns) > 10:
            print("âœ… ãƒªã‚¹ã‚¯è¨ˆç®—ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿")
        else:
            print("âŒ ãƒªã‚¹ã‚¯è¨ˆç®—ã«ã¯ãƒ‡ãƒ¼ã‚¿ä¸è¶³")
```

#### `ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ãŒé«˜ã™ãã¾ã™`
**å¯¾å¿œæ–¹æ³•**:
```python
# ãƒªã‚¹ã‚¯åˆ¶é™ã®èª¿æ•´æ¤œè¨
from production_risk_management_validator import production_risk_validator

# ç¾åœ¨ã®åˆ¶é™ç¢ºèª
print("ç¾åœ¨ã®ãƒªã‚¹ã‚¯åˆ¶é™:")
for key, value in production_risk_validator.risk_limits.items():
    print(f"  {key}: {value}")

# ä¸€æ™‚çš„ãªåˆ¶é™ç·©å’Œï¼ˆæ³¨æ„ã—ã¦ä½¿ç”¨ï¼‰
# production_risk_validator.risk_limits['max_drawdown'] = 0.15  # 10% â†’ 15%

# ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºèª¿æ•´
original_size = 1000000
risk_result = await production_risk_validator.validate_trading_risk("7203", original_size)
if not risk_result['validation_passed']:
    # ã‚µã‚¤ã‚ºã‚’50%ã«å‰Šæ¸›
    reduced_size = original_size * 0.5
    new_result = await production_risk_validator.validate_trading_risk("7203", reduced_size)
    print(f"ãƒã‚¸ã‚·ãƒ§ãƒ³ã‚µã‚¤ã‚ºå‰Šæ¸›çµæœ: {new_result['overall_assessment']}")
```

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å•é¡Œ

#### é«˜CPUä½¿ç”¨ç‡ (`CPUä½¿ç”¨ç‡: >85%`)
```python
# 1. ç¾åœ¨ã®çŠ¶æ³ç¢ºèª
import psutil
cpu_percent = psutil.cpu_percent(interval=1)
memory_percent = psutil.virtual_memory().percent
print(f"CPU: {cpu_percent}%, ãƒ¡ãƒ¢ãƒª: {memory_percent}%")

# 2. é‡ã„ãƒ—ãƒ­ã‚»ã‚¹ç‰¹å®š
for proc in psutil.process_iter(['pid', 'name', 'cpu_percent']):
    if proc.info['cpu_percent'] > 5.0:
        print(f"ãƒ—ãƒ­ã‚»ã‚¹ {proc.info['pid']}: {proc.info['name']} - {proc.info['cpu_percent']}%")

# 3. è‡ªå‹•èª¿æ•´ã«ã‚ˆã‚‹å¯¾å¿œ
from realtime_monitoring_auto_tuning import realtime_monitoring_system
health = realtime_monitoring_system._collect_system_health()
tuning_actions = realtime_monitoring_system.auto_tuner.evaluate_and_apply_optimizations(health)

for action in tuning_actions:
    print(f"è‡ªå‹•èª¿æ•´: {action.reason} - {action.parameter} {action.old_value} â†’ {action.new_value}")
```

#### é«˜ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ (`ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: >90%`)
```python
# 1. ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
import gc
collected = gc.collect()
print(f"ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å")

# 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç¸®å°
from realtime_performance_optimizer import realtime_performance_optimizer
old_size = realtime_performance_optimizer.data_cache.max_size
realtime_performance_optimizer.data_cache.max_size = old_size // 2
print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºç¸®å°: {old_size} â†’ {old_size // 2}")

# 3. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
realtime_performance_optimizer.data_cache.cache.clear()
realtime_performance_optimizer.prediction_cache.cache.clear()
print("ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†")

# 4. ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å†ç¢ºèª
new_memory = psutil.virtual_memory().percent
print(f"ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {new_memory}%")
```

#### ä½ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡ (`ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: <60%`)
```python
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆç¢ºèª
from realtime_performance_optimizer import realtime_performance_optimizer

caches = {
    'data_cache': realtime_performance_optimizer.data_cache,
    'prediction_cache': realtime_performance_optimizer.prediction_cache,
    'analysis_cache': realtime_performance_optimizer.analysis_cache
}

for name, cache in caches.items():
    stats = cache.get_stats()
    print(f"{name}:")
    print(f"  ãƒ’ãƒƒãƒˆç‡: {stats['hit_rate']:.1%}")
    print(f"  ã‚µã‚¤ã‚º: {stats['size']}")
    print(f"  ç·ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {stats['total_requests']}")

# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå¢—åŠ ã«ã‚ˆã‚‹æ”¹å–„
if stats['hit_rate'] < 0.6:
    old_size = cache.max_size
    cache.max_size = int(old_size * 1.5)
    print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå¢—åŠ : {old_size} â†’ {cache.max_size}")
```

### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã‚¨ãƒ©ãƒ¼

#### `table alert_rules has no column named name`
**åŸå› **: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒä¸ä¸€è‡´
```python
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒç¢ºèªãƒ»ä¿®æ­£
import sqlite3

db_path = "alert_data/alerts.db"
with sqlite3.connect(db_path) as conn:
    cursor = conn.cursor()

    # ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
    cursor.execute("PRAGMA table_info(alert_rules);")
    columns = cursor.fetchall()
    print("ç¾åœ¨ã®ã‚«ãƒ©ãƒ :")
    for col in columns:
        print(f"  {col[1]} ({col[2]})")

    # ä¸è¶³ã‚«ãƒ©ãƒ è¿½åŠ 
    try:
        cursor.execute("ALTER TABLE alert_rules ADD COLUMN name TEXT;")
        print("nameã‚«ãƒ©ãƒ è¿½åŠ å®Œäº†")
    except sqlite3.OperationalError as e:
        if "duplicate column name" in str(e):
            print("nameã‚«ãƒ©ãƒ ã¯æ—¢ã«å­˜åœ¨")
        else:
            print(f"ã‚«ãƒ©ãƒ è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
```

#### `Object of type datetime is not JSON serializable`
**è§£æ±º**:
```python
# JSON serializationå•é¡Œã®ä¿®æ­£
import json
from datetime import datetime

class DateTimeEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

# ä½¿ç”¨ä¾‹
data = {'timestamp': datetime.now(), 'value': 100}
json_string = json.dumps(data, cls=DateTimeEncoder)
print(f"JSON: {json_string}")
```

### ã‚¢ãƒ©ãƒ¼ãƒˆé–¢é€£ã‚¨ãƒ©ãƒ¼

#### `no running event loop`
**åŸå› **: éåŒæœŸå‡¦ç†ã®ä¸é©åˆ‡ãªå®Ÿè¡Œ
```python
# ä¿®æ­£æ–¹æ³•
import asyncio

# å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰
# await some_async_function()  # ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—å¤–ã§ã®å®Ÿè¡Œ

# ä¿®æ­£ç‰ˆ
def fixed_notification_worker():
    loop = None
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError:
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)

    # éåŒæœŸé–¢æ•°ã‚’åŒæœŸçš„ã«å®Ÿè¡Œ
    if loop:
        loop.run_until_complete(async_function())
```

#### ã‚¢ãƒ©ãƒ¼ãƒˆãŒç™ºç«ã—ãªã„
```python
# ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®šç¢ºèª
from realtime_alert_notification_system import realtime_alert_system

# ãƒ«ãƒ¼ãƒ«ç¢ºèª
for rule_id, rule in realtime_alert_system.alert_rules.items():
    print(f"ãƒ«ãƒ¼ãƒ« {rule_id}:")
    print(f"  æœ‰åŠ¹: {rule.enabled}")
    print(f"  æ¡ä»¶: {rule.condition}")
    print(f"  æœ€çµ‚ç™ºç«: {rule.last_triggered}")
    print(f"  ç™ºç«å›æ•°: {rule.trigger_count}")

# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã‚¢ãƒ©ãƒ¼ãƒˆç™ºç«ãƒ†ã‚¹ãƒˆ
realtime_alert_system.update_market_data("TEST", {
    'current_price': 3000,
    'current_change': 0.08,  # 8%å¤‰å‹•ï¼ˆ5%è¶…éã§ã‚¢ãƒ©ãƒ¼ãƒˆï¼‰
    'volume_ratio': 2.0,
    'signal_strength': 50,
    'risk_score': 30,
    'volatility': 0.2,
    'prediction_confidence': 0.6,
    'signal_consensus': 0.5,
    'error_count': 0
})

await realtime_alert_system.check_alert_conditions("TEST")
active_alerts = realtime_alert_system.get_active_alerts()
print(f"ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã‚¢ãƒ©ãƒ¼ãƒˆ: {len(active_alerts)}ä»¶")
```

---

## ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§æ‰‹é †

### ãƒ¬ãƒ™ãƒ«1: è»½å¾®ãªå•é¡Œ (5åˆ†ä»¥å†…å¾©æ—§)

```bash
# 1. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
python -c "
import asyncio
from realtime_monitoring_auto_tuning import realtime_monitoring_system
async def quick_check():
    health = realtime_monitoring_system._collect_system_health()
    print(f'CPU: {health.cpu_usage:.1f}% | ãƒ¡ãƒ¢ãƒª: {health.memory_usage:.1f}% | çŠ¶æ…‹: {health.performance_level.value}')
asyncio.run(quick_check())
"

# 2. è»½å¾®ãªæœ€é©åŒ–
python -c "
import gc
from realtime_performance_optimizer import realtime_performance_optimizer
collected = gc.collect()
print(f'GC: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å')
stats = realtime_performance_optimizer.data_cache.get_stats()
print(f'ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡: {stats[\"hit_rate\"]:.1%}')
"

# 3. å‹•ä½œç¢ºèª
python production_readiness_test.py
```

### ãƒ¬ãƒ™ãƒ«2: ä¸­ç¨‹åº¦ã®å•é¡Œ (15åˆ†ä»¥å†…å¾©æ—§)

```bash
# 1. ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå€‹åˆ¥ãƒã‚§ãƒƒã‚¯
echo "=== ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ç¢ºèª ==="
python -c "
import asyncio
from real_data_provider_v2 import real_data_provider
async def test_data():
    data = await real_data_provider.get_stock_data('7203', '5d')
    print(f'ãƒ‡ãƒ¼ã‚¿å–å¾—: {\"OK\" if data is not None else \"NG\"} ({len(data) if data else 0}ä»¶)')
asyncio.run(test_data())
"

echo "=== äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ç¢ºèª ==="
python -c "
import asyncio
from optimized_prediction_system import optimized_prediction_system
async def test_prediction():
    try:
        prediction = await optimized_prediction_system.predict_with_optimized_models('7203')
        print(f'äºˆæ¸¬: OK (ä¿¡é ¼åº¦: {prediction.confidence:.2f})')
    except Exception as e:
        print(f'äºˆæ¸¬: NG ({e})')
asyncio.run(test_prediction())
"

# 2. å•é¡ŒãŒã‚ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®å†åˆæœŸåŒ–
python -c "
# ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢ã¨å†åˆæœŸåŒ–
from realtime_performance_optimizer import realtime_performance_optimizer
realtime_performance_optimizer.data_cache.cache.clear()
realtime_performance_optimizer.prediction_cache.cache.clear()
print('ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å®Œäº†')

# ã‚¬ãƒ™ãƒ¼ã‚¸ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³
import gc
collected = gc.collect()
print(f'ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å')
"

# 3. ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“å†æ¤œè¨¼
python comprehensive_live_validation.py
```

### ãƒ¬ãƒ™ãƒ«3: æ·±åˆ»ãªå•é¡Œ (1æ™‚é–“ä»¥å†…å¾©æ—§)

```bash
# 1. ç·Šæ€¥åœæ­¢
echo "ã‚·ã‚¹ãƒ†ãƒ ç·Šæ€¥åœæ­¢ä¸­..."
pkill -f python
sleep 2

# 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
echo "ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆä¸­..."
timestamp=$(date +%Y%m%d_%H%M%S)
mkdir -p backup_$timestamp

# å…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
find . -name "*.db" -exec cp {} backup_$timestamp/ \;
echo "ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Œäº†: backup_$timestamp"

# 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
python -c "
import sqlite3
from pathlib import Path

def check_db_integrity():
    db_files = list(Path('.').glob('**/*.db'))
    corrupted = []

    for db_file in db_files:
        try:
            with sqlite3.connect(db_file) as conn:
                cursor = conn.cursor()
                cursor.execute('PRAGMA integrity_check;')
                result = cursor.fetchone()[0]
                if result != 'ok':
                    corrupted.append(str(db_file))
                    print(f'âŒ {db_file}: {result}')
                else:
                    print(f'âœ… {db_file}: OK')
        except Exception as e:
            corrupted.append(str(db_file))
            print(f'âŒ {db_file}: {e}')

    return corrupted

corrupted_dbs = check_db_integrity()
if corrupted_dbs:
    print(f'ç ´æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {len(corrupted_dbs)}ä»¶')
    for db in corrupted_dbs:
        print(f'  - {db}')
else:
    print('å…¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®æ•´åˆæ€§: OK')
"

# 4. ç ´æãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ä¿®å¾©
python -c "
import sqlite3
import os
from pathlib import Path

def repair_databases():
    db_files = list(Path('.').glob('**/*.db'))

    for db_file in db_files:
        try:
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä½œæˆ
            backup_file = f'{db_file}.repair_backup'
            os.system(f'cp {db_file} {backup_file}')

            # ä¿®å¾©è©¦è¡Œ
            with sqlite3.connect(db_file) as conn:
                conn.execute('VACUUM;')
                conn.execute('REINDEX;')
                print(f'âœ… ä¿®å¾©å®Œäº†: {db_file}')

        except Exception as e:
            print(f'âŒ ä¿®å¾©å¤±æ•—: {db_file} - {e}')
            # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
            if os.path.exists(backup_file):
                os.system(f'cp {backup_file} {db_file}')

repair_databases()
"

# 5. æ®µéšçš„ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§
echo "æ®µéšçš„ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§é–‹å§‹..."

echo "Phase 1: åŸºæœ¬æ©Ÿèƒ½ç¢ºèª"
python production_readiness_test.py

echo "Phase 2: å€‹åˆ¥ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç¢ºèª"
python -c "
import asyncio

async def component_check():
    components = []

    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼
    try:
        from real_data_provider_v2 import real_data_provider
        data = await real_data_provider.get_stock_data('7203', '5d')
        components.append(('ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼', 'OK' if data else 'NG'))
    except Exception as e:
        components.append(('ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼', f'NG: {e}'))

    # äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ 
    try:
        from optimized_prediction_system import optimized_prediction_system
        pred = await optimized_prediction_system.predict_with_optimized_models('7203')
        components.append(('äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ', 'OK' if pred else 'NG'))
    except Exception as e:
        components.append(('äºˆæ¸¬ã‚·ã‚¹ãƒ†ãƒ ', f'NG: {e}'))

    # ãƒªã‚¹ã‚¯ç®¡ç†
    try:
        from production_risk_management_validator import production_risk_validator
        risk = await production_risk_validator.validate_trading_risk('7203', 1000000)
        components.append(('ãƒªã‚¹ã‚¯ç®¡ç†', 'OK' if risk['validation_passed'] else 'WARNING'))
    except Exception as e:
        components.append(('ãƒªã‚¹ã‚¯ç®¡ç†', f'NG: {e}'))

    print('=== ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆçŠ¶æ³ ===')
    for name, status in components:
        emoji = 'âœ…' if 'OK' in status else 'âš ï¸' if 'WARNING' in status else 'âŒ'
        print(f'{emoji} {name}: {status}')

    return components

asyncio.run(component_check())
"

echo "Phase 3: ã‚·ã‚¹ãƒ†ãƒ çµ±åˆç¢ºèª"
python comprehensive_live_validation.py

echo "å¾©æ—§å®Œäº†ç¢ºèª"
python -c "
print('=== ã‚·ã‚¹ãƒ†ãƒ å¾©æ—§ç¢ºèª ===')
import os
print(f'ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {os.getcwd()}')
print(f'Pythonãƒãƒ¼ã‚¸ãƒ§ãƒ³: {os.popen(\"python --version\").read().strip()}')
print('é‡è¦ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª:')
files = [
    'production_readiness_test.py',
    'comprehensive_live_validation.py',
    'real_data_provider_v2.py',
    'optimized_prediction_system.py'
]
for file in files:
    exists = os.path.exists(file)
    print(f'  {\"âœ…\" if exists else \"âŒ\"} {file}')
"
```

---

## ğŸ“Š ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­ãƒ„ãƒ¼ãƒ«

### ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```python
#!/usr/bin/env python3
"""
ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­ãƒ„ãƒ¼ãƒ«
"""
import asyncio
import time
import psutil
import numpy as np
from datetime import datetime

async def performance_diagnostic():
    print("=== ã‚·ã‚¹ãƒ†ãƒ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è¨ºæ–­ ===")
    print(f"è¨ºæ–­é–‹å§‹æ™‚åˆ»: {datetime.now()}")

    # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹
    print(f"\nğŸ“Š ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹:")
    print(f"  CPUä½¿ç”¨ç‡: {psutil.cpu_percent(interval=1):.1f}%")
    print(f"  ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡: {psutil.virtual_memory().percent:.1f}%")
    print(f"  ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡: {psutil.disk_usage('/').percent:.1f}%")

    # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶æ¸¬å®š
    print(f"\nğŸŒ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é…å»¶:")
    import subprocess
    try:
        result = subprocess.run(['ping', '-c', '3', 'finance.yahoo.com'],
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            print("  Yahoo Finance: OK")
        else:
            print("  Yahoo Finance: NG - æ¥ç¶šå•é¡Œã‚ã‚Š")
    except:
        print("  Yahoo Finance: æ¸¬å®šä¸å¯")

    # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¿œç­”æ™‚é–“æ¸¬å®š
    print(f"\nâš¡ ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆå¿œç­”æ™‚é–“:")

    # ãƒ‡ãƒ¼ã‚¿å–å¾—é€Ÿåº¦
    start = time.time()
    try:
        from real_data_provider_v2 import real_data_provider
        data = await real_data_provider.get_stock_data("7203", "5d")
        data_time = time.time() - start
        print(f"  ãƒ‡ãƒ¼ã‚¿å–å¾—: {data_time:.2f}ç§’ ({'OK' if data_time < 3 else 'SLOW'})")
    except Exception as e:
        print(f"  ãƒ‡ãƒ¼ã‚¿å–å¾—: ã‚¨ãƒ©ãƒ¼ - {e}")

    # äºˆæ¸¬é€Ÿåº¦
    start = time.time()
    try:
        from optimized_prediction_system import optimized_prediction_system
        prediction = await optimized_prediction_system.predict_with_optimized_models("7203")
        pred_time = time.time() - start
        print(f"  äºˆæ¸¬å‡¦ç†: {pred_time:.2f}ç§’ ({'OK' if pred_time < 5 else 'SLOW'})")
    except Exception as e:
        print(f"  äºˆæ¸¬å‡¦ç†: ã‚¨ãƒ©ãƒ¼ - {e}")

    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹æœæ¸¬å®š
    print(f"\nğŸ’¾ ã‚­ãƒ£ãƒƒã‚·ãƒ¥æ€§èƒ½:")
    try:
        from realtime_performance_optimizer import realtime_performance_optimizer

        # 1å›ç›®ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒŸã‚¹ï¼‰
        start = time.time()
        await realtime_performance_optimizer.optimize_data_retrieval("7203")
        first_time = time.time() - start

        # 2å›ç›®ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆï¼‰
        start = time.time()
        await realtime_performance_optimizer.optimize_data_retrieval("7203")
        second_time = time.time() - start

        if second_time > 0:
            speedup = first_time / second_time
            print(f"  1å›ç›®: {first_time:.2f}ç§’")
            print(f"  2å›ç›®: {second_time:.2f}ç§’")
            print(f"  é«˜é€ŸåŒ–: {speedup:.1f}x ({'EXCELLENT' if speedup > 5 else 'GOOD' if speedup > 2 else 'POOR'})")

        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥çµ±è¨ˆ
        cache_stats = realtime_performance_optimizer.data_cache.get_stats()
        print(f"  ãƒ’ãƒƒãƒˆç‡: {cache_stats['hit_rate']:.1%}")

    except Exception as e:
        print(f"  ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ†ã‚¹ãƒˆ: ã‚¨ãƒ©ãƒ¼ - {e}")

    print(f"\nè¨ºæ–­å®Œäº†æ™‚åˆ»: {datetime.now()}")

if __name__ == "__main__":
    asyncio.run(performance_diagnostic())
```

ä¿å­˜ã—ã¦å®Ÿè¡Œ:
```bash
python performance_diagnostic.py
```

---

## ğŸš¨ ç·Šæ€¥äº‹æ…‹å¯¾å¿œãƒ—ãƒ¬ã‚¤ãƒ–ãƒƒã‚¯

### Phase 1: çŠ¶æ³ç¢ºèª (2åˆ†ä»¥å†…)
```bash
#!/bin/bash
echo "=== ç·Šæ€¥äº‹æ…‹å¯¾å¿œé–‹å§‹ ==="
echo "æ™‚åˆ»: $(date)"

# 1. ã‚·ã‚¹ãƒ†ãƒ ç”Ÿå­˜ç¢ºèª
echo "1. ã‚·ã‚¹ãƒ†ãƒ ç”Ÿå­˜ç¢ºèª"
if pgrep -f python > /dev/null; then
    echo "âœ… Pythonãƒ—ãƒ­ã‚»ã‚¹ç¨¼åƒä¸­"
else
    echo "âŒ Pythonãƒ—ãƒ­ã‚»ã‚¹åœæ­¢"
fi

# 2. ãƒªã‚½ãƒ¼ã‚¹ç¢ºèª
echo "2. ãƒªã‚½ãƒ¼ã‚¹çŠ¶æ³"
echo "  CPU: $(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//')%"
echo "  ãƒ¡ãƒ¢ãƒª: $(free | grep Mem | awk '{printf "%.1f", $3/$2 * 100.0}')%"
echo "  ãƒ‡ã‚£ã‚¹ã‚¯: $(df -h . | tail -1 | awk '{print $5}')"

# 3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª
echo "3. ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ç¢ºèª"
if ping -c 1 google.com > /dev/null 2>&1; then
    echo "âœ… ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š: OK"
else
    echo "âŒ ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆæ¥ç¶š: NG"
fi
```

### Phase 2: å¿œæ€¥å‡¦ç½® (5åˆ†ä»¥å†…)
```python
#!/usr/bin/env python3
"""
ç·Šæ€¥å¿œæ€¥å‡¦ç½®ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""
import os
import gc
import psutil
import asyncio
from datetime import datetime

async def emergency_response():
    print("=== ç·Šæ€¥å¿œæ€¥å‡¦ç½®é–‹å§‹ ===")
    actions = []

    # 1. ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
    try:
        before_mem = psutil.virtual_memory().percent
        collected = gc.collect()
        after_mem = psutil.virtual_memory().percent
        actions.append(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—: {before_mem:.1f}% â†’ {after_mem:.1f}% ({collected}ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå›å)")
    except Exception as e:
        actions.append(f"ãƒ¡ãƒ¢ãƒªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")

    # 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢
    try:
        from realtime_performance_optimizer import realtime_performance_optimizer
        old_size = len(realtime_performance_optimizer.data_cache.cache)
        realtime_performance_optimizer.data_cache.cache.clear()
        realtime_performance_optimizer.prediction_cache.cache.clear()
        actions.append(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢: {old_size}ã‚¨ãƒ³ãƒˆãƒªå‰Šé™¤")
    except Exception as e:
        actions.append(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚¯ãƒªã‚¢å¤±æ•—: {e}")

    # 3. åŸºæœ¬æ©Ÿèƒ½ç¢ºèª
    try:
        from real_data_provider_v2 import real_data_provider
        data = await real_data_provider.get_stock_data("7203", "1d")
        if data is not None:
            actions.append(f"ãƒ‡ãƒ¼ã‚¿å–å¾—: OK ({len(data)}ãƒ¬ã‚³ãƒ¼ãƒ‰)")
        else:
            actions.append("ãƒ‡ãƒ¼ã‚¿å–å¾—: NG")
    except Exception as e:
        actions.append(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")

    # 4. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹è¨˜éŒ²
    status_file = f"emergency_status_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
    with open(status_file, 'w') as f:
        f.write(f"ç·Šæ€¥å¯¾å¿œå®Ÿè¡Œæ™‚åˆ»: {datetime.now()}\n")
        for action in actions:
            f.write(f"- {action}\n")

    actions.append(f"çŠ¶æ…‹è¨˜éŒ²: {status_file}")

    # çµæœè¡¨ç¤º
    for action in actions:
        print(f"  {action}")

    print("=== ç·Šæ€¥å¿œæ€¥å‡¦ç½®å®Œäº† ===")

if __name__ == "__main__":
    asyncio.run(emergency_response())
```

### Phase 3: å›å¾©ç¢ºèª (10åˆ†ä»¥å†…)
```bash
# å›å¾©ç¢ºèªã‚¹ã‚¯ãƒªãƒ—ãƒˆ
echo "=== å›å¾©ç¢ºèªé–‹å§‹ ==="

# åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ
echo "1. åŸºæœ¬æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"
python -c "
import asyncio
async def basic_test():
    try:
        from real_data_provider_v2 import real_data_provider
        data = await real_data_provider.get_stock_data('7203', '1d')
        print(f'  ãƒ‡ãƒ¼ã‚¿å–å¾—: {\"OK\" if data is not None else \"NG\"}')
    except Exception as e:
        print(f'  ãƒ‡ãƒ¼ã‚¿å–å¾—: ã‚¨ãƒ©ãƒ¼ - {e}')

    try:
        from optimized_prediction_system import optimized_prediction_system
        pred = await optimized_prediction_system.predict_with_optimized_models('7203')
        print(f'  äºˆæ¸¬: {\"OK\" if pred else \"NG\"}')
    except Exception as e:
        print(f'  äºˆæ¸¬: ã‚¨ãƒ©ãƒ¼ - {e}')

asyncio.run(basic_test())
"

# ã‚¯ã‚¤ãƒƒã‚¯æ¤œè¨¼
echo "2. ã‚¯ã‚¤ãƒƒã‚¯æ¤œè¨¼å®Ÿè¡Œ"
python production_readiness_test.py | tail -5

# ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
echo "3. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹"
python -c "
import psutil
print(f'  CPU: {psutil.cpu_percent():.1f}%')
print(f'  ãƒ¡ãƒ¢ãƒª: {psutil.virtual_memory().percent:.1f}%')
print(f'  ãƒ—ãƒ­ã‚»ã‚¹æ•°: {len(psutil.pids())}')
"

echo "=== å›å¾©ç¢ºèªå®Œäº† ==="
```

---

## ğŸ“ ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åŸºæº–

### è‡ªå‹•ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ¡ä»¶
- ã‚·ã‚¹ãƒ†ãƒ åœæ­¢ > 30åˆ†
- ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—ç‡ > 50%
- äºˆæ¸¬ç²¾åº¦ < 40%
- ãƒ¡ãƒ¢ãƒªä½¿ç”¨ç‡ > 95%
- é€£ç¶šã‚¨ãƒ©ãƒ¼ > 100ä»¶

### æ‰‹å‹•ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¤æ–­åŸºæº–
- æ¥­å‹™æ™‚é–“ä¸­ã®éƒ¨åˆ†çš„æ©Ÿèƒ½åœæ­¢
- ãƒ‡ãƒ¼ã‚¿ç ´æã®ç–‘ã„
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆ
- å¾©æ—§æ‰‹é †ã§è§£æ±ºã§ããªã„å•é¡Œ

---

**æœ€çµ‚æ›´æ–°**: 2025å¹´8æœˆ14æ—¥  
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: 1.0.0  
**ç·Šæ€¥é€£çµ¡**: ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã¾ã§