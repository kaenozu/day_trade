# MLå‡¦ç†ä¸¦åˆ—åŒ–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ
**Issue #323: ML Processing Parallelization for Throughput Improvement**

---

## ğŸ“Š ç¾åœ¨ã®MLå‡¦ç†ãƒœãƒˆãƒ«ãƒãƒƒã‚¯åˆ†æ

### æ¤œå‡ºã•ã‚ŒãŸæ€§èƒ½å•é¡Œ

1. **ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†ã®é™ç•Œ**
   - å˜ä¸€ã‚¹ãƒ¬ãƒƒãƒ‰å‡¦ç†ã«ã‚ˆã‚‹ä½ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ
   - CPUãƒãƒ«ãƒã‚³ã‚¢åˆ©ç”¨ç‡ã®ä½ã•
   - I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã§ã®å¾…æ©Ÿæ™‚é–“

2. **æ—¢å­˜ã®ä¸¦åˆ—åŒ–å®Ÿè£…çŠ¶æ³**
   - `TOPIX500ParallelEngine`: åŸºæœ¬çš„ãªä¸¦åˆ—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯å­˜åœ¨
   - `ParallelMLEngine`: ä¸€éƒ¨å®Ÿè£…æ¸ˆã¿ï¼ˆadvanced_ml_engine.pyå†…ï¼‰
   - `BatchDataFetcher`: ãƒ‡ãƒ¼ã‚¿å–å¾—ã®ä¸¦åˆ—åŒ–å¯¾å¿œæ¸ˆã¿

### æ€§èƒ½æ¸¬å®šçµæœï¼ˆIssue #325ã‚ˆã‚Šï¼‰

```
ã‚·ãƒ¼ã‚±ãƒ³ã‚·ãƒ£ãƒ«å‡¦ç†:
- æŠ€è¡“æŒ‡æ¨™è¨ˆç®—: 23.6ç§’ï¼ˆæœ€å¤§ãƒœãƒˆãƒ«ãƒãƒƒã‚¯ï¼‰
- MLç‰¹å¾´é‡æº–å‚™: 3.2ç§’  
- ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬: 1.8ç§’
- ç·å‡¦ç†æ™‚é–“: 28.6ç§’/éŠ˜æŸ„

æœ€é©åŒ–å¾Œï¼ˆIssue #325):
- æŠ€è¡“æŒ‡æ¨™è¨ˆç®—: 0.3ç§’ï¼ˆ97%æ”¹å–„ï¼‰
- MLç‰¹å¾´é‡æº–å‚™: 1.1ç§’
- ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬: 0.8ç§’
- ç·å‡¦ç†æ™‚é–“: 2.2ç§’/éŠ˜æŸ„
```

---

## ğŸ” ä¸¦åˆ—å‡¦ç†ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£åˆ†æ

### ç¾åœ¨ã®ä¸¦åˆ—åŒ–ãƒ¬ãƒ™ãƒ«

1. **ãƒ‡ãƒ¼ã‚¿å–å¾—å±¤ï¼ˆLevel 1ï¼‰**
   - `BatchDataFetcher`: âœ… å®Ÿè£…æ¸ˆã¿
   - è¤‡æ•°éŠ˜æŸ„ã®åŒæ™‚APIå‘¼ã³å‡ºã—
   - åŠ¹æœ: ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“50%çŸ­ç¸®

2. **MLå‡¦ç†å±¤ï¼ˆLevel 2ï¼‰**
   - `ParallelMLEngine`: ğŸ”„ éƒ¨åˆ†å®Ÿè£…
   - éŠ˜æŸ„å˜ä½ã®ä¸¦åˆ—å‡¦ç†
   - ç¾çŠ¶: åŸºæœ¬ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ã¿

3. **ãƒãƒƒãƒå‡¦ç†å±¤ï¼ˆLevel 3ï¼‰**
   - `TOPIX500ParallelEngine`: âœ… å®Ÿè£…æ¸ˆã¿
   - ãƒãƒƒãƒå˜ä½ã®ãƒ—ãƒ­ã‚»ã‚¹ä¸¦åˆ—åŒ–
   - ãƒ¡ãƒ¢ãƒªåŠ¹ç‡ç®¡ç†å¯¾å¿œ

### ä¸¦åˆ—åŒ–ã®èª²é¡Œ

```python
# ç¾åœ¨ã®å®Ÿè£…ã«ãŠã‘ã‚‹åˆ¶ç´„
1. GIL (Global Interpreter Lock)
   - ã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—åŒ–ã®åˆ¶ç´„
   - CPUé›†ç´„çš„å‡¦ç†ã§ã®æ€§èƒ½é™ç•Œ

2. ãƒ¡ãƒ¢ãƒªç®¡ç†
   - ä¸¦åˆ—ãƒ—ãƒ­ã‚»ã‚¹é–“ã§ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡
   - ã‚­ãƒ£ãƒƒã‚·ãƒ¥å…±æœ‰ã®è¤‡é›‘æ€§

3. ãƒ¢ãƒ‡ãƒ«å…±æœ‰
   - å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¸¦åˆ—ã‚¢ã‚¯ã‚»ã‚¹
   - ãƒ©ã‚¤ãƒ–ãƒ©ãƒªä¾å­˜é–¢ä¿‚ã®é‡è¤‡
```

---

## âš¡ æœ€é©åŒ–æˆ¦ç•¥è¨­è¨ˆ

### 1. ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ä¸¦åˆ—åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Master Orchestrator                â”‚
â”‚         (çµ±åˆåˆ¶å¾¡ãƒ»è² è·åˆ†æ•£ãƒ»ãƒªã‚½ãƒ¼ã‚¹ç®¡ç†)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Process Pool   â”‚  â”‚  Thread Pool    â”‚  â”‚  Async Pool     â”‚
â”‚  (CPUé›†ç´„å‡¦ç†)   â”‚  â”‚  (I/Oå‡¦ç†)      â”‚  â”‚  (APIå‘¼ã³å‡ºã—)   â”‚
â”‚                â”‚  â”‚                â”‚  â”‚                â”‚
â”‚ - MLè¨ˆç®—        â”‚  â”‚ - ãƒ‡ãƒ¼ã‚¿å¤‰æ›    â”‚  â”‚ - æ ªä¾¡å–å¾—      â”‚
â”‚ - æŠ€è¡“æŒ‡æ¨™      â”‚  â”‚ - ã‚­ãƒ£ãƒƒã‚·ãƒ¥    â”‚  â”‚ - ãƒ‹ãƒ¥ãƒ¼ã‚¹å–å¾—   â”‚
â”‚ - ãƒ¢ãƒ‡ãƒ«è¨“ç·´    â”‚  â”‚ - ãƒ•ã‚¡ã‚¤ãƒ«I/O   â”‚  â”‚ - å¤–éƒ¨API      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ¥ä¸¦åˆ—åŒ–æˆ¦ç•¥

| ãƒ¬ã‚¤ãƒ¤ãƒ¼ | ä¸¦åˆ—åŒ–æ‰‹æ³• | æœ€å¤§workeræ•° | æœŸå¾…åŠ¹æœ |
|----------|-----------|-------------|----------|
| **ãƒ‡ãƒ¼ã‚¿å–å¾—** | AsyncIO | 20 | 5xé«˜é€ŸåŒ– |
| **å‰å‡¦ç†** | ThreadPool | 4-8 | 2xé«˜é€ŸåŒ– |
| **MLè¨ˆç®—** | ProcessPool | CPUæ•° | 4xé«˜é€ŸåŒ– |
| **å¾Œå‡¦ç†** | ThreadPool | 4 | 1.5xé«˜é€ŸåŒ– |

### 3. å‹•çš„è² è·åˆ†æ•£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 

```python
class AdaptiveLoadBalancer:
    """å‹•çš„è² è·åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ """

    def calculate_optimal_workers(self, task_type: str, system_resources: dict) -> int:
        """ã‚¿ã‚¹ã‚¯ç¨®åˆ¥ã«å¿œã˜ãŸæœ€é©workeræ•°ç®—å‡º"""

        if task_type == "ml_computation":
            # CPUé›†ç´„çš„: CPUã‚³ã‚¢æ•°ãƒ™ãƒ¼ã‚¹
            return min(system_resources['cpu_count'], 8)

        elif task_type == "data_fetching":
            # I/Oãƒã‚¦ãƒ³ãƒ‰: é«˜ä¸¦åˆ—
            return min(system_resources['memory_gb'] * 4, 20)

        elif task_type == "preprocessing":
            # ä¸­é–“å‡¦ç†: ãƒãƒ©ãƒ³ã‚¹å‹
            return system_resources['cpu_count'] // 2
```

---

## ğŸ› ï¸ å®Ÿè£…è¨ˆç”»

### Phase 1: åŸºç›¤ä¸¦åˆ—åŒ–ã‚·ã‚¹ãƒ†ãƒ 

```python
class AdvancedParallelMLEngine:
    """é«˜åº¦ä¸¦åˆ—MLå‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self,
                 cpu_workers: int = None,
                 io_workers: int = None,
                 memory_limit_gb: float = 2.0):

        # è‡ªå‹•ãƒªã‚½ãƒ¼ã‚¹æ¤œå‡º
        cpu_count = os.cpu_count()
        memory_gb = psutil.virtual_memory().total / (1024**3)

        self.cpu_workers = cpu_workers or min(cpu_count, 8)
        self.io_workers = io_workers or min(int(memory_gb * 4), 20)
        self.memory_limit = memory_limit_gb

        # ä¸¦åˆ—åŒ–ãƒ—ãƒ¼ãƒ«åˆæœŸåŒ–
        self.process_pool = ProcessPoolExecutor(max_workers=self.cpu_workers)
        self.thread_pool = ThreadPoolExecutor(max_workers=self.io_workers)
        self.async_semaphore = asyncio.Semaphore(self.io_workers)
```

### Phase 2: æ™ºèƒ½ã‚¿ã‚¹ã‚¯åˆ†æ•£

```python
def intelligent_task_distribution(self, symbols: List[str], batch_size: int = 50):
    """çŸ¥çš„ã‚¿ã‚¹ã‚¯åˆ†æ•£ã‚·ã‚¹ãƒ†ãƒ """

    # éŠ˜æŸ„è¤‡é›‘åº¦åˆ†æ
    symbol_complexity = self.analyze_symbol_complexity(symbols)

    # å‹•çš„ãƒãƒƒãƒä½œæˆ
    balanced_batches = self.create_complexity_balanced_batches(
        symbol_complexity, batch_size
    )

    # ãƒªã‚½ãƒ¼ã‚¹åˆ©ç”¨ç‡æœ€é©åŒ–
    optimal_scheduling = self.optimize_resource_scheduling(balanced_batches)

    return optimal_scheduling
```

### Phase 3: ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€£æºæœ€é©åŒ–

```python
# Issue #324ã§å®Ÿè£…ã—ãŸçµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¨ã®é€£æº
def parallel_processing_with_cache(self, symbols: List[str]):
    """ä¸¦åˆ—å‡¦ç† + çµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥é€£æº"""

    # L1ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‹ã‚‰é«˜é€Ÿå–å¾—
    cached_results = self.unified_cache.batch_get(symbols, layer="L1")

    # æœªã‚­ãƒ£ãƒƒã‚·ãƒ¥éŠ˜æŸ„ã®ã¿ä¸¦åˆ—å‡¦ç†
    uncached_symbols = [s for s in symbols if s not in cached_results]

    if uncached_symbols:
        # ä¸¦åˆ—å‡¦ç†å®Ÿè¡Œ
        new_results = await self.parallel_ml_processing(uncached_symbols)

        # çµæœã‚’ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã«è‡ªå‹•ä¿å­˜ï¼ˆå„ªå…ˆåº¦ä»˜ãï¼‰
        self.unified_cache.batch_put(new_results, priority_based=True)

        # çµæœçµ±åˆ
        return {**cached_results, **new_results}

    return cached_results
```

---

## ğŸ“ˆ æœŸå¾…ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„

### å‡¦ç†æ™‚é–“äºˆæ¸¬

```
ç¾åœ¨ã®å‡¦ç†èƒ½åŠ›ï¼ˆIssue #325æœ€é©åŒ–å¾Œï¼‰:
- å˜ä¸€éŠ˜æŸ„: 2.2ç§’
- 10éŠ˜æŸ„: 22ç§’
- 85éŠ˜æŸ„: 187ç§’ï¼ˆç´„3åˆ†ï¼‰
- 500éŠ˜æŸ„: 1,100ç§’ï¼ˆç´„18åˆ†ï¼‰

ä¸¦åˆ—åŒ–å¾Œã®ç›®æ¨™:
- å˜ä¸€éŠ˜æŸ„: 2.2ç§’ï¼ˆå¤‰ã‚ã‚‰ãšï¼‰
- 10éŠ˜æŸ„: 6ç§’ï¼ˆ4å€é«˜é€ŸåŒ–ï¼‰
- 85éŠ˜æŸ„: 47ç§’ï¼ˆ4å€é«˜é€ŸåŒ–ï¼‰
- 500éŠ˜æŸ„: 275ç§’ï¼ˆç´„4.5åˆ†ã€4å€é«˜é€ŸåŒ–ï¼‰

ç†æƒ³çš„ãªã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£:
- 8ã‚³ã‚¢CPUã§æœ€å¤§8å€ä¸¦åˆ—åŒ–
- I/Oãƒã‚¦ãƒ³ãƒ‰å‡¦ç†ã§20å€ä¸¦åˆ—åŒ–
- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ’ãƒƒãƒˆç‡90%ã§10å€é«˜é€ŸåŒ–
```

### ãƒªã‚½ãƒ¼ã‚¹åŠ¹ç‡åŒ–

```
ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡æœ€é©åŒ–:
- å…±æœ‰ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹: 60%å‰Šæ¸›
- çµ±åˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨: 98%å‰Šæ¸›ï¼ˆIssue #324ï¼‰
- ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡æœ€å°åŒ–: 30%å‰Šæ¸›

CPUä½¿ç”¨ç‡æ”¹å–„:
- ãƒãƒ«ãƒã‚³ã‚¢æ´»ç”¨ç‡: 15% â†’ 85%
- å¾…æ©Ÿæ™‚é–“å‰Šæ¸›: 70%çŸ­ç¸®
- ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ: 4-8å€å‘ä¸Š
```

---

## ğŸ¯ å®Ÿè£…å„ªå…ˆåº¦

### é«˜å„ªå…ˆåº¦ï¼ˆå³æ™‚å®Ÿè£…ï¼‰
1. **AdvancedParallelMLEngine** - åŸºç›¤ä¸¦åˆ—åŒ–ã‚·ã‚¹ãƒ†ãƒ 
2. **BatchProcessingOrchestrator** - ãƒãƒƒãƒå‡¦ç†çµ±åˆåˆ¶å¾¡
3. **CacheAwareParallelProcessor** - ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€£æºæœ€é©åŒ–

### ä¸­å„ªå…ˆåº¦ï¼ˆPhase 2ï¼‰
1. **AdaptiveLoadBalancer** - å‹•çš„è² è·åˆ†æ•£
2. **ResourceOptimizer** - ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨é‡æœ€é©åŒ–
3. **PredictiveScheduler** - äºˆæ¸¬çš„ã‚¿ã‚¹ã‚¯ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

### ä½å„ªå…ˆåº¦ï¼ˆå°†æ¥æ‹¡å¼µï¼‰
1. **DistributedMLEngine** - åˆ†æ•£å‡¦ç†å¯¾å¿œ
2. **GPUAccelerator** - GPUä¸¦åˆ—åŒ–
3. **CloudNativeScaling** - ã‚¯ãƒ©ã‚¦ãƒ‰ç’°å¢ƒè‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

---

## ğŸ“‹ æŠ€è¡“ä»•æ§˜

### ä¾å­˜é–¢ä¿‚
```python
# å¿…è¦ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
concurrent.futures    # ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚¹ãƒ¬ãƒƒãƒ‰ä¸¦åˆ—åŒ–
multiprocessing      # ãƒãƒ«ãƒãƒ—ãƒ­ã‚»ã‚¹å‡¦ç†
asyncio             # éåŒæœŸI/O
psutil              # ã‚·ã‚¹ãƒ†ãƒ ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–
threading           # ã‚¹ãƒ¬ãƒƒãƒ‰åˆ¶å¾¡
queue               # ãƒ—ãƒ­ã‚»ã‚¹é–“é€šä¿¡
```

### è¨­å®šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
```python
PARALLEL_CONFIG = {
    'cpu_workers': 'auto',        # CPUã‚³ã‚¢æ•°è‡ªå‹•æ¤œå‡º
    'io_workers': 'auto',         # ãƒ¡ãƒ¢ãƒªãƒ™ãƒ¼ã‚¹è‡ªå‹•ç®—å‡º
    'memory_limit_gb': 2.0,       # ãƒ—ãƒ­ã‚»ã‚¹å½“ãŸã‚Šãƒ¡ãƒ¢ãƒªåˆ¶é™
    'timeout_seconds': 300,       # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
    'retry_count': 3,             # å¤±æ•—æ™‚ãƒªãƒˆãƒ©ã‚¤å›æ•°
    'batch_size': 50,             # ãƒãƒƒãƒã‚µã‚¤ã‚º
    'cache_integration': True,    # ã‚­ãƒ£ãƒƒã‚·ãƒ¥é€£æºæœ‰åŠ¹åŒ–
    'resource_monitoring': True   # ãƒªã‚½ãƒ¼ã‚¹ç›£è¦–æœ‰åŠ¹åŒ–
}
```

---

## ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

### ä»Šå¾Œã®ä½œæ¥­è¨ˆç”»
1. **ä¸¦åˆ—åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è©³ç´°è¨­è¨ˆ** - ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“è¨­è¨ˆ
2. **AdvancedParallelMLEngineå®Ÿè£…** - ã‚³ã‚¢ä¸¦åˆ—å‡¦ç†ã‚¨ãƒ³ã‚¸ãƒ³
3. **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ** - åŠ¹æœæ¸¬å®šã¨èª¿æ•´
4. **ãƒ—ãƒ­ãƒ€ã‚¯ã‚·ãƒ§ãƒ³çµ±åˆ** - æ—¢å­˜ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆ

**æ¨å®šä½œæ¥­æ™‚é–“**: 3-4æ™‚é–“  
**æœŸå¾…åŠ¹æœ**: 4-8å€ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆæ”¹å–„  
**å¯¾è±¡**: TOPIX500 (500éŠ˜æŸ„) 18åˆ† â†’ 4.5åˆ†å‡¦ç†

---

**åˆ†ææ—¥æ™‚**: 2025-08-08 19:35:00  
**Issue**: #323 ML Processing Parallelization  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: åˆ†æå®Œäº† â†’ è¨­è¨ˆãƒ•ã‚§ãƒ¼ã‚º  
**æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ä¸¦åˆ—åŒ–ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆãƒ»å®Ÿè£…
