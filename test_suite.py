#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Day Trade Personal Test Suite - åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
Issue #933 Phase 4å¯¾å¿œ: ã‚·ã‚¹ãƒ†ãƒ å“è³ªä¿è¨¼ã®ãŸã‚ã®çµ±åˆãƒ†ã‚¹ãƒˆ
"""

import unittest
import sys
import os
import time
import json
import sqlite3
from datetime import datetime, timedelta
from pathlib import Path
from unittest.mock import patch, MagicMock
import tempfile
import shutil

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import sys
    sys.path.insert(0, '.')

    # ã‚³ã‚¢ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
    from version import get_version_info, __version__, __version_extended__
    from performance_monitor import PerformanceMonitor, performance_monitor
    from data_persistence import DataPersistence, data_persistence

    # Webã‚µãƒ¼ãƒãƒ¼ã¨CLI
    from daytrade_web import DayTradeWebServer
    from daytrade_core import main as daytrade_core_main

    MODULES_AVAILABLE = True
except ImportError as e:
    print(f"[è­¦å‘Š] ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
    MODULES_AVAILABLE = False


class TestVersionManagement(unittest.TestCase):
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        if not MODULES_AVAILABLE:
            self.skipTest("Required modules not available")

    def test_version_info_structure(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã®æ§‹é€ ãƒ†ã‚¹ãƒˆ"""
        version_info = get_version_info()

        self.assertIsInstance(version_info, dict)
        self.assertIn('version', version_info)
        self.assertIn('version_extended', version_info)
        self.assertIn('release_name', version_info)
        self.assertIn('build_date', version_info)

        # ãƒãƒ¼ã‚¸ãƒ§ãƒ³å½¢å¼ãƒã‚§ãƒƒã‚¯
        self.assertRegex(version_info['version'], r'\d+\.\d+\.\d+')

    def test_version_consistency(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        version_info = get_version_info()

        self.assertEqual(version_info['version'], __version__)
        self.assertEqual(version_info['version_extended'], __version_extended__)

    def test_version_components(self):
        """ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        from version import COMPONENTS, COMPATIBILITY

        self.assertIsInstance(COMPONENTS, dict)
        self.assertIn('core', COMPONENTS)
        self.assertIn('web_server', COMPONENTS)
        self.assertIn('cli', COMPONENTS)

        self.assertIsInstance(COMPATIBILITY, dict)
        self.assertIn('min_python_version', COMPATIBILITY)
        self.assertIn('supported_os', COMPATIBILITY)


class TestPerformanceMonitoring(unittest.TestCase):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        if not MODULES_AVAILABLE:
            self.skipTest("Required modules not available")

        # ãƒ†ã‚¹ãƒˆç”¨ã®ç›£è¦–ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        self.monitor = PerformanceMonitor(max_history_size=50)

    def tearDown(self):
        if hasattr(self, 'monitor'):
            self.monitor.stop_monitoring()

    def test_analysis_time_tracking(self):
        """åˆ†æžæ™‚é–“è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
        self.monitor.track_analysis_time('7203', 0.15, 'test_analysis')
        self.monitor.track_analysis_time('8306', 0.22, 'test_analysis')

        summary = self.monitor.get_performance_summary()
        self.assertEqual(summary['total_analyses'], 2)
        self.assertGreater(summary['avg_analysis_time_ms'], 0)

    def test_api_response_tracking(self):
        """APIå¿œç­”æ™‚é–“è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
        self.monitor.track_api_response_time('/api/test', 0.12, 200)
        self.monitor.track_api_response_time('/api/test', 0.08, 200)
        self.monitor.track_api_response_time('/api/error', 0.30, 500)

        summary = self.monitor.get_performance_summary()
        self.assertEqual(summary['total_api_calls'], 3)
        self.assertGreater(summary['avg_api_response_ms'], 0)

    def test_error_tracking(self):
        """ã‚¨ãƒ©ãƒ¼è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
        self.monitor.track_error('test_error', 'Test error message')
        self.monitor.track_error('api_error', 'API error message')

        summary = self.monitor.get_performance_summary()
        self.assertEqual(len(summary['error_counts']), 2)
        self.assertEqual(summary['error_counts']['test_error'], 1)
        self.assertEqual(summary['error_counts']['api_error'], 1)

    def test_performance_report_generation(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ 
        self.monitor.track_analysis_time('7203', 0.15, 'test_analysis')
        self.monitor.track_api_response_time('/api/test', 0.12, 200)

        report = self.monitor.generate_performance_report()

        self.assertIsInstance(report, str)
        self.assertIn('Performance Report', report)
        self.assertIn('System Overview', report)
        self.assertIn('Total Analyses', report)
        self.assertIn('Total API Calls', report)

    def test_memory_monitoring(self):
        """ãƒ¡ãƒ¢ãƒªç›£è¦–ãƒ†ã‚¹ãƒˆ"""
        memory_usage = self.monitor.get_memory_usage()

        if memory_usage:  # psutilãŒåˆ©ç”¨å¯èƒ½ãªå ´åˆ
            self.assertIsInstance(memory_usage, dict)
            self.assertIn('rss_mb', memory_usage)
            self.assertIn('memory_percent', memory_usage)
            self.assertGreater(memory_usage['rss_mb'], 0)


class TestDataPersistence(unittest.TestCase):
    """ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã‚·ã‚¹ãƒ†ãƒ ã®ãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        if not MODULES_AVAILABLE:
            self.skipTest("Required modules not available")

        # ãƒ†ã‚¹ãƒˆç”¨ã®ä¸€æ™‚ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
        self.test_dir = tempfile.mkdtemp()
        self.test_db_path = os.path.join(self.test_dir, 'test_db.sqlite')
        self.persistence = DataPersistence(db_path=self.test_db_path)

    def tearDown(self):
        if hasattr(self, 'persistence'):
            self.persistence.stop_auto_backup()

        if hasattr(self, 'test_dir'):
            shutil.rmtree(self.test_dir, ignore_errors=True)

    def test_database_initialization(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
        self.assertTrue(Path(self.test_db_path).exists())

        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.execute(
                "SELECT name FROM sqlite_master WHERE type='table'"
            )
            tables = [row[0] for row in cursor.fetchall()]

            expected_tables = [
                'analysis_history', 'api_performance', 'system_metrics',
                'error_logs', 'recommendations_history'
            ]

            for table in expected_tables:
                self.assertIn(table, tables)

    def test_analysis_result_saving(self):
        """åˆ†æžçµæžœä¿å­˜ãƒ†ã‚¹ãƒˆ"""
        test_data = {
            'symbol': '7203',
            'recommendation': 'BUY',
            'confidence': 0.85,
            'price': 1500
        }

        self.persistence.save_analysis_result(
            symbol='7203',
            analysis_type='test_analysis',
            duration_ms=150.5,
            result_data=test_data,
            confidence_score=0.85,
            session_id='test_session'
        )

        stats = self.persistence.get_analysis_statistics(24)
        self.assertEqual(stats['total_statistics']['total_analyses'], 1)

    def test_api_performance_saving(self):
        """APIæ€§èƒ½ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ†ã‚¹ãƒˆ"""
        self.persistence.save_api_performance(
            endpoint='/api/test',
            response_time_ms=120.3,
            status_code=200,
            session_id='test_session'
        )

        stats = self.persistence.get_api_statistics(24)
        self.assertEqual(stats['total_statistics']['total_requests'], 1)

    def test_error_log_saving(self):
        """ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜ãƒ†ã‚¹ãƒˆ"""
        self.persistence.save_error_log(
            error_type='test_error',
            error_message='Test error occurred',
            context_data={'test': 'data'},
            session_id='test_session'
        )

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ç›´æŽ¥æ¤œè¨¼
        with sqlite3.connect(self.test_db_path) as conn:
            cursor = conn.execute('SELECT COUNT(*) FROM error_logs')
            count = cursor.fetchone()[0]
            self.assertEqual(count, 1)

    def test_data_export(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿è¿½åŠ 
        test_data = {'test': 'data'}
        self.persistence.save_analysis_result(
            symbol='7203',
            analysis_type='test',
            duration_ms=100,
            result_data=test_data,
            confidence_score=0.8
        )

        # JSONã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ
        export_result = self.persistence.export_data('json', self.test_dir)
        self.assertTrue(Path(export_result).exists())

        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª
        with open(export_result, 'r', encoding='utf-8') as f:
            exported_data = json.load(f)

        self.assertIn('export_info', exported_data)
        self.assertIn('analysis_history', exported_data)
        self.assertEqual(len(exported_data['analysis_history']), 1)


class TestWebServerIntegration(unittest.TestCase):
    """Webã‚µãƒ¼ãƒãƒ¼ã¨ã®Shellçµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        if not MODULES_AVAILABLE:
            self.skipTest("Required modules not available")

        # ãƒ†ã‚¹ãƒˆç”¨Webã‚µãƒ¼ãƒãƒ¼èµ·å‹•
        self.web_server = DayTradeWebServer(port=8099, debug=True)
        self.app = self.web_server.app.test_client()

    def test_status_endpoint(self):
        """ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        response = self.app.get('/api/status')
        self.assertEqual(response.status_code, 200)

        data = json.loads(response.data)
        self.assertEqual(data['status'], 'running')
        self.assertIn('version', data)
        self.assertIn('features', data)

    def test_analysis_endpoint(self):
        """åˆ†æžã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        response = self.app.get('/api/analysis/7203')
        self.assertEqual(response.status_code, 200)

        data = json.loads(response.data)
        self.assertEqual(data['symbol'], '7203')
        self.assertIn('recommendation', data)
        self.assertIn('confidence', data)
        self.assertIn('timestamp', data)

    def test_recommendations_endpoint(self):
        """æŽ¨å¥¨éŠ˜æŸ„ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        response = self.app.get('/api/recommendations')
        self.assertEqual(response.status_code, 200)

        data = json.loads(response.data)
        self.assertIn('recommendations', data)
        self.assertIn('total_count', data)
        self.assertGreater(data['total_count'], 0)

    def test_performance_endpoints(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        # åŸºæœ¬ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹
        response = self.app.get('/api/performance')
        self.assertIn(response.status_code, [200, 501])  # 501 = ç›£è¦–ç„¡åŠ¹æ™‚

        # è©³ç´°ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹
        response = self.app.get('/api/performance/detailed')
        self.assertIn(response.status_code, [200, 501])

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ
        response = self.app.get('/api/performance/report')
        self.assertIn(response.status_code, [200, 501])

    def test_data_persistence_endpoints(self):
        """ãƒ‡ãƒ¼ã‚¿æ°¸ç¶šåŒ–ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãƒ†ã‚¹ãƒˆ"""
        # çµ±è¨ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
        response = self.app.get('/api/data/statistics')
        self.assertIn(response.status_code, [200, 501])

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æƒ…å ±
        response = self.app.get('/api/data/database-info')
        self.assertIn(response.status_code, [200, 501])

        # ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
        response = self.app.get('/api/data/export?format=json')
        self.assertIn(response.status_code, [200, 501])

    def test_health_check(self):
        """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ†ã‚¹ãƒˆ"""
        response = self.app.get('/health')
        self.assertEqual(response.status_code, 200)

        data = json.loads(response.data)
        self.assertEqual(data['status'], 'healthy')


class TestSystemIntegration(unittest.TestCase):
    """ã‚·ã‚¹ãƒ†ãƒ å…¨ä½“çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        if not MODULES_AVAILABLE:
            self.skipTest("Required modules not available")

    def test_module_imports(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ†ã‚¹ãƒˆ"""
        modules_to_test = [
            'version', 'performance_monitor', 'data_persistence',
            'daytrade_web', 'daytrade_core'
        ]

        for module_name in modules_to_test:
            try:
                __import__(module_name)
            except ImportError:
                self.fail(f"Failed to import {module_name}")

    def test_version_consistency_across_modules(self):
        """ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“ãƒãƒ¼ã‚¸ãƒ§ãƒ³ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        from version import get_version_info
        from daytrade_web import VERSION_INFO as web_version

        base_version = get_version_info()

        # Webã‚µãƒ¼ãƒãƒ¼ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ä¸€è‡´ç¢ºèª
        self.assertEqual(base_version['version'], web_version['version'])
        self.assertEqual(base_version['build_date'], web_version['build_date'])

    def test_performance_monitor_integration(self):
        """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ç›£è¦–çµ±åˆãƒ†ã‚¹ãƒˆ"""
        from performance_monitor import performance_monitor, track_performance

        # ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ
        @track_performance
        def test_function(x, y):
            time.sleep(0.01)  # å°‘ã—æ™‚é–“ã‚’ã‹ã‘ã‚‹
            return x + y

        result = test_function(1, 2)
        self.assertEqual(result, 3)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ãŒè¨˜éŒ²ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
        summary = performance_monitor.get_performance_summary()
        self.assertGreaterEqual(summary['total_analyses'], 1)


def run_performance_benchmark():
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œ"""
    print("=== ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œ ===")

    if not MODULES_AVAILABLE:
        print("[è­¦å‘Š] ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒåˆ©ç”¨ã§ããªã„ãŸã‚ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
        return

    # åˆ†æžå‡¦ç†ã®ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯
    start_time = time.time()

    try:
        monitor = PerformanceMonitor(max_history_size=100)

        # 100å›žã®åˆ†æžã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        for i in range(100):
            monitor.track_analysis_time(f'symbol_{i}', 0.1 + (i % 10) * 0.01, 'benchmark')

        # APIå‘¼ã³å‡ºã—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        for i in range(50):
            monitor.track_api_response_time('/api/test', 0.05 + (i % 5) * 0.01, 200)

        total_time = time.time() - start_time
        summary = monitor.get_performance_summary()

        print(f"ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œæ™‚é–“: {total_time:.2f}ç§’")
        print(f"å‡¦ç†ã—ãŸåˆ†æžæ•°: {summary['total_analyses']}")
        print(f"å‡¦ç†ã—ãŸAPIå‘¼ã³å‡ºã—æ•°: {summary['total_api_calls']}")
        print(f"å¹³å‡åˆ†æžæ™‚é–“: {summary['avg_analysis_time_ms']:.2f}ms")
        print(f"å¹³å‡APIå¿œç­”æ™‚é–“: {summary['avg_api_response_ms']:.2f}ms")

        monitor.stop_monitoring()

    except Exception as e:
        print(f"ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")


def run_full_test_suite():
    """å®Œå…¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ"""
    print("Day Trade Personal - åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60)

    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
    if MODULES_AVAILABLE:
        try:
            version_info = get_version_info()
            print(f"ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒãƒ¼ã‚¸ãƒ§ãƒ³: {version_info['version']} {version_info['release_name']}")
            print(f"ãƒ“ãƒ«ãƒ‰æ—¥: {version_info['build_date']}")
        except Exception as e:
            print(f"ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

    print("-" * 60)

    # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    test_suite = unittest.TestLoader().loadTestsFromModule(sys.modules[__name__])
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    print("-" * 60)

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒžãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒžãƒ¼ã‚¯
    run_performance_benchmark()

    print("-" * 60)

    # çµæžœã‚µãƒžãƒªãƒ¼
    total_tests = result.testsRun
    failures = len(result.failures)
    errors = len(result.errors)
    success_rate = ((total_tests - failures - errors) / total_tests * 100) if total_tests > 0 else 0

    print(f"ãƒ†ã‚¹ãƒˆçµæžœã‚µãƒžãƒªãƒ¼:")
    print(f"  å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
    print(f"  æˆåŠŸ: {total_tests - failures - errors}")
    print(f"  å¤±æ•—: {failures}")
    print(f"  ã‚¨ãƒ©ãƒ¼: {errors}")
    print(f"  æˆåŠŸçŽ‡: {success_rate:.1f}%")

    if success_rate >= 90:
        print("ðŸŽ‰ ã‚·ã‚¹ãƒ†ãƒ å“è³ª: å„ªç§€ (90%ä»¥ä¸Š)")
    elif success_rate >= 80:
        print("âœ… ã‚·ã‚¹ãƒ†ãƒ å“è³ª: è‰¯å¥½ (80%ä»¥ä¸Š)")
    elif success_rate >= 70:
        print("âš ï¸  ã‚·ã‚¹ãƒ†ãƒ å“è³ª: æ³¨æ„ãŒå¿…è¦ (70%ä»¥ä¸Š)")
    else:
        print("âŒ ã‚·ã‚¹ãƒ†ãƒ å“è³ª: æ”¹å–„ãŒå¿…è¦ (70%æœªæº€)")

    return success_rate >= 80


if __name__ == '__main__':
    success = run_full_test_suite()

    # çµ‚äº†ã‚³ãƒ¼ãƒ‰è¨­å®š
    sys.exit(0 if success else 1)